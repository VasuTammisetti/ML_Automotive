{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance//NASA_Dataset_Turbofan Engine Degradation Simulation/CMAPSSData/train_FD004.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unit Number</th>\n",
       "      <th>Cycles Time</th>\n",
       "      <th>Operational Setting 1</th>\n",
       "      <th>Operational Setting 2</th>\n",
       "      <th>Operational Setting 3</th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 13</th>\n",
       "      <th>Sensor 14</th>\n",
       "      <th>Sensor 15</th>\n",
       "      <th>Sensor 16</th>\n",
       "      <th>Sensor 17</th>\n",
       "      <th>Sensor 18</th>\n",
       "      <th>Sensor 19</th>\n",
       "      <th>Sensor 20</th>\n",
       "      <th>Sensor 21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0049</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.68</td>\n",
       "      <td>1343.43</td>\n",
       "      <td>1112.93</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>8074.83</td>\n",
       "      <td>9.3335</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.62</td>\n",
       "      <td>6.3670</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0020</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>606.07</td>\n",
       "      <td>1477.61</td>\n",
       "      <td>1237.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.73</td>\n",
       "      <td>8046.13</td>\n",
       "      <td>9.1913</td>\n",
       "      <td>0.02</td>\n",
       "      <td>361</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.37</td>\n",
       "      <td>14.6552</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0038</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.95</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1117.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.97</td>\n",
       "      <td>8066.62</td>\n",
       "      <td>9.4007</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.48</td>\n",
       "      <td>6.4213</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.70</td>\n",
       "      <td>1341.24</td>\n",
       "      <td>1118.03</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8076.05</td>\n",
       "      <td>9.3369</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.54</td>\n",
       "      <td>6.4176</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0063</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.10</td>\n",
       "      <td>1255.23</td>\n",
       "      <td>1033.59</td>\n",
       "      <td>...</td>\n",
       "      <td>2028.08</td>\n",
       "      <td>7865.80</td>\n",
       "      <td>10.8366</td>\n",
       "      <td>0.02</td>\n",
       "      <td>305</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.03</td>\n",
       "      <td>8.6754</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unit Number  Cycles Time  Operational Setting 1  \\\n",
       "0           0            1            1                42.0049   \n",
       "1           1            1            2                20.0020   \n",
       "2           2            1            3                42.0038   \n",
       "3           3            1            4                42.0000   \n",
       "4           4            1            5                25.0063   \n",
       "\n",
       "   Operational Setting 2  Operational Setting 3  Sensor 1  Sensor 2  Sensor 3  \\\n",
       "0                 0.8400                  100.0    445.00    549.68   1343.43   \n",
       "1                 0.7002                  100.0    491.19    606.07   1477.61   \n",
       "2                 0.8409                  100.0    445.00    548.95   1343.12   \n",
       "3                 0.8400                  100.0    445.00    548.70   1341.24   \n",
       "4                 0.6207                   60.0    462.54    536.10   1255.23   \n",
       "\n",
       "   Sensor 4  ...  Sensor 13  Sensor 14  Sensor 15  Sensor 16  Sensor 17  \\\n",
       "0   1112.93  ...    2387.99    8074.83     9.3335       0.02        330   \n",
       "1   1237.50  ...    2387.73    8046.13     9.1913       0.02        361   \n",
       "2   1117.05  ...    2387.97    8066.62     9.4007       0.02        329   \n",
       "3   1118.03  ...    2388.02    8076.05     9.3369       0.02        328   \n",
       "4   1033.59  ...    2028.08    7865.80    10.8366       0.02        305   \n",
       "\n",
       "   Sensor 18  Sensor 19  Sensor 20  Sensor 21   RUL  \n",
       "0       2212     100.00      10.62     6.3670  22.0  \n",
       "1       2324     100.00      24.37    14.6552  22.0  \n",
       "2       2212     100.00      10.48     6.4213  22.0  \n",
       "3       2212     100.00      10.54     6.4176  22.0  \n",
       "4       1915      84.93      14.03     8.6754  22.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321, 299, 307, 274, 193, 331, 221, 230, 334, 354, 301, 272, 256, 253, 224, 184, 151, 343, 210, 245, 227, 211, 280, 186, 150, 297, 163, 202, 247, 297, 263, 219, 201, 276, 221, 143, 388, 177, 202, 206, 279, 280, 223, 203, 177, 321, 375, 322, 446, 172, 285, 357, 304, 197, 344, 347, 193, 281, 177, 218, 244, 297, 170, 184, 351, 175, 167, 163, 226, 185, 312, 308, 181, 244, 230, 152, 148, 250, 218, 305, 187, 197, 184, 159, 277, 232, 259, 388, 168, 212, 354, 191, 196, 249, 239, 270, 262, 245, 167, 261, 260, 194, 224, 203, 170, 266, 183, 304, 325, 186, 297, 340, 184, 161, 131, 344, 342, 543, 187, 177, 194, 174, 226, 170, 239, 302, 235, 248, 190, 166, 370, 254, 489, 247, 149, 205, 225, 178, 251, 298, 199, 209, 184, 297, 228, 303, 234, 193, 261, 149, 351, 262, 168, 203, 295, 139, 298, 399, 288, 187, 303, 313, 285, 380, 255, 269, 263, 196, 227, 161, 399, 273, 457, 370, 156, 180, 242, 170, 435, 344, 134, 205, 190, 379, 259, 163, 273, 254, 239, 381, 297, 190, 197, 145, 159, 174, 170, 164, 176, 225, 378, 241, 324, 211, 242, 263, 379, 290, 161, 167, 146, 229, 197, 128, 361, 244, 200, 236, 190, 202, 274, 202, 247, 268, 418, 194, 287, 279, 280, 250, 194, 273, 289, 207, 199, 225, 212, 187, 365, 149, 332, 222, 327, 267, 205, 161, 211, 184, 255] 249\n",
      "[  1   2   3 ... 253 254 255]\n"
     ]
    }
   ],
   "source": [
    "df1['RUL'] = df1['Unit Number']\n",
    "a=np.array(df1['RUL'])\n",
    "c=df1['RUL'].values\n",
    "#b = np.array(df2[0].values)\n",
    "l=[]\n",
    "#print(a,a.size)\n",
    "for j in range(1,250): # for FD001 range(1,101), for FD002 range(1,261), for FD003 range(1,101), for FD004 range (1,250)\n",
    "    count = 0\n",
    "    for i in range(0,a.size):\n",
    "        if a[i] == j:\n",
    "             count += 1\n",
    "    l.append(count)\n",
    "    \n",
    "print(l,len(l))\n",
    "#df1['RUL']= pd.Series(l)\n",
    "#print(pd.Series(l))\n",
    "cyl = np.array(df1['Cycles Time'])\n",
    "l1=[]\n",
    "print(cyl)\n",
    "\n",
    "for j in range(1,250): # for FD001 range(1,101), for FD002 range(1,261), for FD003 range(1,101), for FD004 range (1,250)\n",
    "    dec = 1\n",
    "    for i in range(0,a.size):\n",
    "        if a[i] == j:\n",
    "            l1.append(l[j-1]-dec)\n",
    "            dec += 1\n",
    "                \n",
    "#print(l1,dec,len(l1))\n",
    "df1['RUL']= pd.Series(l1)\n",
    "#df1=df1.drop(labels='RUL', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unit Number</th>\n",
       "      <th>Cycles Time</th>\n",
       "      <th>Operational Setting 1</th>\n",
       "      <th>Operational Setting 2</th>\n",
       "      <th>Operational Setting 3</th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 13</th>\n",
       "      <th>Sensor 14</th>\n",
       "      <th>Sensor 15</th>\n",
       "      <th>Sensor 16</th>\n",
       "      <th>Sensor 17</th>\n",
       "      <th>Sensor 18</th>\n",
       "      <th>Sensor 19</th>\n",
       "      <th>Sensor 20</th>\n",
       "      <th>Sensor 21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0049</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.68</td>\n",
       "      <td>1343.43</td>\n",
       "      <td>1112.93</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>8074.83</td>\n",
       "      <td>9.3335</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.62</td>\n",
       "      <td>6.3670</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0020</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>606.07</td>\n",
       "      <td>1477.61</td>\n",
       "      <td>1237.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.73</td>\n",
       "      <td>8046.13</td>\n",
       "      <td>9.1913</td>\n",
       "      <td>0.02</td>\n",
       "      <td>361</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.37</td>\n",
       "      <td>14.6552</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0038</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.95</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1117.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.97</td>\n",
       "      <td>8066.62</td>\n",
       "      <td>9.4007</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.48</td>\n",
       "      <td>6.4213</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.70</td>\n",
       "      <td>1341.24</td>\n",
       "      <td>1118.03</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8076.05</td>\n",
       "      <td>9.3369</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.54</td>\n",
       "      <td>6.4176</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0063</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.10</td>\n",
       "      <td>1255.23</td>\n",
       "      <td>1033.59</td>\n",
       "      <td>...</td>\n",
       "      <td>2028.08</td>\n",
       "      <td>7865.80</td>\n",
       "      <td>10.8366</td>\n",
       "      <td>0.02</td>\n",
       "      <td>305</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.03</td>\n",
       "      <td>8.6754</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unit Number  Cycles Time  Operational Setting 1  \\\n",
       "0           0            1            1                42.0049   \n",
       "1           1            1            2                20.0020   \n",
       "2           2            1            3                42.0038   \n",
       "3           3            1            4                42.0000   \n",
       "4           4            1            5                25.0063   \n",
       "\n",
       "   Operational Setting 2  Operational Setting 3  Sensor 1  Sensor 2  Sensor 3  \\\n",
       "0                 0.8400                  100.0    445.00    549.68   1343.43   \n",
       "1                 0.7002                  100.0    491.19    606.07   1477.61   \n",
       "2                 0.8409                  100.0    445.00    548.95   1343.12   \n",
       "3                 0.8400                  100.0    445.00    548.70   1341.24   \n",
       "4                 0.6207                   60.0    462.54    536.10   1255.23   \n",
       "\n",
       "   Sensor 4  ...  Sensor 13  Sensor 14  Sensor 15  Sensor 16  Sensor 17  \\\n",
       "0   1112.93  ...    2387.99    8074.83     9.3335       0.02        330   \n",
       "1   1237.50  ...    2387.73    8046.13     9.1913       0.02        361   \n",
       "2   1117.05  ...    2387.97    8066.62     9.4007       0.02        329   \n",
       "3   1118.03  ...    2388.02    8076.05     9.3369       0.02        328   \n",
       "4   1033.59  ...    2028.08    7865.80    10.8366       0.02        305   \n",
       "\n",
       "   Sensor 18  Sensor 19  Sensor 20  Sensor 21  RUL  \n",
       "0       2212     100.00      10.62     6.3670  320  \n",
       "1       2324     100.00      24.37    14.6552  319  \n",
       "2       2212     100.00      10.48     6.4213  318  \n",
       "3       2212     100.00      10.54     6.4176  317  \n",
       "4       1915      84.93      14.03     8.6754  316  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unit Number</th>\n",
       "      <th>Cycles Time</th>\n",
       "      <th>Operational Setting 1</th>\n",
       "      <th>Operational Setting 2</th>\n",
       "      <th>Operational Setting 3</th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 13</th>\n",
       "      <th>Sensor 14</th>\n",
       "      <th>Sensor 15</th>\n",
       "      <th>Sensor 16</th>\n",
       "      <th>Sensor 17</th>\n",
       "      <th>Sensor 18</th>\n",
       "      <th>Sensor 19</th>\n",
       "      <th>Sensor 20</th>\n",
       "      <th>Sensor 21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61244</th>\n",
       "      <td>61244</td>\n",
       "      <td>249</td>\n",
       "      <td>251</td>\n",
       "      <td>9.9998</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>100.0</td>\n",
       "      <td>489.05</td>\n",
       "      <td>605.33</td>\n",
       "      <td>1516.36</td>\n",
       "      <td>1315.28</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.73</td>\n",
       "      <td>8185.69</td>\n",
       "      <td>8.4541</td>\n",
       "      <td>0.03</td>\n",
       "      <td>372</td>\n",
       "      <td>2319</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.11</td>\n",
       "      <td>17.5234</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61245</th>\n",
       "      <td>61245</td>\n",
       "      <td>249</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1598.92</td>\n",
       "      <td>1426.77</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.46</td>\n",
       "      <td>8185.47</td>\n",
       "      <td>8.2221</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.38</td>\n",
       "      <td>23.7151</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61246</th>\n",
       "      <td>61246</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.68</td>\n",
       "      <td>1607.72</td>\n",
       "      <td>1430.56</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.48</td>\n",
       "      <td>8193.94</td>\n",
       "      <td>8.2525</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.78</td>\n",
       "      <td>23.8270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61247</th>\n",
       "      <td>61247</td>\n",
       "      <td>249</td>\n",
       "      <td>254</td>\n",
       "      <td>35.0046</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.77</td>\n",
       "      <td>1381.29</td>\n",
       "      <td>1148.18</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.83</td>\n",
       "      <td>8125.64</td>\n",
       "      <td>9.0515</td>\n",
       "      <td>0.02</td>\n",
       "      <td>337</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.26</td>\n",
       "      <td>9.0774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61248</th>\n",
       "      <td>61248</td>\n",
       "      <td>249</td>\n",
       "      <td>255</td>\n",
       "      <td>42.0030</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.85</td>\n",
       "      <td>1369.75</td>\n",
       "      <td>1147.45</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.66</td>\n",
       "      <td>8144.33</td>\n",
       "      <td>9.1207</td>\n",
       "      <td>0.02</td>\n",
       "      <td>333</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>6.4341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unit Number  Cycles Time  Operational Setting 1  \\\n",
       "61244       61244          249          251                 9.9998   \n",
       "61245       61245          249          252                 0.0028   \n",
       "61246       61246          249          253                 0.0029   \n",
       "61247       61247          249          254                35.0046   \n",
       "61248       61248          249          255                42.0030   \n",
       "\n",
       "       Operational Setting 2  Operational Setting 3  Sensor 1  Sensor 2  \\\n",
       "61244                 0.2500                  100.0    489.05    605.33   \n",
       "61245                 0.0015                  100.0    518.67    643.42   \n",
       "61246                 0.0000                  100.0    518.67    643.68   \n",
       "61247                 0.8400                  100.0    449.44    555.77   \n",
       "61248                 0.8400                  100.0    445.00    549.85   \n",
       "\n",
       "       Sensor 3  Sensor 4  ...  Sensor 13  Sensor 14  Sensor 15  Sensor 16  \\\n",
       "61244   1516.36   1315.28  ...    2388.73    8185.69     8.4541       0.03   \n",
       "61245   1598.92   1426.77  ...    2388.46    8185.47     8.2221       0.03   \n",
       "61246   1607.72   1430.56  ...    2388.48    8193.94     8.2525       0.03   \n",
       "61247   1381.29   1148.18  ...    2388.83    8125.64     9.0515       0.02   \n",
       "61248   1369.75   1147.45  ...    2388.66    8144.33     9.1207       0.02   \n",
       "\n",
       "       Sensor 17  Sensor 18  Sensor 19  Sensor 20  Sensor 21  RUL  \n",
       "61244        372       2319      100.0      29.11    17.5234    4  \n",
       "61245        396       2388      100.0      39.38    23.7151    3  \n",
       "61246        395       2388      100.0      39.78    23.8270    2  \n",
       "61247        337       2223      100.0      15.26     9.0774    1  \n",
       "61248        333       2212      100.0      10.66     6.4341    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD004_derivedRUL.csv\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_derived = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD001_derivedRUL.csv\",header='infer')\n",
    "df2_derived = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD002_derivedRUL.csv\",header='infer')\n",
    "df3_derived = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD003_derivedRUL.csv\",header='infer')\n",
    "df4_derived = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD004_derivedRUL.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame = [df1_derived,df2_derived,df3_derived,df4_derived]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat(df_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unit Number</th>\n",
       "      <th>Cycles Time</th>\n",
       "      <th>Operational Setting 1</th>\n",
       "      <th>Operational Setting 2</th>\n",
       "      <th>Operational Setting 3</th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 13</th>\n",
       "      <th>Sensor 14</th>\n",
       "      <th>Sensor 15</th>\n",
       "      <th>Sensor 16</th>\n",
       "      <th>Sensor 17</th>\n",
       "      <th>Sensor 18</th>\n",
       "      <th>Sensor 19</th>\n",
       "      <th>Sensor 20</th>\n",
       "      <th>Sensor 21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unit Number  Cycles Time  Operational Setting 1  \\\n",
       "0           0            1            1                -0.0007   \n",
       "1           1            1            2                 0.0019   \n",
       "2           2            1            3                -0.0043   \n",
       "3           3            1            4                 0.0007   \n",
       "4           4            1            5                -0.0019   \n",
       "\n",
       "   Operational Setting 2  Operational Setting 3  Sensor 1  Sensor 2  Sensor 3  \\\n",
       "0                -0.0004                  100.0    518.67    641.82   1589.70   \n",
       "1                -0.0003                  100.0    518.67    642.15   1591.82   \n",
       "2                 0.0003                  100.0    518.67    642.35   1587.99   \n",
       "3                 0.0000                  100.0    518.67    642.35   1582.79   \n",
       "4                -0.0002                  100.0    518.67    642.37   1582.85   \n",
       "\n",
       "   Sensor 4  ...  Sensor 13  Sensor 14  Sensor 15  Sensor 16  Sensor 17  \\\n",
       "0   1400.60  ...    2388.02    8138.62     8.4195       0.03        392   \n",
       "1   1403.14  ...    2388.07    8131.49     8.4318       0.03        392   \n",
       "2   1404.20  ...    2388.03    8133.23     8.4178       0.03        390   \n",
       "3   1401.87  ...    2388.08    8133.83     8.3682       0.03        392   \n",
       "4   1406.22  ...    2388.04    8133.80     8.4294       0.03        393   \n",
       "\n",
       "   Sensor 18  Sensor 19  Sensor 20  Sensor 21  RUL  \n",
       "0       2388      100.0      39.06    23.4190  191  \n",
       "1       2388      100.0      39.00    23.4236  190  \n",
       "2       2388      100.0      38.95    23.3442  189  \n",
       "3       2388      100.0      38.88    23.3739  188  \n",
       "4       2388      100.0      38.90    23.4044  187  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unit Number</th>\n",
       "      <th>Cycles Time</th>\n",
       "      <th>Operational Setting 1</th>\n",
       "      <th>Operational Setting 2</th>\n",
       "      <th>Operational Setting 3</th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 13</th>\n",
       "      <th>Sensor 14</th>\n",
       "      <th>Sensor 15</th>\n",
       "      <th>Sensor 16</th>\n",
       "      <th>Sensor 17</th>\n",
       "      <th>Sensor 18</th>\n",
       "      <th>Sensor 19</th>\n",
       "      <th>Sensor 20</th>\n",
       "      <th>Sensor 21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61244</th>\n",
       "      <td>61244</td>\n",
       "      <td>249</td>\n",
       "      <td>251</td>\n",
       "      <td>9.9998</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>100.0</td>\n",
       "      <td>489.05</td>\n",
       "      <td>605.33</td>\n",
       "      <td>1516.36</td>\n",
       "      <td>1315.28</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.73</td>\n",
       "      <td>8185.69</td>\n",
       "      <td>8.4541</td>\n",
       "      <td>0.03</td>\n",
       "      <td>372</td>\n",
       "      <td>2319</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.11</td>\n",
       "      <td>17.5234</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61245</th>\n",
       "      <td>61245</td>\n",
       "      <td>249</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1598.92</td>\n",
       "      <td>1426.77</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.46</td>\n",
       "      <td>8185.47</td>\n",
       "      <td>8.2221</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.38</td>\n",
       "      <td>23.7151</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61246</th>\n",
       "      <td>61246</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.68</td>\n",
       "      <td>1607.72</td>\n",
       "      <td>1430.56</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.48</td>\n",
       "      <td>8193.94</td>\n",
       "      <td>8.2525</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.78</td>\n",
       "      <td>23.8270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61247</th>\n",
       "      <td>61247</td>\n",
       "      <td>249</td>\n",
       "      <td>254</td>\n",
       "      <td>35.0046</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.77</td>\n",
       "      <td>1381.29</td>\n",
       "      <td>1148.18</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.83</td>\n",
       "      <td>8125.64</td>\n",
       "      <td>9.0515</td>\n",
       "      <td>0.02</td>\n",
       "      <td>337</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.26</td>\n",
       "      <td>9.0774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61248</th>\n",
       "      <td>61248</td>\n",
       "      <td>249</td>\n",
       "      <td>255</td>\n",
       "      <td>42.0030</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.85</td>\n",
       "      <td>1369.75</td>\n",
       "      <td>1147.45</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.66</td>\n",
       "      <td>8144.33</td>\n",
       "      <td>9.1207</td>\n",
       "      <td>0.02</td>\n",
       "      <td>333</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>6.4341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unit Number  Cycles Time  Operational Setting 1  \\\n",
       "61244       61244          249          251                 9.9998   \n",
       "61245       61245          249          252                 0.0028   \n",
       "61246       61246          249          253                 0.0029   \n",
       "61247       61247          249          254                35.0046   \n",
       "61248       61248          249          255                42.0030   \n",
       "\n",
       "       Operational Setting 2  Operational Setting 3  Sensor 1  Sensor 2  \\\n",
       "61244                 0.2500                  100.0    489.05    605.33   \n",
       "61245                 0.0015                  100.0    518.67    643.42   \n",
       "61246                 0.0000                  100.0    518.67    643.68   \n",
       "61247                 0.8400                  100.0    449.44    555.77   \n",
       "61248                 0.8400                  100.0    445.00    549.85   \n",
       "\n",
       "       Sensor 3  Sensor 4  ...  Sensor 13  Sensor 14  Sensor 15  Sensor 16  \\\n",
       "61244   1516.36   1315.28  ...    2388.73    8185.69     8.4541       0.03   \n",
       "61245   1598.92   1426.77  ...    2388.46    8185.47     8.2221       0.03   \n",
       "61246   1607.72   1430.56  ...    2388.48    8193.94     8.2525       0.03   \n",
       "61247   1381.29   1148.18  ...    2388.83    8125.64     9.0515       0.02   \n",
       "61248   1369.75   1147.45  ...    2388.66    8144.33     9.1207       0.02   \n",
       "\n",
       "       Sensor 17  Sensor 18  Sensor 19  Sensor 20  Sensor 21  RUL  \n",
       "61244        372       2319      100.0      29.11    17.5234    4  \n",
       "61245        396       2388      100.0      39.38    23.7151    3  \n",
       "61246        395       2388      100.0      39.78    23.8270    2  \n",
       "61247        337       2223      100.0      15.26     9.0774    1  \n",
       "61248        333       2212      100.0      10.66     6.4341    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_Merged_derivedRUL.csv\",index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noise = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/NASA_Dataset_Turbofan Engine Degradation Simulation/CMAPSSData/train_FD003.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unit Number</th>\n",
       "      <th>Cycles Time</th>\n",
       "      <th>Operational Setting 1</th>\n",
       "      <th>Operational Setting 2</th>\n",
       "      <th>Operational Setting 3</th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 13</th>\n",
       "      <th>Sensor 14</th>\n",
       "      <th>Sensor 15</th>\n",
       "      <th>Sensor 16</th>\n",
       "      <th>Sensor 17</th>\n",
       "      <th>Sensor 18</th>\n",
       "      <th>Sensor 19</th>\n",
       "      <th>Sensor 20</th>\n",
       "      <th>Sensor 21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.36</td>\n",
       "      <td>1583.23</td>\n",
       "      <td>1396.84</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>8145.32</td>\n",
       "      <td>8.4246</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.11</td>\n",
       "      <td>23.3537</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.50</td>\n",
       "      <td>1584.69</td>\n",
       "      <td>1396.89</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8152.85</td>\n",
       "      <td>8.4403</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4491</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.18</td>\n",
       "      <td>1582.35</td>\n",
       "      <td>1405.61</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8150.17</td>\n",
       "      <td>8.3901</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.85</td>\n",
       "      <td>23.3669</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.92</td>\n",
       "      <td>1585.61</td>\n",
       "      <td>1392.27</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8146.56</td>\n",
       "      <td>8.3878</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.96</td>\n",
       "      <td>23.2951</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.68</td>\n",
       "      <td>1588.63</td>\n",
       "      <td>1397.65</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8147.80</td>\n",
       "      <td>8.3869</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.14</td>\n",
       "      <td>23.4583</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unit Number  Cycles Time  Operational Setting 1  \\\n",
       "0           0            1            1                -0.0005   \n",
       "1           1            1            2                 0.0008   \n",
       "2           2            1            3                -0.0014   \n",
       "3           3            1            4                -0.0020   \n",
       "4           4            1            5                 0.0016   \n",
       "\n",
       "   Operational Setting 2  Operational Setting 3  Sensor 1  Sensor 2  Sensor 3  \\\n",
       "0                 0.0004                  100.0    518.67    642.36   1583.23   \n",
       "1                -0.0003                  100.0    518.67    642.50   1584.69   \n",
       "2                -0.0002                  100.0    518.67    642.18   1582.35   \n",
       "3                 0.0001                  100.0    518.67    642.92   1585.61   \n",
       "4                 0.0000                  100.0    518.67    641.68   1588.63   \n",
       "\n",
       "   Sensor 4  ...  Sensor 13  Sensor 14  Sensor 15  Sensor 16  Sensor 17  \\\n",
       "0   1396.84  ...    2388.01    8145.32     8.4246       0.03        391   \n",
       "1   1396.89  ...    2388.03    8152.85     8.4403       0.03        392   \n",
       "2   1405.61  ...    2388.00    8150.17     8.3901       0.03        391   \n",
       "3   1392.27  ...    2388.08    8146.56     8.3878       0.03        392   \n",
       "4   1397.65  ...    2388.03    8147.80     8.3869       0.03        392   \n",
       "\n",
       "   Sensor 18  Sensor 19  Sensor 20  Sensor 21  RUL  \n",
       "0       2388      100.0      39.11    23.3537   44  \n",
       "1       2388      100.0      38.99    23.4491   44  \n",
       "2       2388      100.0      38.85    23.3669   44  \n",
       "3       2388      100.0      38.96    23.2951   44  \n",
       "4       2388      100.0      39.14    23.4583   44  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1, ..., 100, 100, 100], dtype=int64)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit =np.array(df_noise['Unit Number'])\n",
    "#for i in range(0,101):\n",
    "unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259, 253, 222, 272, 213, 278, 424, 267, 406, 481, 197, 170, 185, 207, 202, 344, 312, 447, 229, 338, 220, 192, 196, 494, 193, 243, 320, 200, 223, 218, 183, 189, 231, 459, 231, 324, 324, 201, 288, 188, 295, 193, 321, 180, 205, 204, 269, 174, 256, 161, 190, 222, 164, 194, 525, 195, 215, 178, 299, 190, 199, 246, 231, 195, 234, 165, 263, 201, 170, 172, 409, 232, 215, 193, 259, 153, 255, 221, 166, 147, 347, 285, 181, 226, 266, 341, 172, 322, 207, 181, 156, 158, 171, 392, 166, 491, 275, 307, 145, 152] 100\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for j in range(1,101):  # for FD001 range(1,101), for FD002 range(1,261), for FD003 range(1,101), for FD004 range (1,250) \n",
    "    count = 0\n",
    "    for i in unit:\n",
    "        if(i==j):\n",
    "            count +=1\n",
    "    l.append(count)\n",
    "print(l,len(l))  \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensor1 = np.array(df_noise['Sensor 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([518.67, 518.67, 518.67, ..., 518.67, 518.67, 518.67])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[518.6699999999988, 518.6699999999986, 518.6699999999985, 518.6699999999995, 518.6699999999985, 518.6699999999998, 518.6700000000043, 518.6699999999993, 518.6700000000039, 518.6700000000053, 518.6699999999986, 518.6699999999986, 518.6699999999986, 518.6699999999985, 518.6699999999986, 518.6700000000023, 518.6700000000012, 518.6700000000047, 518.6699999999985, 518.6700000000021, 518.6699999999985, 518.6699999999986, 518.6699999999986, 518.6700000000055, 518.6699999999986, 518.6699999999985, 518.6700000000016, 518.6699999999986, 518.6699999999985, 518.6699999999985, 518.6699999999986, 518.6699999999986, 518.6699999999985, 518.670000000005, 518.6699999999985, 518.6700000000017, 518.6700000000017, 518.6699999999986, 518.6700000000003, 518.6699999999986, 518.6700000000005, 518.6699999999986, 518.6700000000016, 518.6699999999986, 518.6699999999985, 518.6699999999986, 518.6699999999994, 518.6699999999986, 518.6699999999987, 518.6699999999986, 518.6699999999986, 518.6699999999985, 518.6699999999986, 518.6699999999986, 518.6700000000048, 518.6699999999986, 518.6699999999985, 518.6699999999986, 518.6700000000008, 518.6699999999986, 518.6699999999986, 518.6699999999985, 518.6699999999985, 518.6699999999986, 518.6699999999985, 518.6699999999986, 518.669999999999, 518.6699999999986, 518.6699999999986, 518.6699999999986, 518.6700000000039, 518.6699999999985, 518.6699999999985, 518.6699999999986, 518.6699999999988, 518.6699999999986, 518.6699999999987, 518.6699999999985, 518.6699999999986, 518.6699999999986, 518.6700000000025, 518.6700000000002, 518.6699999999986, 518.6699999999985, 518.6699999999993, 518.6700000000022, 518.6699999999986, 518.6700000000016, 518.6699999999985, 518.6699999999986, 518.6699999999986, 518.6699999999986, 518.6699999999986, 518.6700000000036, 518.6699999999986, 518.6700000000054, 518.6699999999997, 518.6700000000011, 518.6699999999987, 518.6699999999986] 100\n"
     ]
    }
   ],
   "source": [
    "l1=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor1[j]\n",
    "    l1.append(k/l[i])\n",
    "print(l1,len(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = pd.DataFrame(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  518.67\n",
       "1  518.67\n",
       "2  518.67\n",
       "3  518.67\n",
       "4  518.67"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "95  518.67\n",
       "96  518.67\n",
       "97  518.67\n",
       "98  518.67\n",
       "99  518.67"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg=df_avg.rename(columns={0: \"Sensor1_Avg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg\n",
       "0       518.67\n",
       "1       518.67\n",
       "2       518.67\n",
       "3       518.67\n",
       "4       518.67"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[642.5733204633208, 642.5460869565221, 642.4285585585587, 642.5523897058827, 642.4047417840379, 642.5372302158275, 642.3654716981133, 642.5625842696633, 642.3761330049261, 642.3696049896049, 642.3708629441624, 642.3341176470586, 642.3467027027025, 642.3902898550725, 642.3752970297029, 642.431104651163, 642.4818589743592, 642.3590604026845, 642.4579475982537, 642.4378106508877, 642.421681818182, 642.3624999999998, 642.3688265306122, 642.3782388663966, 642.3643005181345, 642.5044444444449, 642.4710625000001, 642.3737999999998, 642.4315246636774, 642.418165137615, 642.3438251366118, 642.3570899470898, 642.4635930735934, 642.3635729847492, 642.4635930735934, 642.4646604938273, 642.4646604938273, 642.374278606965, 642.5211111111115, 642.3576063829786, 642.5111186440681, 642.3643005181345, 642.4693457943927, 642.3466666666666, 642.3830731707317, 642.3798529411764, 642.5584386617104, 642.3352873563216, 642.5600390625003, 642.3229813664594, 642.3610526315788, 642.4285585585587, 642.3292682926826, 642.3643814432988, 642.3999428571427, 642.3677435897434, 642.4091627906979, 642.3391011235954, 642.5044147157193, 642.3610526315788, 642.3710552763819, 642.5176016260166, 642.4635930735934, 642.3677435897434, 642.4758974358978, 642.3283030303028, 642.5653612167304, 642.374278606965, 642.3341176470586, 642.3360465116276, 642.3737163814181, 642.4678017241383, 642.4091627906979, 642.3643005181345, 642.5733204633208, 642.3136601307187, 642.5550196078435, 642.4258823529415, 642.3287951807226, 642.3054421768707, 642.4277521613835, 642.5274385964916, 642.3464640883976, 642.4449557522126, 642.5630827067672, 642.4345454545457, 642.3360465116276, 642.4673602484473, 642.3902898550725, 642.3464640883976, 642.3208333333332, 642.3202531645568, 642.3345614035086, 642.3830102040819, 642.3287951807226, 642.3771690427698, 642.5452000000002, 642.4906840390881, 642.299172413793, 642.310394736842] 100\n"
     ]
    }
   ],
   "source": [
    "Sensor2 = np.array(df_noise['Sensor 2'])\n",
    "l2=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor2[j]\n",
    "    l2.append(k/l[i])\n",
    "print(l2,len(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg[\"Sensor2_Avg\"]=l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg\n",
       "0       518.67   642.573320\n",
       "1       518.67   642.546087\n",
       "2       518.67   642.428559\n",
       "3       518.67   642.552390\n",
       "4       518.67   642.404742"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1589.2270270270278, 1588.92881422925, 1587.8373423423436, 1588.9545220588243, 1587.5224413145552, 1588.800575539569, 1586.7937971698136, 1589.0518726591768, 1586.8505418719233, 1586.9538669438687, 1586.934365482234, 1586.4210000000003, 1586.7345405405408, 1587.3285507246385, 1587.1029207920799, 1587.5156104651173, 1588.0080128205134, 1586.7277181208076, 1588.132227074237, 1587.5578994082848, 1587.7729545454558, 1586.8479166666673, 1586.91306122449, 1587.1684615384636, 1586.8645595854928, 1588.5892592592604, 1587.8527812500008, 1587.0438000000006, 1587.8869506726471, 1587.7042660550471, 1586.7243715846998, 1586.8199470899476, 1588.2022510822524, 1586.75209150327, 1588.2022510822524, 1587.7731172839515, 1587.7731172839515, 1587.063582089553, 1588.4483680555563, 1586.7894148936175, 1588.2762372881364, 1586.8645595854928, 1587.8389096573217, 1586.653555555556, 1587.2613658536595, 1587.186519607844, 1589.0003345724915, 1586.6142528735636, 1589.070664062501, 1586.2564596273296, 1586.8376315789478, 1587.8373423423436, 1586.2821341463418, 1586.867164948454, 1587.4786666666687, 1586.889692307693, 1587.5939534883732, 1586.6700000000003, 1588.2432441471578, 1586.8376315789478, 1587.001507537689, 1588.7017886178874, 1588.2022510822524, 1586.889692307693, 1588.312905982907, 1586.28096969697, 1589.1260076045635, 1587.063582089553, 1586.4210000000003, 1586.494244186047, 1586.8460391198068, 1588.2355172413806, 1587.5939534883732, 1586.8645595854928, 1589.2270270270278, 1586.014117647059, 1589.0305098039225, 1587.8028506787343, 1586.3298192771088, 1585.9158503401363, 1587.497521613834, 1588.5575087719308, 1586.6791712707186, 1588.0542920353996, 1589.0483458646625, 1587.530439882699, 1586.494244186047, 1587.8150310559015, 1587.3285507246385, 1586.6791712707186, 1586.0932051282055, 1586.1584810126585, 1586.4298245614038, 1586.922882653063, 1586.3298192771088, 1587.112851323831, 1588.8754545454553, 1588.0881433224763, 1585.8577241379312, 1586.0025000000003] 100\n"
     ]
    }
   ],
   "source": [
    "Sensor3 = np.array(df_noise['Sensor 3'])\n",
    "l3=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor3[j]\n",
    "    l3.append(k/l[i])\n",
    "print(l3,len(l3))\n",
    "df_avg[\"Sensor3_Avg\"]=l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg\n",
       "0       518.67   642.573320  1589.227027\n",
       "1       518.67   642.546087  1588.928814\n",
       "2       518.67   642.428559  1587.837342\n",
       "3       518.67   642.552390  1588.954522\n",
       "4       518.67   642.404742  1587.522441"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1406.5979150579158, 1406.0786166007913, 1403.7329729729734, 1406.0010294117653, 1403.1687323943665, 1405.775575539569, 1402.5327122641502, 1406.2271161048695, 1402.687684729064, 1402.5531185031175, 1402.2733502538067, 1401.3529411764707, 1401.750324324324, 1402.823236714976, 1402.545099009901, 1403.6902034883722, 1404.603141025641, 1402.3798210290822, 1404.1811353711794, 1403.8527810650887, 1403.552863636364, 1402.0157812499995, 1402.2328571428566, 1402.8171457489866, 1402.1028497409322, 1405.2579835390954, 1404.3804375, 1402.4625499999997, 1403.765739910314, 1403.4124770642206, 1401.7296174863388, 1401.8851851851848, 1404.3207792207795, 1402.4074509803918, 1404.3207792207795, 1404.2491975308642, 1404.2491975308642, 1402.4988557213928, 1405.390381944445, 1401.884734042553, 1405.1820677966105, 1402.1028497409322, 1404.3452959501556, 1401.6106666666667, 1402.737512195122, 1402.682205882353, 1406.1664312267665, 1401.460459770115, 1406.3200390625007, 1400.9086335403729, 1401.9018947368418, 1403.7329729729734, 1401.0415243902441, 1402.1201030927832, 1403.3366666666652, 1402.2024615384612, 1403.2852558139539, 1401.553202247191, 1405.050434782609, 1401.9018947368418, 1402.4006532663313, 1405.517764227643, 1404.3207792207795, 1402.2024615384612, 1404.534743589744, 1401.0642424242426, 1406.3955893536129, 1402.4988557213928, 1401.3529411764707, 1401.4258139534884, 1402.6532518337406, 1404.3987068965523, 1403.2852558139539, 1402.1028497409322, 1406.5979150579158, 1400.5432026143797, 1406.251764705883, 1403.6418099547516, 1401.117168674699, 1400.382585034014, 1403.650720461095, 1405.5051929824567, 1401.599005524862, 1403.9705752212392, 1406.2633082706775, 1403.7888856304985, 1401.4258139534884, 1404.3219875776397, 1402.823236714976, 1401.599005524862, 1400.6543589743594, 1400.7256329113927, 1401.3605847953218, 1402.8540306122447, 1401.117168674699, 1402.7460692464344, 1405.870254545455, 1404.7671335504886, 1400.2993793103456, 1400.5216447368425] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg\n",
       "0       518.67   642.573320  1589.227027  1406.597915\n",
       "1       518.67   642.546087  1588.928814  1406.078617\n",
       "2       518.67   642.428559  1587.837342  1403.732973\n",
       "3       518.67   642.552390  1588.954522  1406.001029\n",
       "4       518.67   642.404742  1587.522441  1403.168732"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor4 = np.array(df_noise['Sensor 4'])\n",
    "l4=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor4[j]\n",
    "    l4.append(k/l[i])\n",
    "print(l4,len(l4))\n",
    "df_avg[\"Sensor4_Avg\"]=l4\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.619999999999923, 14.619999999999923, 14.619999999999928, 14.619999999999921, 14.61999999999993, 14.619999999999921, 14.61999999999991, 14.619999999999921, 14.61999999999991, 14.619999999999909, 14.619999999999932, 14.619999999999939, 14.619999999999935, 14.61999999999993, 14.619999999999932, 14.619999999999914, 14.619999999999918, 14.619999999999909, 14.619999999999926, 14.619999999999916, 14.619999999999928, 14.619999999999933, 14.619999999999933, 14.619999999999907, 14.619999999999933, 14.619999999999925, 14.619999999999916, 14.619999999999932, 14.619999999999928, 14.619999999999928, 14.619999999999935, 14.619999999999933, 14.619999999999926, 14.619999999999909, 14.619999999999926, 14.619999999999916, 14.619999999999916, 14.619999999999932, 14.61999999999992, 14.619999999999935, 14.61999999999992, 14.619999999999933, 14.619999999999916, 14.619999999999937, 14.61999999999993, 14.619999999999932, 14.619999999999921, 14.619999999999937, 14.619999999999923, 14.619999999999942, 14.619999999999933, 14.619999999999928, 14.61999999999994, 14.619999999999933, 14.619999999999907, 14.619999999999933, 14.619999999999928, 14.619999999999937, 14.619999999999918, 14.619999999999933, 14.619999999999932, 14.619999999999925, 14.619999999999926, 14.619999999999933, 14.619999999999926, 14.61999999999994, 14.619999999999923, 14.619999999999932, 14.619999999999939, 14.619999999999939, 14.61999999999991, 14.619999999999926, 14.619999999999928, 14.619999999999933, 14.619999999999923, 14.619999999999944, 14.619999999999923, 14.619999999999928, 14.61999999999994, 14.619999999999946, 14.619999999999914, 14.61999999999992, 14.619999999999935, 14.619999999999926, 14.619999999999921, 14.619999999999916, 14.619999999999939, 14.619999999999916, 14.61999999999993, 14.619999999999935, 14.619999999999944, 14.619999999999942, 14.619999999999939, 14.619999999999912, 14.61999999999994, 14.619999999999907, 14.619999999999921, 14.619999999999918, 14.619999999999948, 14.619999999999944] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62\n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62\n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62\n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62\n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor5 = np.array(df_noise['Sensor 5'])\n",
    "l5=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor5[j]\n",
    "    l5.append(k/l[i])\n",
    "print(l5,len(l5))\n",
    "df_avg[\"Sensor5_Avg\"]=l5\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.609652509652452, 21.60964426877465, 21.609594594594583, 21.60812499999994, 21.60957746478873, 21.607446043165407, 21.59629716981122, 21.60872659176024, 21.597315270935862, 21.593929313929205, 21.60954314720815, 21.609470588235325, 21.60951351351355, 21.609565217391314, 21.60955445544556, 21.6013081395348, 21.604070512820442, 21.59527964205806, 21.609606986899543, 21.601745562130095, 21.6095909090909, 21.609531250000035, 21.60954081632656, 21.593522267206367, 21.609533678756513, 21.60962962962959, 21.603343749999926, 21.609550000000024, 21.60959641255604, 21.609587155963297, 21.60950819672135, 21.60952380952385, 21.609610389610364, 21.594705882352834, 21.609610389610364, 21.602962962962888, 21.602962962962888, 21.60955223880599, 21.606388888888823, 21.609521276595785, 21.60569491525417, 21.609533678756513, 21.60323987538933, 21.609500000000036, 21.60956097560977, 21.609558823529426, 21.608475836431168, 21.60948275862072, 21.609648437499946, 21.609440993788844, 21.609526315789513, 21.609594594594583, 21.609451219512223, 21.60953608247426, 21.59342857142848, 21.60953846153849, 21.609581395348833, 21.609494382022508, 21.605284280936388, 21.609526315789513, 21.60954773869349, 21.60963414634142, 21.609610389610364, 21.60953846153849, 21.609615384615356, 21.60945454545457, 21.609163498098802, 21.60955223880599, 21.609470588235325, 21.60947674418608, 21.59711491442533, 21.60961206896549, 21.609581395348833, 21.609533678756513, 21.609652509652452, 21.6094117647059, 21.609647058823477, 21.609592760180984, 21.60945783132533, 21.609387755102055, 21.60109510086447, 21.6066666666666, 21.609502762430974, 21.609601769911485, 21.608834586466106, 21.601524926686135, 21.60947674418608, 21.603136645962657, 21.609565217391314, 21.609502762430974, 21.609423076923097, 21.609430379746858, 21.609473684210556, 21.598112244897862, 21.60945783132533, 21.593625254582378, 21.607781818181756, 21.604495114006443, 21.609379310344842, 21.60940789473686] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  \n",
       "0    21.609653  \n",
       "1    21.609644  \n",
       "2    21.609595  \n",
       "3    21.608125  \n",
       "4    21.609577  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor6 = np.array(df_noise['Sensor 6'])\n",
    "l6=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor6[j]\n",
    "    l6.append(k/l[i])\n",
    "print(l6,len(l6))\n",
    "df_avg[\"Sensor6_Avg\"]=l6\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[553.6131660231658, 553.6571146245057, 553.8741441441439, 553.6102573529411, 553.9265727699529, 553.6116546762589, 553.8451650943393, 553.6143445692882, 553.7699014778321, 554.3761330561326, 554.0173096446699, 554.1417058823527, 554.0755135135133, 553.957536231884, 553.9918811881188, 553.6226744186043, 553.6121474358972, 554.0003803131987, 553.8304803493447, 553.6178402366862, 553.8856818181816, 554.04328125, 554.0236224489795, 554.5937044534409, 554.0391191709843, 553.7375308641973, 553.6189062499998, 554.00335, 553.8668609865468, 553.895596330275, 554.0810928961747, 554.054074074074, 553.8199567099564, 554.10688453159, 553.8199567099564, 553.6186111111109, 553.6186111111109, 553.9976119402985, 553.6130902777776, 554.0579787234042, 553.6023050847457, 554.0391191709843, 553.6207165109032, 554.0902777777775, 553.9709268292681, 553.9778921568626, 553.6143866171002, 554.1245977011491, 553.6363281249997, 554.1742236024842, 554.0498421052631, 553.8741441441439, 554.1555487804875, 554.033092783505, 554.9963809523804, 554.0293846153845, 553.9164651162789, 554.0998314606738, 553.6001337792641, 554.0498421052631, 554.00608040201, 553.7136178861787, 553.8199567099564, 554.0293846153845, 553.7974358974357, 554.154727272727, 553.613384030418, 553.9976119402985, 554.1417058823527, 554.1334302325579, 553.7812469437649, 553.8128879310342, 553.9164651162789, 554.0391191709843, 553.6131660231658, 554.210653594771, 553.6440784313722, 553.8801809954749, 554.1518674698792, 554.2218367346937, 553.6259654178672, 553.6122456140349, 554.0870165745854, 553.8496902654865, 553.6133834586465, 553.6219061583575, 554.1334302325579, 553.6192236024843, 553.957536231884, 554.0870165745854, 554.1944871794869, 554.1843037974681, 554.1399415204676, 553.7167602040813, 554.1518674698792, 554.5383503054985, 553.6103272727272, 553.6044299674267, 554.228344827586, 554.2161184210523] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  \n",
       "0    21.609653   553.613166  \n",
       "1    21.609644   553.657115  \n",
       "2    21.609595   553.874144  \n",
       "3    21.608125   553.610257  \n",
       "4    21.609577   553.926573  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor7 = np.array(df_noise['Sensor 7'])\n",
    "l7=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor7[j]\n",
    "    l7.append(k/l[i])\n",
    "print(l7,len(l7))\n",
    "df_avg[\"Sensor7_Avg\"]=l7\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2388.0647876447883, 2388.060316205534, 2388.0437387387406, 2388.0597794117652, 2388.039154929579, 2388.0577697841727, 2388.0331603773575, 2388.0616853932593, 2388.0333743842352, 2388.043284823284, 2388.0333502538083, 2388.024294117648, 2388.029567567569, 2388.0367632850257, 2388.03485148515, 2388.039999999999, 2388.0477884615384, 2388.034876957495, 2388.0466812227096, 2388.0415384615376, 2388.0425909090923, 2388.031822916668, 2388.032857142858, 2388.0493117408905, 2388.03202072539, 2388.054032921812, 2388.0457499999993, 2388.0342000000014, 2388.043991031392, 2388.041146788992, 2388.028907103826, 2388.030687830689, 2388.047575757578, 2388.0364488017444, 2388.047575757578, 2388.0448456790114, 2388.0448456790114, 2388.034577114429, 2388.0549305555555, 2388.030425531916, 2388.0527457627118, 2388.03202072539, 2388.045451713395, 2388.02788888889, 2388.0359512195137, 2388.0355882352956, 2388.0608550185884, 2388.0258045977025, 2388.0623828125003, 2388.020869565218, 2388.0310000000013, 2388.0437387387406, 2388.0226829268304, 2388.032113402063, 2388.0618285714277, 2388.0326153846163, 2388.039906976746, 2388.0270224719116, 2388.0515384615383, 2388.0310000000013, 2388.033819095479, 2388.055853658538, 2388.047575757578, 2388.0326153846163, 2388.049102564105, 2388.02290909091, 2388.063155893537, 2388.034577114429, 2388.024294117648, 2388.0249418604662, 2388.0332029339843, 2388.04806034483, 2388.039906976746, 2388.03202072539, 2388.0647876447883, 2388.0190849673204, 2388.0618823529417, 2388.043167420816, 2388.0230120481933, 2388.0174829931975, 2388.0396541786736, 2388.0557894736844, 2388.0283977900563, 2388.0452654867277, 2388.0619548872187, 2388.0407038123158, 2388.0249418604662, 2388.0453105590054, 2388.0367632850257, 2388.0283977900563, 2388.0198717948724, 2388.0200632911396, 2388.0246783625744, 2388.03369897959, 2388.0230120481933, 2388.0476985743376, 2388.0588000000002, 2388.0493159609114, 2388.0168275862075, 2388.0189473684213] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  \n",
       "0    21.609653   553.613166  2388.064788  \n",
       "1    21.609644   553.657115  2388.060316  \n",
       "2    21.609595   553.874144  2388.043739  \n",
       "3    21.608125   553.610257  2388.059779  \n",
       "4    21.609577   553.926573  2388.039155  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor8 = np.array(df_noise['Sensor 8'])\n",
    "l8=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor8[j]\n",
    "    l8.append(k/l[i])\n",
    "print(l8,len(l8))\n",
    "df_avg[\"Sensor8_Avg\"]=l8\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9071.174208494203, 9071.030434782604, 9070.434054054047, 9070.184007352937, 9070.338638497647, 9069.67338129496, 9063.779551886793, 9070.550524344564, 9064.027955665026, 9064.768253638262, 9070.236142131975, 9069.819764705875, 9069.924540540533, 9070.26710144927, 9070.219059405936, 9065.964651162793, 9067.583653846154, 9063.833109619687, 9070.629563318771, 9066.255000000001, 9070.409090909085, 9070.100520833326, 9070.205459183668, 9065.56354251013, 9070.114922279785, 9070.888024691352, 9067.13171875, 9070.231749999994, 9070.477040358737, 9070.42041284403, 9069.867158469939, 9069.993809523803, 9070.678701298695, 9064.047864923748, 9070.678701298695, 9066.948302469138, 9066.948302469138, 9070.185124378104, 9068.982499999998, 9069.990159574461, 9068.563864406779, 9070.114922279785, 9067.074361370718, 9069.92027777777, 9070.229756097555, 9070.21897058823, 9070.417137546463, 9069.868965517233, 9071.072539062496, 9069.79639751552, 9070.016894736835, 9070.434054054047, 9069.796707317066, 9070.175412371127, 9066.87078095239, 9070.200769230763, 9070.357302325576, 9069.908820224711, 9068.310200668897, 9070.016894736835, 9070.234572864316, 9070.96796747967, 9070.678701298695, 9070.200769230763, 9070.776880341875, 9069.820848484842, 9070.87395437262, 9070.185124378104, 9069.819764705875, 9069.843488372086, 9063.967139364304, 9070.711637931028, 9070.357302325576, 9070.114922279785, 9071.174208494203, 9069.714313725484, 9071.074235294112, 9070.418416289587, 9069.778614457824, 9069.614081632646, 9065.812737752163, 9069.17143859649, 9069.886408839773, 9070.579380530968, 9070.619473684206, 9066.11237536657, 9069.843488372086, 9067.033633540374, 9070.26710144927, 9069.886408839773, 9069.738269230762, 9069.728291139234, 9069.832748538005, 9064.24492346939, 9069.778614457824, 9065.344134419562, 9069.905781818177, 9067.839250814332, 9069.575241379305, 9069.69276315789] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  \n",
       "0    21.609653   553.613166  2388.064788  9071.174208  \n",
       "1    21.609644   553.657115  2388.060316  9071.030435  \n",
       "2    21.609595   553.874144  2388.043739  9070.434054  \n",
       "3    21.608125   553.610257  2388.059779  9070.184007  \n",
       "4    21.609577   553.926573  2388.039155  9070.338638  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor9 = np.array(df_noise['Sensor 9'])\n",
    "l9=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor9[j]\n",
    "    l9.append(k/l[i])\n",
    "print(l9,len(l9))\n",
    "df_avg[\"Sensor9_Avg\"]=l9\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3000000000000063, 1.3000000000000063, 1.3000000000000054, 1.3000000000000065, 1.3000000000000052, 1.3000000000000067, 1.300000000000004, 1.3000000000000065, 1.3000000000000063, 1.3003534303534283, 1.3000000000000047, 1.3000000000000036, 1.3000000000000043, 1.3000000000000052, 1.300000000000005, 1.3000000000000076, 1.3000000000000071, 1.3000000000000016, 1.3000000000000056, 1.3000000000000076, 1.3000000000000054, 1.3000000000000045, 1.3000000000000047, 1.3006072874493892, 1.3000000000000045, 1.300000000000006, 1.3000000000000074, 1.300000000000005, 1.3000000000000056, 1.3000000000000054, 1.3000000000000043, 1.3000000000000045, 1.3000000000000058, 1.300021786492375, 1.3000000000000058, 1.3000000000000074, 1.3000000000000074, 1.300000000000005, 1.300000000000007, 1.3000000000000045, 1.300000000000007, 1.3000000000000045, 1.3000000000000074, 1.300000000000004, 1.300000000000005, 1.300000000000005, 1.3000000000000065, 1.3000000000000038, 1.3000000000000063, 1.3000000000000032, 1.3000000000000045, 1.3000000000000054, 1.3000000000000034, 1.3000000000000047, 1.3009333333333273, 1.3000000000000047, 1.3000000000000054, 1.300000000000004, 1.300000000000007, 1.3000000000000045, 1.3000000000000047, 1.300000000000006, 1.3000000000000058, 1.3000000000000047, 1.3000000000000058, 1.3000000000000034, 1.3000000000000065, 1.300000000000005, 1.3000000000000036, 1.3000000000000038, 1.300000000000006, 1.3000000000000058, 1.3000000000000054, 1.3000000000000045, 1.3000000000000063, 1.300000000000003, 1.3000000000000063, 1.3000000000000054, 1.3000000000000036, 1.3000000000000025, 1.3000000000000076, 1.3000000000000067, 1.300000000000004, 1.3000000000000056, 1.3000000000000065, 1.3000000000000076, 1.3000000000000038, 1.3000000000000074, 1.3000000000000052, 1.300000000000004, 1.300000000000003, 1.3000000000000032, 1.3000000000000038, 1.300000000000008, 1.3000000000000036, 1.300549898167003, 1.3000000000000067, 1.3000000000000071, 1.3000000000000023, 1.3000000000000027] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3  \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3  \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3  \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3  \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor10 = np.array(df_noise['Sensor 10'])\n",
    "l10=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor10[j]\n",
    "    l10.append(k/l[i])\n",
    "print(l10,len(l10))\n",
    "df_avg[\"Sensor10_Avg\"]=l10\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.46204633204632, 47.445296442687734, 47.37585585585584, 47.44356617647058, 47.36173708920187, 47.43499999999999, 47.333254716981116, 47.44999999999999, 47.33583743842363, 47.34257796257793, 47.339187817258875, 47.29994117647058, 47.31940540540542, 47.3530917874396, 47.34613861386138, 47.36886627906975, 47.395416666666655, 47.331812080536885, 47.38917030567684, 47.37423076923075, 47.371954545454535, 47.331041666666664, 47.33683673469387, 47.35311740890686, 47.33310880829015, 47.419341563786, 47.389187499999984, 47.34309999999999, 47.37874439461882, 47.36880733944953, 47.31617486338798, 47.32661375661377, 47.393030303030294, 47.33302832244007, 47.393030303030294, 47.38506172839505, 47.38506172839505, 47.34452736318407, 47.42197916666665, 47.324627659574475, 47.413491525423716, 47.33310880829015, 47.38809968847351, 47.31188888888889, 47.34917073170731, 47.34833333333332, 47.447992565055756, 47.305574712643676, 47.453359374999984, 47.29124223602484, 47.32778947368421, 47.37585585585584, 47.294207317073166, 47.33474226804123, 47.373066666666645, 47.33528205128205, 47.36395348837208, 47.3088202247191, 47.40856187290968, 47.32778947368421, 47.342010050251254, 47.42699186991869, 47.393030303030294, 47.33528205128205, 47.39927350427349, 47.29424242424242, 47.45714828897338, 47.34452736318407, 47.29994117647058, 47.30238372093023, 47.334718826405854, 47.39482758620688, 47.36395348837208, 47.33310880829015, 47.46204633204632, 47.283529411764704, 47.45101960784312, 47.37389140271492, 47.295602409638555, 47.27836734693878, 47.36717579250718, 47.42547368421051, 47.313867403314916, 47.383141592920346, 47.45191729323307, 47.37217008797652, 47.30238372093023, 47.38695652173912, 47.3530917874396, 47.313867403314916, 47.28628205128205, 47.287531645569615, 47.30122807017543, 47.34158163265305, 47.295602409638555, 47.35040733197553, 47.439636363636346, 47.400065146579784, 47.27717241379311, 47.28046052631579] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  \n",
       "0     47.462046  \n",
       "1     47.445296  \n",
       "2     47.375856  \n",
       "3     47.443566  \n",
       "4     47.361737  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor11 = np.array(df_noise['Sensor 11'])\n",
    "l11=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor11[j]\n",
    "    l11.append(k/l[i])\n",
    "print(l11,len(l11))\n",
    "df_avg[\"Sensor11_Avg\"]=l11\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[521.6665637065637, 521.7103162055336, 521.8921171171172, 521.6665073529412, 521.9357276995306, 521.665035971223, 521.8559905660376, 521.6667415730336, 521.7864039408867, 522.3434719334716, 522.0138578680205, 522.0937647058824, 522.0462702702704, 521.9614009661838, 521.9908415841586, 521.6659593023254, 521.6616025641026, 521.9929082774048, 521.852227074236, 521.6648816568046, 521.9035909090911, 522.0273958333336, 522.0148469387757, 522.5519838056678, 522.02585492228, 521.7762139917696, 521.66803125, 521.9976000000003, 521.8856950672647, 521.9110091743121, 522.0518032786887, 522.0339153439155, 521.8451082251083, 522.0912200435728, 521.8451082251083, 521.6649074074073, 521.6649074074073, 521.9951741293535, 521.6622569444445, 522.0362234042555, 521.6638644067797, 522.02585492228, 521.6667912772585, 522.0613333333334, 521.9746341463417, 521.9782843137258, 521.6669516728624, 522.0852873563219, 521.6905078125, 522.1191925465839, 522.0319473684212, 521.8921171171172, 522.1095731707318, 522.021082474227, 522.928438095238, 522.0178974358976, 521.9265116279071, 522.0698876404496, 521.6634448160535, 522.0319473684212, 522.0018090452263, 521.7574796747967, 521.8451082251083, 522.0178974358976, 521.8270512820515, 522.1058181818183, 521.6663498098859, 521.9951741293535, 522.0937647058824, 522.0853488372094, 521.7958924205378, 521.838879310345, 521.9265116279071, 522.02585492228, 521.6665637065637, 522.1380392156865, 521.6975686274509, 521.8977375565613, 522.1035542168676, 522.1497959183675, 521.6693371757924, 521.6626666666666, 522.0583977900553, 521.8658849557523, 521.6664661654136, 521.6650439882696, 522.0853488372094, 521.666552795031, 521.9614009661838, 522.0583977900553, 522.1378205128207, 522.1331012658229, 522.0892982456141, 521.7411989795918, 522.1035542168676, 522.500244399185, 521.6655272727272, 521.658306188925, 522.1585517241382, 522.1376315789475] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  \n",
       "0     47.462046    521.666564  \n",
       "1     47.445296    521.710316  \n",
       "2     47.375856    521.892117  \n",
       "3     47.443566    521.666507  \n",
       "4     47.361737    521.935728  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor12 = np.array(df_noise['Sensor 12'])\n",
    "l12=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor12[j]\n",
    "    l12.append(k/l[i])\n",
    "print(l12,len(l12))\n",
    "df_avg[\"Sensor12_Avg\"]=l12\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2388.0647876447865, 2388.0607114624495, 2388.0427927927926, 2388.060110294115, 2388.0385915492957, 2388.057985611508, 2388.0340801886746, 2388.06172284644, 2388.03440886699, 2388.0439085239045, 2388.0317766497465, 2388.0242941176475, 2388.028162162162, 2388.035797101449, 2388.033910891089, 2388.0407848837162, 2388.04833333333, 2388.0355257270658, 2388.0469868995633, 2388.0420118343154, 2388.0422272727274, 2388.0305208333334, 2388.0317346938778, 2388.050910931171, 2388.030932642487, 2388.054526748971, 2388.0464374999965, 2388.0332, 2388.043408071749, 2388.0412844036696, 2388.0275956284154, 2388.029417989418, 2388.048051948052, 2388.037342047928, 2388.048051948052, 2388.0453703703665, 2388.0453703703665, 2388.033432835821, 2388.0547222222185, 2388.0291489361703, 2388.052745762708, 2388.030932642487, 2388.0462928348875, 2388.0263333333337, 2388.0348292682925, 2388.034607843137, 2388.0611895910756, 2388.0245977011496, 2388.062812499999, 2388.02149068323, 2388.0296315789474, 2388.0427927927926, 2388.0226829268295, 2388.031082474227, 2388.0633142857114, 2388.031487179487, 2388.0396744186046, 2388.0256179775283, 2388.0517725752475, 2388.0296315789474, 2388.032814070352, 2388.0564634146335, 2388.048051948052, 2388.031487179487, 2388.0492307692307, 2388.0227272727275, 2388.06342205323, 2388.033432835821, 2388.0242941176475, 2388.0244186046516, 2388.034229828846, 2388.048405172414, 2388.0396744186046, 2388.030932642487, 2388.0647876447865, 2388.020130718954, 2388.0621960784306, 2388.0423981900453, 2388.022590361446, 2388.019523809524, 2388.0404034582084, 2388.0557192982424, 2388.0268508287295, 2388.0452654867254, 2388.0621804511256, 2388.0414662756552, 2388.0244186046516, 2388.0459316770152, 2388.035797101449, 2388.0268508287295, 2388.0205769230765, 2388.0212025316455, 2388.0242690058485, 2388.0346173469334, 2388.022590361446, 2388.0491853360454, 2388.0590545454515, 2388.0497394136773, 2388.018965517241, 2388.0202631578945] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  \n",
       "0     47.462046    521.666564   2388.064788  \n",
       "1     47.445296    521.710316   2388.060711  \n",
       "2     47.375856    521.892117   2388.042793  \n",
       "3     47.443566    521.666507   2388.060110  \n",
       "4     47.361737    521.935728   2388.038592  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor13 = np.array(df_noise['Sensor 13'])\n",
    "l13=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor13[j]\n",
    "    l13.append(k/l[i])\n",
    "print(l13,len(l13))\n",
    "df_avg[\"Sensor13_Avg\"]=l13\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8149.744324324323, 8149.774940711461, 8149.83788288288, 8148.979669117644, 8149.906291079808, 8148.680251798557, 8144.81198113207, 8149.306928838949, 8144.880418719205, 8145.71715176715, 8149.8903045685265, 8149.9242352941155, 8149.9287027027, 8149.859420289851, 8149.887475247521, 8146.105726744179, 8147.218621794867, 8144.935145413864, 8149.795895196503, 8146.2854733727745, 8149.879272727269, 8149.962968749997, 8149.891734693875, 8146.330182186233, 8149.915492227977, 8149.813950617281, 8146.909812499996, 8149.892349999997, 8149.834035874436, 8149.883577981647, 8149.942021857921, 8149.934550264547, 8149.812467532463, 8145.091764705877, 8149.812467532463, 8146.747962962958, 8146.747962962958, 8149.880049751241, 8148.211527777774, 8149.916914893614, 8147.909322033894, 8149.915492227977, 8146.8771028037345, 8150.009611111109, 8149.844878048777, 8149.861568627448, 8149.177546468399, 8149.927758620686, 8149.7435546874985, 8150.036335403725, 8149.947947368418, 8149.83788288288, 8149.981219512195, 8149.913453608245, 8147.341161904765, 8149.903589743587, 8149.878186046508, 8150.0248314606715, 8147.723812709025, 8149.947947368418, 8149.907336683415, 8149.850487804876, 8149.812467532463, 8149.903589743587, 8149.841495726492, 8149.941818181817, 8149.535703422051, 8149.880049751241, 8149.9242352941155, 8149.930813953486, 8144.868239608796, 8149.818017241376, 8149.878186046508, 8149.915492227977, 8149.744324324323, 8150.068300653595, 8149.738078431372, 8149.857466063345, 8149.95204819277, 8150.046530612245, 8146.044927953883, 8148.377157894734, 8149.990552486185, 8149.816858407076, 8149.382481203005, 8146.178973607032, 8149.930813953486, 8146.844906832294, 8149.859420289851, 8149.990552486185, 8150.088205128203, 8150.067088607594, 8149.921812865495, 8145.033392857138, 8149.95204819277, 8146.162057026474, 8148.828218181814, 8147.390260586315, 8150.002344827587, 8150.062302631579] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  \n",
       "0     47.462046    521.666564   2388.064788   8149.744324  \n",
       "1     47.445296    521.710316   2388.060711   8149.774941  \n",
       "2     47.375856    521.892117   2388.042793   8149.837883  \n",
       "3     47.443566    521.666507   2388.060110   8148.979669  \n",
       "4     47.361737    521.935728   2388.038592   8149.906291  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor14 = np.array(df_noise['Sensor 14'])\n",
    "l14=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor14[j]\n",
    "    l14.append(k/l[i])\n",
    "print(l14,len(l14))\n",
    "df_avg[\"Sensor14_Avg\"]=l14\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.432769111969115, 8.430755731225299, 8.422490540540545, 8.430340808823534, 8.4208985915493, 8.429586330935257, 8.41151273584906, 8.43117378277154, 8.41361034482759, 8.40249126819127, 8.418696954314724, 8.414717647058827, 8.416500000000005, 8.420101449275366, 8.41937574257426, 8.420700290697676, 8.424507051282054, 8.408475167785236, 8.424056331877734, 8.42158579881657, 8.421946818181823, 8.417958333333337, 8.418708673469391, 8.399418421052632, 8.418068911917102, 8.427712345679018, 8.423555937500002, 8.419002500000003, 8.422653811659197, 8.421722018348628, 8.416101639344266, 8.417328571428577, 8.424595670995677, 8.406313071895426, 8.424595670995677, 8.422984567901237, 8.422984567901237, 8.41917313432836, 8.428123958333337, 8.41711542553192, 8.427197627118648, 8.418068911917102, 8.423432087227416, 8.415926111111114, 8.419760000000004, 8.419659803921572, 8.43086394052045, 8.415353448275866, 8.431759375000002, 8.414106832298138, 8.41761578947369, 8.422490540540545, 8.414262195121953, 8.418156185567014, 8.394428000000003, 8.418424615384618, 8.421079069767446, 8.415714606741576, 8.426684615384621, 8.41761578947369, 8.418964824120607, 8.428706504065044, 8.424595670995677, 8.418424615384618, 8.42550897435898, 8.414538181818184, 8.431856653992398, 8.41917313432836, 8.414717647058827, 8.41509593023256, 8.413220782396092, 8.42480086206897, 8.421079069767446, 8.418068911917102, 8.432769111969115, 8.413200000000002, 8.431469019607846, 8.422167873303172, 8.414603012048195, 8.412540136054421, 8.420290489913546, 8.428466666666672, 8.415928176795584, 8.423244247787615, 8.431368796992484, 8.421170674486806, 8.41509593023256, 8.423289751552797, 8.420101449275366, 8.415928176795584, 8.413558333333336, 8.413868354430381, 8.414819298245618, 8.415271428571431, 8.414603012048195, 8.40016517311609, 8.429969454545457, 8.425294462540723, 8.412091034482758, 8.41295855263158] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  \n",
       "0     47.462046    521.666564   2388.064788   8149.744324      8.432769  \n",
       "1     47.445296    521.710316   2388.060711   8149.774941      8.430756  \n",
       "2     47.375856    521.892117   2388.042793   8149.837883      8.422491  \n",
       "3     47.443566    521.666507   2388.060110   8148.979669      8.430341  \n",
       "4     47.361737    521.935728   2388.038592   8149.906291      8.420899  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor15 = np.array(df_noise['Sensor 15'])\n",
    "l15=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor15[j]\n",
    "    l15.append(k/l[i])\n",
    "print(l15,len(l15))\n",
    "df_avg[\"Sensor15_Avg\"]=l15\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03000000000000008, 0.030000000000000072, 0.030000000000000047, 0.030000000000000065, 0.03000000000000004, 0.03000000000000005, 0.02999999999999981, 0.03000000000000008, 0.029999999999999832, 0.02999999999999976, 0.030000000000000023, 0.02999999999999999, 0.03000000000000001, 0.030000000000000034, 0.03000000000000003, 0.02999999999999992, 0.029999999999999975, 0.02999999999999979, 0.030000000000000054, 0.02999999999999993, 0.030000000000000047, 0.030000000000000016, 0.030000000000000023, 0.02999999999999975, 0.03000000000000002, 0.030000000000000065, 0.02999999999999996, 0.030000000000000027, 0.03000000000000005, 0.030000000000000044, 0.030000000000000006, 0.030000000000000013, 0.030000000000000058, 0.029999999999999777, 0.030000000000000058, 0.029999999999999954, 0.029999999999999954, 0.030000000000000027, 0.030000000000000027, 0.030000000000000013, 0.03000000000000001, 0.03000000000000002, 0.029999999999999957, 0.030000000000000002, 0.030000000000000034, 0.03000000000000003, 0.030000000000000075, 0.029999999999999992, 0.030000000000000075, 0.02999999999999997, 0.030000000000000016, 0.030000000000000047, 0.029999999999999978, 0.03000000000000002, 0.029999999999999725, 0.03000000000000002, 0.03000000000000004, 0.03, 0.030000000000000002, 0.030000000000000016, 0.030000000000000027, 0.03000000000000007, 0.030000000000000058, 0.03000000000000002, 0.030000000000000058, 0.029999999999999978, 0.03000000000000008, 0.030000000000000027, 0.02999999999999999, 0.029999999999999992, 0.02999999999999983, 0.030000000000000058, 0.03000000000000004, 0.03000000000000002, 0.03000000000000008, 0.029999999999999957, 0.030000000000000075, 0.030000000000000047, 0.02999999999999998, 0.029999999999999947, 0.029999999999999912, 0.030000000000000034, 0.030000000000000002, 0.03000000000000005, 0.030000000000000082, 0.029999999999999923, 0.029999999999999992, 0.029999999999999957, 0.030000000000000034, 0.030000000000000002, 0.029999999999999964, 0.029999999999999968, 0.02999999999999999, 0.02999999999999985, 0.02999999999999998, 0.029999999999999753, 0.030000000000000058, 0.029999999999999985, 0.029999999999999943, 0.029999999999999957] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  \\\n",
       "0     47.462046    521.666564   2388.064788   8149.744324      8.432769   \n",
       "1     47.445296    521.710316   2388.060711   8149.774941      8.430756   \n",
       "2     47.375856    521.892117   2388.042793   8149.837883      8.422491   \n",
       "3     47.443566    521.666507   2388.060110   8148.979669      8.430341   \n",
       "4     47.361737    521.935728   2388.038592   8149.906291      8.420899   \n",
       "\n",
       "   Sensor16_Avg  \n",
       "0          0.03  \n",
       "1          0.03  \n",
       "2          0.03  \n",
       "3          0.03  \n",
       "4          0.03  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor16 = np.array(df_noise['Sensor 16'])\n",
    "l16=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor16[j]\n",
    "    l16.append(k/l[i])\n",
    "print(l16,len(l16))\n",
    "df_avg[\"Sensor16_Avg\"]=l16\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[392.9343629343629, 392.8498023715415, 392.5045045045045, 392.8492647058824, 392.4178403755869, 392.8129496402878, 392.2806603773585, 392.87640449438203, 392.29802955665025, 392.33056133056135, 392.2791878172589, 392.1411764705882, 392.2108108108108, 392.3768115942029, 392.33168316831683, 392.4796511627907, 392.6057692307692, 392.2774049217002, 392.5764192139738, 392.49704142011836, 392.48636363636365, 392.2447916666667, 392.2755102040816, 392.3805668016194, 392.2538860103627, 392.7078189300411, 392.56875, 392.315, 392.52017937219733, 392.4678899082569, 392.20765027322403, 392.23809523809524, 392.5930735930736, 392.29847494553377, 392.5930735930736, 392.537037037037, 392.537037037037, 392.32338308457713, 392.74305555555554, 392.22872340425533, 392.71525423728815, 392.2538860103627, 392.55763239875387, 392.19444444444446, 392.3560975609756, 392.3480392156863, 392.8736059479554, 392.1666666666667, 392.8828125, 392.0993788819876, 392.2421052631579, 392.5045045045045, 392.1219512195122, 392.2628865979381, 392.4742857142857, 392.2717948717949, 392.4418604651163, 392.1685393258427, 392.685618729097, 392.2421052631579, 392.3065326633166, 392.7560975609756, 392.5930735930736, 392.2717948717949, 392.61965811965814, 392.1272727272727, 392.90494296577947, 392.32338308457713, 392.1411764705882, 392.1511627906977, 392.3031784841076, 392.5948275862069, 392.4418604651163, 392.2538860103627, 392.9343629343629, 392.0457516339869, 392.8666666666667, 392.4977375565611, 392.1265060240964, 392.01360544217687, 392.46974063400575, 392.7684210526316, 392.1988950276243, 392.55309734513276, 392.8872180451128, 392.4868035190616, 392.1511627906977, 392.5496894409938, 392.3768115942029, 392.1988950276243, 392.06410256410254, 392.0822784810127, 392.15204678362574, 392.32142857142856, 392.1265060240964, 392.36659877800406, 392.83272727272725, 392.6319218241042, 392.0137931034483, 392.0394736842105] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.934363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.504505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.417840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  \\\n",
       "0     47.462046    521.666564   2388.064788   8149.744324      8.432769   \n",
       "1     47.445296    521.710316   2388.060711   8149.774941      8.430756   \n",
       "2     47.375856    521.892117   2388.042793   8149.837883      8.422491   \n",
       "3     47.443566    521.666507   2388.060110   8148.979669      8.430341   \n",
       "4     47.361737    521.935728   2388.038592   8149.906291      8.420899   \n",
       "\n",
       "   Sensor16_Avg  Sensor17_Avg  \n",
       "0          0.03    392.934363  \n",
       "1          0.03    392.849802  \n",
       "2          0.03    392.504505  \n",
       "3          0.03    392.849265  \n",
       "4          0.03    392.417840  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor17 = np.array(df_noise['Sensor 17'])\n",
    "l17=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor17[j]\n",
    "    l17.append(k/l[i])\n",
    "print(l17,len(l17))\n",
    "df_avg[\"Sensor17_Avg\"]=l17\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0, 2388.0] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.934363</td>\n",
       "      <td>2388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849802</td>\n",
       "      <td>2388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.504505</td>\n",
       "      <td>2388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849265</td>\n",
       "      <td>2388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.417840</td>\n",
       "      <td>2388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  \\\n",
       "0     47.462046    521.666564   2388.064788   8149.744324      8.432769   \n",
       "1     47.445296    521.710316   2388.060711   8149.774941      8.430756   \n",
       "2     47.375856    521.892117   2388.042793   8149.837883      8.422491   \n",
       "3     47.443566    521.666507   2388.060110   8148.979669      8.430341   \n",
       "4     47.361737    521.935728   2388.038592   8149.906291      8.420899   \n",
       "\n",
       "   Sensor16_Avg  Sensor17_Avg  Sensor18_Avg  \n",
       "0          0.03    392.934363        2388.0  \n",
       "1          0.03    392.849802        2388.0  \n",
       "2          0.03    392.504505        2388.0  \n",
       "3          0.03    392.849265        2388.0  \n",
       "4          0.03    392.417840        2388.0  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor18 = np.array(df_noise['Sensor 18'])\n",
    "l18=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor18[j]\n",
    "    l18.append(k/l[i])\n",
    "print(l18,len(l18))\n",
    "df_avg[\"Sensor18_Avg\"]=l18\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "      <th>Sensor19_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.934363</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849802</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.504505</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849265</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.417840</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  \\\n",
       "0     47.462046    521.666564   2388.064788   8149.744324      8.432769   \n",
       "1     47.445296    521.710316   2388.060711   8149.774941      8.430756   \n",
       "2     47.375856    521.892117   2388.042793   8149.837883      8.422491   \n",
       "3     47.443566    521.666507   2388.060110   8148.979669      8.430341   \n",
       "4     47.361737    521.935728   2388.038592   8149.906291      8.420899   \n",
       "\n",
       "   Sensor16_Avg  Sensor17_Avg  Sensor18_Avg  Sensor19_Avg  \n",
       "0          0.03    392.934363        2388.0         100.0  \n",
       "1          0.03    392.849802        2388.0         100.0  \n",
       "2          0.03    392.504505        2388.0         100.0  \n",
       "3          0.03    392.849265        2388.0         100.0  \n",
       "4          0.03    392.417840        2388.0         100.0  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor19 = np.array(df_noise['Sensor 19'])\n",
    "l19=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor19[j]\n",
    "    l19.append(k/l[i])\n",
    "print(l19,len(l19))\n",
    "df_avg[\"Sensor19_Avg\"]=l19\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.857683397683395, 38.86849802371541, 38.91103603603605, 38.865367647058825, 38.921455399061045, 38.871043165467626, 38.931108490566025, 38.86277153558052, 38.9249014778325, 38.965405405405384, 38.9363959390863, 38.960058823529415, 38.949243243243245, 38.928067632850244, 38.9330693069307, 38.903808139534874, 38.889711538461526, 38.94355704697985, 38.9027074235808, 38.90118343195265, 38.913409090909106, 38.94067708333334, 38.93698979591837, 38.97536437246962, 38.94062176165804, 38.885555555555555, 38.89303124999999, 38.935050000000004, 38.9098206278027, 38.915229357798175, 38.950054644808745, 38.9452380952381, 38.90095238095239, 38.95004357298473, 38.90095238095239, 38.89469135802468, 38.89469135802468, 38.93422885572139, 38.87732638888889, 38.94712765957448, 38.879830508474576, 38.94062176165804, 38.893831775700924, 38.95355555555556, 38.9289756097561, 38.930931372549026, 38.86394052044609, 38.955114942528745, 38.863046874999995, 38.96546583850932, 38.94336842105264, 38.91103603603605, 38.96426829268293, 38.93896907216496, 38.99588571428571, 38.93738461538462, 38.91902325581396, 38.952977528089896, 38.88257525083611, 38.94336842105264, 38.935175879396986, 38.88044715447155, 38.90095238095239, 38.93738461538462, 38.89709401709403, 38.96369696969697, 38.859011406844104, 38.93422885572139, 38.960058823529415, 38.95802325581396, 38.92523227383862, 38.90012931034484, 38.91902325581396, 38.94062176165804, 38.857683397683395, 38.96986928104575, 38.86462745098039, 38.91271493212671, 38.96265060240964, 38.97632653061224, 38.9050432276657, 38.87480701754386, 38.9528729281768, 38.90690265486727, 38.86214285714285, 38.90255131964808, 38.95802325581396, 38.89385093167701, 38.928067632850244, 38.9528729281768, 38.9698076923077, 38.968354430379755, 38.95888888888889, 38.91943877551019, 38.96265060240964, 38.97250509164968, 38.86836363636364, 38.887557003257314, 38.97537931034482, 38.9703947368421] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "      <th>Sensor19_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.934363</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.857683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849802</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.868498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.504505</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.911036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849265</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.865368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.417840</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.921455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  \\\n",
       "0     47.462046    521.666564   2388.064788   8149.744324      8.432769   \n",
       "1     47.445296    521.710316   2388.060711   8149.774941      8.430756   \n",
       "2     47.375856    521.892117   2388.042793   8149.837883      8.422491   \n",
       "3     47.443566    521.666507   2388.060110   8148.979669      8.430341   \n",
       "4     47.361737    521.935728   2388.038592   8149.906291      8.420899   \n",
       "\n",
       "   Sensor16_Avg  Sensor17_Avg  Sensor18_Avg  Sensor19_Avg  Sensor20_Avg  \n",
       "0          0.03    392.934363        2388.0         100.0     38.857683  \n",
       "1          0.03    392.849802        2388.0         100.0     38.868498  \n",
       "2          0.03    392.504505        2388.0         100.0     38.911036  \n",
       "3          0.03    392.849265        2388.0         100.0     38.865368  \n",
       "4          0.03    392.417840        2388.0         100.0     38.921455  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor20 = np.array(df_noise['Sensor 20'])\n",
    "l20=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor20[j]\n",
    "    l20.append(k/l[i])\n",
    "print(l20,len(l20))\n",
    "df_avg[\"Sensor20_Avg\"]=l20\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.3217447876448, 23.32751343873519, 23.352205855855868, 23.325818750000014, 23.357806103286393, 23.328415827338144, 23.361688915094344, 23.32440337078653, 23.35708004926109, 23.38031725571727, 23.366448223350265, 23.38053411764707, 23.371984864864878, 23.36132125603866, 23.3640683168317, 23.34473284883723, 23.336933974358992, 23.36751387024609, 23.34805152838429, 23.34361272189351, 23.35344681818183, 23.36928802083334, 23.36679387755103, 23.387217004048594, 23.36870725388602, 23.335733744855975, 23.339159062500016, 23.36554800000001, 23.35126547085203, 23.354121559633036, 23.371832786885257, 23.370525925925936, 23.346612987012996, 23.371571459694998, 23.346612987012996, 23.34035709876545, 23.34035709876545, 23.36468955223882, 23.330863888888903, 23.370469148936184, 23.333498644067813, 23.36870725388602, 23.33934704049846, 23.373569444444456, 23.362773658536597, 23.363243137254916, 23.32530371747213, 23.37823793103449, 23.324568750000008, 23.38425279503107, 23.370562105263172, 23.352205855855868, 23.382296951219526, 23.367896907216505, 23.399995238095237, 23.36726410256411, 23.356501860465123, 23.375945505617988, 23.33450969899667, 23.370562105263172, 23.365585427135688, 23.333363008130092, 23.346612987012996, 23.36726410256411, 23.343578205128214, 23.381771515151527, 23.322859695817503, 23.36468955223882, 23.38053411764707, 23.379167441860474, 23.35766405867971, 23.34567931034484, 23.356501860465123, 23.36870725388602, 23.3217447876448, 23.38788562091505, 23.325650196078442, 23.35282217194571, 23.381440361445794, 23.389752380952395, 23.34510000000002, 23.33052807017545, 23.372811602209953, 23.349196460177, 23.32405375939851, 23.344201173020547, 23.379167441860474, 23.33978664596275, 23.36132125603866, 23.372811602209953, 23.386614102564117, 23.38633037974685, 23.379981871345038, 23.353876275510217, 23.381440361445794, 23.385780448065187, 23.327168000000015, 23.33629902280132, 23.39065724137932, 23.388596710526333] 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "      <th>Sensor19_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "      <th>Sensor21_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.934363</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.857683</td>\n",
       "      <td>23.321745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849802</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.868498</td>\n",
       "      <td>23.327513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.504505</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.911036</td>\n",
       "      <td>23.352206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849265</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.865368</td>\n",
       "      <td>23.325819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.417840</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.921455</td>\n",
       "      <td>23.357806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  ...  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3  ...   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3  ...   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3  ...   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3  ...   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3  ...   \n",
       "\n",
       "   Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  Sensor16_Avg  \\\n",
       "0    521.666564   2388.064788   8149.744324      8.432769          0.03   \n",
       "1    521.710316   2388.060711   8149.774941      8.430756          0.03   \n",
       "2    521.892117   2388.042793   8149.837883      8.422491          0.03   \n",
       "3    521.666507   2388.060110   8148.979669      8.430341          0.03   \n",
       "4    521.935728   2388.038592   8149.906291      8.420899          0.03   \n",
       "\n",
       "   Sensor17_Avg  Sensor18_Avg  Sensor19_Avg  Sensor20_Avg  Sensor21_Avg  \n",
       "0    392.934363        2388.0         100.0     38.857683     23.321745  \n",
       "1    392.849802        2388.0         100.0     38.868498     23.327513  \n",
       "2    392.504505        2388.0         100.0     38.911036     23.352206  \n",
       "3    392.849265        2388.0         100.0     38.865368     23.325819  \n",
       "4    392.417840        2388.0         100.0     38.921455     23.357806  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sensor21 = np.array(df_noise['Sensor 21'])\n",
    "l21=[]\n",
    "\n",
    "for i in range(0,100): # for FD001 range(0,100), for FD002 range(0,260), for FD003 range(0,100), for FD004 range (0,249)\n",
    "    k=0\n",
    "    for j in range(0,(l[i])):\n",
    "        k += Sensor21[j]\n",
    "    l21.append(k/l[i])\n",
    "print(l21,len(l21))\n",
    "df_avg[\"Sensor21_Avg\"]=l21\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rul = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/NASA_Dataset_Turbofan Engine Degradation Simulation/CMAPSSData/RUL_FD003.txt\",sep=' ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0   44 NaN\n",
       "1   51 NaN\n",
       "2   27 NaN\n",
       "3  120 NaN\n",
       "4  101 NaN"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rul.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rul=df_rul.drop(columns=[1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0   44\n",
       "1   51\n",
       "2   27\n",
       "3  120\n",
       "4  101"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rul.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg[\"RUL\"]=df_rul[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "      <th>Sensor19_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "      <th>Sensor21_Avg</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609653</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.934363</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.857683</td>\n",
       "      <td>23.321745</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609644</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>2388.060316</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849802</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.868498</td>\n",
       "      <td>23.327513</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609595</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>2388.043739</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.504505</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.911036</td>\n",
       "      <td>23.352206</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.608125</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>2388.059779</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.849265</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.865368</td>\n",
       "      <td>23.325819</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609577</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>2388.039155</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.417840</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.921455</td>\n",
       "      <td>23.357806</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0       518.67   642.573320  1589.227027  1406.597915        14.62   \n",
       "1       518.67   642.546087  1588.928814  1406.078617        14.62   \n",
       "2       518.67   642.428559  1587.837342  1403.732973        14.62   \n",
       "3       518.67   642.552390  1588.954522  1406.001029        14.62   \n",
       "4       518.67   642.404742  1587.522441  1403.168732        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  ...  \\\n",
       "0    21.609653   553.613166  2388.064788  9071.174208           1.3  ...   \n",
       "1    21.609644   553.657115  2388.060316  9071.030435           1.3  ...   \n",
       "2    21.609595   553.874144  2388.043739  9070.434054           1.3  ...   \n",
       "3    21.608125   553.610257  2388.059779  9070.184007           1.3  ...   \n",
       "4    21.609577   553.926573  2388.039155  9070.338638           1.3  ...   \n",
       "\n",
       "   Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  Sensor16_Avg  Sensor17_Avg  \\\n",
       "0   2388.064788   8149.744324      8.432769          0.03    392.934363   \n",
       "1   2388.060711   8149.774941      8.430756          0.03    392.849802   \n",
       "2   2388.042793   8149.837883      8.422491          0.03    392.504505   \n",
       "3   2388.060110   8148.979669      8.430341          0.03    392.849265   \n",
       "4   2388.038592   8149.906291      8.420899          0.03    392.417840   \n",
       "\n",
       "   Sensor18_Avg  Sensor19_Avg  Sensor20_Avg  Sensor21_Avg  RUL  \n",
       "0        2388.0         100.0     38.857683     23.321745   44  \n",
       "1        2388.0         100.0     38.868498     23.327513   51  \n",
       "2        2388.0         100.0     38.911036     23.352206   27  \n",
       "3        2388.0         100.0     38.865368     23.325819  120  \n",
       "4        2388.0         100.0     38.921455     23.357806  101  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "      <th>Sensor19_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "      <th>Sensor21_Avg</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.377169</td>\n",
       "      <td>1587.112851</td>\n",
       "      <td>1402.746069</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.593625</td>\n",
       "      <td>554.538350</td>\n",
       "      <td>2388.047699</td>\n",
       "      <td>9065.344134</td>\n",
       "      <td>1.30055</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.049185</td>\n",
       "      <td>8146.162057</td>\n",
       "      <td>8.400165</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.366599</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.972505</td>\n",
       "      <td>23.385780</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.545200</td>\n",
       "      <td>1588.875455</td>\n",
       "      <td>1405.870255</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.607782</td>\n",
       "      <td>553.610327</td>\n",
       "      <td>2388.058800</td>\n",
       "      <td>9069.905782</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.059055</td>\n",
       "      <td>8148.828218</td>\n",
       "      <td>8.429969</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.832727</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.868364</td>\n",
       "      <td>23.327168</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.490684</td>\n",
       "      <td>1588.088143</td>\n",
       "      <td>1404.767134</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.604495</td>\n",
       "      <td>553.604430</td>\n",
       "      <td>2388.049316</td>\n",
       "      <td>9067.839251</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.049739</td>\n",
       "      <td>8147.390261</td>\n",
       "      <td>8.425294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.631922</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.887557</td>\n",
       "      <td>23.336299</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.299172</td>\n",
       "      <td>1585.857724</td>\n",
       "      <td>1400.299379</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609379</td>\n",
       "      <td>554.228345</td>\n",
       "      <td>2388.016828</td>\n",
       "      <td>9069.575241</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.018966</td>\n",
       "      <td>8150.002345</td>\n",
       "      <td>8.412091</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.013793</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.975379</td>\n",
       "      <td>23.390657</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>518.67</td>\n",
       "      <td>642.310395</td>\n",
       "      <td>1586.002500</td>\n",
       "      <td>1400.521645</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609408</td>\n",
       "      <td>554.216118</td>\n",
       "      <td>2388.018947</td>\n",
       "      <td>9069.692763</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.020263</td>\n",
       "      <td>8150.062303</td>\n",
       "      <td>8.412959</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.039474</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.970395</td>\n",
       "      <td>23.388597</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "95       518.67   642.377169  1587.112851  1402.746069        14.62   \n",
       "96       518.67   642.545200  1588.875455  1405.870255        14.62   \n",
       "97       518.67   642.490684  1588.088143  1404.767134        14.62   \n",
       "98       518.67   642.299172  1585.857724  1400.299379        14.62   \n",
       "99       518.67   642.310395  1586.002500  1400.521645        14.62   \n",
       "\n",
       "    Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  ...  \\\n",
       "95    21.593625   554.538350  2388.047699  9065.344134       1.30055  ...   \n",
       "96    21.607782   553.610327  2388.058800  9069.905782       1.30000  ...   \n",
       "97    21.604495   553.604430  2388.049316  9067.839251       1.30000  ...   \n",
       "98    21.609379   554.228345  2388.016828  9069.575241       1.30000  ...   \n",
       "99    21.609408   554.216118  2388.018947  9069.692763       1.30000  ...   \n",
       "\n",
       "    Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  Sensor16_Avg  Sensor17_Avg  \\\n",
       "95   2388.049185   8146.162057      8.400165          0.03    392.366599   \n",
       "96   2388.059055   8148.828218      8.429969          0.03    392.832727   \n",
       "97   2388.049739   8147.390261      8.425294          0.03    392.631922   \n",
       "98   2388.018966   8150.002345      8.412091          0.03    392.013793   \n",
       "99   2388.020263   8150.062303      8.412959          0.03    392.039474   \n",
       "\n",
       "    Sensor18_Avg  Sensor19_Avg  Sensor20_Avg  Sensor21_Avg  RUL  \n",
       "95        2388.0         100.0     38.972505     23.385780  113  \n",
       "96        2388.0         100.0     38.868364     23.327168  123  \n",
       "97        2388.0         100.0     38.887557     23.336299   17  \n",
       "98        2388.0         100.0     38.975379     23.390657    8  \n",
       "99        2388.0         100.0     38.970395     23.388597   28  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.to_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD003_avg.csv\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg1=df_avg.drop(['Sensor1_Avg','Sensor5_Avg','Sensor6_Avg','Sensor8_Avg','Sensor10_Avg','Sensor16_Avg','Sensor18_Avg','Sensor19_Avg'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "      <th>Sensor21_Avg</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>642.573320</td>\n",
       "      <td>1589.227027</td>\n",
       "      <td>1406.597915</td>\n",
       "      <td>553.613166</td>\n",
       "      <td>9071.174208</td>\n",
       "      <td>47.462046</td>\n",
       "      <td>521.666564</td>\n",
       "      <td>2388.064788</td>\n",
       "      <td>8149.744324</td>\n",
       "      <td>8.432769</td>\n",
       "      <td>392.934363</td>\n",
       "      <td>38.857683</td>\n",
       "      <td>23.321745</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642.546087</td>\n",
       "      <td>1588.928814</td>\n",
       "      <td>1406.078617</td>\n",
       "      <td>553.657115</td>\n",
       "      <td>9071.030435</td>\n",
       "      <td>47.445296</td>\n",
       "      <td>521.710316</td>\n",
       "      <td>2388.060711</td>\n",
       "      <td>8149.774941</td>\n",
       "      <td>8.430756</td>\n",
       "      <td>392.849802</td>\n",
       "      <td>38.868498</td>\n",
       "      <td>23.327513</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642.428559</td>\n",
       "      <td>1587.837342</td>\n",
       "      <td>1403.732973</td>\n",
       "      <td>553.874144</td>\n",
       "      <td>9070.434054</td>\n",
       "      <td>47.375856</td>\n",
       "      <td>521.892117</td>\n",
       "      <td>2388.042793</td>\n",
       "      <td>8149.837883</td>\n",
       "      <td>8.422491</td>\n",
       "      <td>392.504505</td>\n",
       "      <td>38.911036</td>\n",
       "      <td>23.352206</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>642.552390</td>\n",
       "      <td>1588.954522</td>\n",
       "      <td>1406.001029</td>\n",
       "      <td>553.610257</td>\n",
       "      <td>9070.184007</td>\n",
       "      <td>47.443566</td>\n",
       "      <td>521.666507</td>\n",
       "      <td>2388.060110</td>\n",
       "      <td>8148.979669</td>\n",
       "      <td>8.430341</td>\n",
       "      <td>392.849265</td>\n",
       "      <td>38.865368</td>\n",
       "      <td>23.325819</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>642.404742</td>\n",
       "      <td>1587.522441</td>\n",
       "      <td>1403.168732</td>\n",
       "      <td>553.926573</td>\n",
       "      <td>9070.338638</td>\n",
       "      <td>47.361737</td>\n",
       "      <td>521.935728</td>\n",
       "      <td>2388.038592</td>\n",
       "      <td>8149.906291</td>\n",
       "      <td>8.420899</td>\n",
       "      <td>392.417840</td>\n",
       "      <td>38.921455</td>\n",
       "      <td>23.357806</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor7_Avg  Sensor9_Avg  \\\n",
       "0   642.573320  1589.227027  1406.597915   553.613166  9071.174208   \n",
       "1   642.546087  1588.928814  1406.078617   553.657115  9071.030435   \n",
       "2   642.428559  1587.837342  1403.732973   553.874144  9070.434054   \n",
       "3   642.552390  1588.954522  1406.001029   553.610257  9070.184007   \n",
       "4   642.404742  1587.522441  1403.168732   553.926573  9070.338638   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  \\\n",
       "0     47.462046    521.666564   2388.064788   8149.744324      8.432769   \n",
       "1     47.445296    521.710316   2388.060711   8149.774941      8.430756   \n",
       "2     47.375856    521.892117   2388.042793   8149.837883      8.422491   \n",
       "3     47.443566    521.666507   2388.060110   8148.979669      8.430341   \n",
       "4     47.361737    521.935728   2388.038592   8149.906291      8.420899   \n",
       "\n",
       "   Sensor17_Avg  Sensor20_Avg  Sensor21_Avg  RUL  \n",
       "0    392.934363     38.857683     23.321745   44  \n",
       "1    392.849802     38.868498     23.327513   51  \n",
       "2    392.504505     38.911036     23.352206   27  \n",
       "3    392.849265     38.865368     23.325819  120  \n",
       "4    392.417840     38.921455     23.357806  101  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg1.to_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD003_avg_col_dropped.csv\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD001_avg.csv\",header='infer')\n",
    "df2 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD002_avg.csv\",header='infer')\n",
    "df3 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD003_avg.csv\",header='infer')\n",
    "df4 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD004_avg.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame = [df1,df2,df3,df4]\n",
    "df_merged = pd.concat(df_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "      <th>Sensor19_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "      <th>Sensor21_Avg</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>642.621042</td>\n",
       "      <td>642.621042</td>\n",
       "      <td>1589.485521</td>\n",
       "      <td>1407.262135</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>553.439427</td>\n",
       "      <td>2388.110260</td>\n",
       "      <td>9048.265833</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.110833</td>\n",
       "      <td>8128.913542</td>\n",
       "      <td>8.436555</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.854167</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.840052</td>\n",
       "      <td>23.306310</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642.423031</td>\n",
       "      <td>642.423031</td>\n",
       "      <td>1587.581533</td>\n",
       "      <td>1403.757247</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609547</td>\n",
       "      <td>553.795993</td>\n",
       "      <td>2388.078223</td>\n",
       "      <td>9049.902927</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.075854</td>\n",
       "      <td>8131.658467</td>\n",
       "      <td>8.422551</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.351916</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.906376</td>\n",
       "      <td>23.343887</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642.545363</td>\n",
       "      <td>642.545363</td>\n",
       "      <td>1588.757709</td>\n",
       "      <td>1405.981564</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>553.575196</td>\n",
       "      <td>2388.099218</td>\n",
       "      <td>9048.757151</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.098771</td>\n",
       "      <td>8129.803520</td>\n",
       "      <td>8.431322</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.631285</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.865140</td>\n",
       "      <td>23.323317</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>642.606984</td>\n",
       "      <td>642.606984</td>\n",
       "      <td>1589.302804</td>\n",
       "      <td>1406.959841</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>553.475714</td>\n",
       "      <td>2388.107302</td>\n",
       "      <td>9048.415238</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.107460</td>\n",
       "      <td>8129.170794</td>\n",
       "      <td>8.435278</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.804233</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.845873</td>\n",
       "      <td>23.310315</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>642.448922</td>\n",
       "      <td>642.448922</td>\n",
       "      <td>1587.766022</td>\n",
       "      <td>1404.140409</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609628</td>\n",
       "      <td>553.753717</td>\n",
       "      <td>2388.082565</td>\n",
       "      <td>9049.710446</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.080186</td>\n",
       "      <td>8131.302937</td>\n",
       "      <td>8.424452</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.423792</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.898327</td>\n",
       "      <td>23.339687</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0   642.621042   642.621042  1589.485521  1407.262135        14.62   \n",
       "1   642.423031   642.423031  1587.581533  1403.757247        14.62   \n",
       "2   642.545363   642.545363  1588.757709  1405.981564        14.62   \n",
       "3   642.606984   642.606984  1589.302804  1406.959841        14.62   \n",
       "4   642.448922   642.448922  1587.766022  1404.140409        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  ...  \\\n",
       "0    21.610000   553.439427  2388.110260  9048.265833           1.3  ...   \n",
       "1    21.609547   553.795993  2388.078223  9049.902927           1.3  ...   \n",
       "2    21.610000   553.575196  2388.099218  9048.757151           1.3  ...   \n",
       "3    21.610000   553.475714  2388.107302  9048.415238           1.3  ...   \n",
       "4    21.609628   553.753717  2388.082565  9049.710446           1.3  ...   \n",
       "\n",
       "   Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  Sensor16_Avg  Sensor17_Avg  \\\n",
       "0   2388.110833   8128.913542      8.436555          0.03    392.854167   \n",
       "1   2388.075854   8131.658467      8.422551          0.03    392.351916   \n",
       "2   2388.098771   8129.803520      8.431322          0.03    392.631285   \n",
       "3   2388.107460   8129.170794      8.435278          0.03    392.804233   \n",
       "4   2388.080186   8131.302937      8.424452          0.03    392.423792   \n",
       "\n",
       "   Sensor18_Avg  Sensor19_Avg  Sensor20_Avg  Sensor21_Avg    RUL  \n",
       "0        2388.0         100.0     38.840052     23.306310  112.0  \n",
       "1        2388.0         100.0     38.906376     23.343887   98.0  \n",
       "2        2388.0         100.0     38.865140     23.323317   69.0  \n",
       "3        2388.0         100.0     38.845873     23.310315   82.0  \n",
       "4        2388.0         100.0     38.898327     23.339687   91.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "      <th>Sensor19_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "      <th>Sensor21_Avg</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>472.633220</td>\n",
       "      <td>578.065171</td>\n",
       "      <td>1407.273073</td>\n",
       "      <td>1187.799415</td>\n",
       "      <td>7.996585</td>\n",
       "      <td>11.495415</td>\n",
       "      <td>278.973610</td>\n",
       "      <td>2222.304098</td>\n",
       "      <td>8497.429854</td>\n",
       "      <td>1.090341</td>\n",
       "      <td>...</td>\n",
       "      <td>2328.234732</td>\n",
       "      <td>8050.698976</td>\n",
       "      <td>9.325580</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>345.039024</td>\n",
       "      <td>2222.424390</td>\n",
       "      <td>97.500585</td>\n",
       "      <td>20.678537</td>\n",
       "      <td>12.406811</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>471.637516</td>\n",
       "      <td>576.736584</td>\n",
       "      <td>1403.109006</td>\n",
       "      <td>1182.536025</td>\n",
       "      <td>7.841925</td>\n",
       "      <td>11.262609</td>\n",
       "      <td>272.453292</td>\n",
       "      <td>2219.268137</td>\n",
       "      <td>8484.385590</td>\n",
       "      <td>1.082919</td>\n",
       "      <td>...</td>\n",
       "      <td>2327.551242</td>\n",
       "      <td>8047.412484</td>\n",
       "      <td>9.354919</td>\n",
       "      <td>0.022671</td>\n",
       "      <td>343.981366</td>\n",
       "      <td>2219.403727</td>\n",
       "      <td>97.472733</td>\n",
       "      <td>20.236584</td>\n",
       "      <td>12.144677</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>472.592654</td>\n",
       "      <td>577.855166</td>\n",
       "      <td>1406.573365</td>\n",
       "      <td>1187.367773</td>\n",
       "      <td>7.999668</td>\n",
       "      <td>11.494123</td>\n",
       "      <td>278.781374</td>\n",
       "      <td>2220.590758</td>\n",
       "      <td>8495.120427</td>\n",
       "      <td>1.090047</td>\n",
       "      <td>...</td>\n",
       "      <td>2326.523886</td>\n",
       "      <td>8049.970711</td>\n",
       "      <td>9.332004</td>\n",
       "      <td>0.022986</td>\n",
       "      <td>344.867299</td>\n",
       "      <td>2220.706161</td>\n",
       "      <td>97.428815</td>\n",
       "      <td>20.668057</td>\n",
       "      <td>12.400678</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>472.713533</td>\n",
       "      <td>578.068315</td>\n",
       "      <td>1406.733967</td>\n",
       "      <td>1186.952880</td>\n",
       "      <td>8.003641</td>\n",
       "      <td>11.501630</td>\n",
       "      <td>278.812935</td>\n",
       "      <td>2221.590489</td>\n",
       "      <td>8495.781576</td>\n",
       "      <td>1.088261</td>\n",
       "      <td>...</td>\n",
       "      <td>2327.280380</td>\n",
       "      <td>8048.959946</td>\n",
       "      <td>9.336988</td>\n",
       "      <td>0.022880</td>\n",
       "      <td>344.858696</td>\n",
       "      <td>2221.717391</td>\n",
       "      <td>97.461033</td>\n",
       "      <td>20.670815</td>\n",
       "      <td>12.405743</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>471.661922</td>\n",
       "      <td>576.797843</td>\n",
       "      <td>1404.380314</td>\n",
       "      <td>1184.796588</td>\n",
       "      <td>7.884353</td>\n",
       "      <td>11.326118</td>\n",
       "      <td>274.774980</td>\n",
       "      <td>2219.037765</td>\n",
       "      <td>8488.834667</td>\n",
       "      <td>1.086471</td>\n",
       "      <td>...</td>\n",
       "      <td>2327.269686</td>\n",
       "      <td>8051.579725</td>\n",
       "      <td>9.331643</td>\n",
       "      <td>0.022824</td>\n",
       "      <td>344.298039</td>\n",
       "      <td>2219.121569</td>\n",
       "      <td>97.458784</td>\n",
       "      <td>20.382039</td>\n",
       "      <td>12.228475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "244   472.633220   578.065171  1407.273073  1187.799415     7.996585   \n",
       "245   471.637516   576.736584  1403.109006  1182.536025     7.841925   \n",
       "246   472.592654   577.855166  1406.573365  1187.367773     7.999668   \n",
       "247   472.713533   578.068315  1406.733967  1186.952880     8.003641   \n",
       "248   471.661922   576.797843  1404.380314  1184.796588     7.884353   \n",
       "\n",
       "     Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  ...  \\\n",
       "244    11.495415   278.973610  2222.304098  8497.429854      1.090341  ...   \n",
       "245    11.262609   272.453292  2219.268137  8484.385590      1.082919  ...   \n",
       "246    11.494123   278.781374  2220.590758  8495.120427      1.090047  ...   \n",
       "247    11.501630   278.812935  2221.590489  8495.781576      1.088261  ...   \n",
       "248    11.326118   274.774980  2219.037765  8488.834667      1.086471  ...   \n",
       "\n",
       "     Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  Sensor16_Avg  Sensor17_Avg  \\\n",
       "244   2328.234732   8050.698976      9.325580      0.022976    345.039024   \n",
       "245   2327.551242   8047.412484      9.354919      0.022671    343.981366   \n",
       "246   2326.523886   8049.970711      9.332004      0.022986    344.867299   \n",
       "247   2327.280380   8048.959946      9.336988      0.022880    344.858696   \n",
       "248   2327.269686   8051.579725      9.331643      0.022824    344.298039   \n",
       "\n",
       "     Sensor18_Avg  Sensor19_Avg  Sensor20_Avg  Sensor21_Avg    RUL  \n",
       "244   2222.424390     97.500585     20.678537     12.406811  131.0  \n",
       "245   2219.403727     97.472733     20.236584     12.144677  194.0  \n",
       "246   2220.706161     97.428815     20.668057     12.400678  112.0  \n",
       "247   2221.717391     97.461033     20.670815     12.405743   26.0  \n",
       "248   2219.121569     97.458784     20.382039     12.228475    NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15598"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_Merged_data_avg.csv\",index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEXCAYAAABCjVgAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de7wcdX3/8ddbkkA0hOtRIwGOKKJIvZAExUu1Cq14AVqvqVb0F0UfKipqFVFr20fxp9X+EKRWKbHghYggVVS8AELVFoFwB4OCECSC5qAYQCME+vn9MbMnm5Pds2f37Mx8Z/b9fDz2sbvfvZzP7MyZz3wv8x1FBGZmZgAPqToAMzNLh5OCmZlNclIwM7NJTgpmZjbJScHMzCY5KZiZ2SQnBbOESXqdpB9VHYeNDicFayxJz5L0P5I2SPqtpP+WtGwW37fVDlrSqZL+aZZx/r2kTZLulfS7POYDB/ieiyS9YTaxmDkpWCNJWgh8E/gUsDOwG/APwH1VxjWVpDn5wzMiYgEwBvwIOFuSqovMRpWTgjXV4wAiYlVEPBgRGyPiexFxDYCkN0paI+keST+RtH9efoykn7eV/2Ve/gTgM8CBbUf0RwKvBt6bl30jf++jJH1V0oSkWyS9vRVUXis4S9IXJd0NvK496IjYBJwGPBLYZepCSXqGpMvy2s9lkp6Rlx8HPBs4KY/lpKH+mjYynBSsqX4GPCjpNEmHSNqp9YKklwN/D7wWWAgcCvwmf/nnZDvXHchqFl+UtCgi1gBvBi6OiAURsWNEnAx8CfjnvOwlkh4CfAO4mqx28nzgnZL+oi22w4CzgB3zz0+StC1ZolgXEXdOeW1n4FvAiWQJ4/8B35K0S0R8APgh8LY8lrcN/MvZSHNSsEaKiLuBZwEB/DswIekcSY8A3kC2I78sMjdFxK35586MiNsj4n8j4gzgRuCAPv70MmAsIv4xIu6PiJvzv/+qtvdcHBFfy//GxrzsFZJ+B9wGLAEO7/DdLwJujIgvRMQDEbEKuAF4SR/xmU1rTu+3mNVTfnT/OgBJjwe+CHwS2J2sRrAVSa8F3gWM50ULgF37+LN7Ao/Kd/At25Adxbfc1uFzX4mI1/T47kcBt04pu5WsRmI2FE4KNhIi4gZJpwJvItspP2bqeyTtSXZU/3yyo/kHJV0FtDp8O00pPLXsNuCWiNh7unD6DL/ldrKk024P4Duz/F6zSW4+skaS9HhJ75a0OH++O7Ac+DFwCvAeSUuUeWyeEB5GtmOdyD/zemC/tq/9NbBY0rwpZXu1Pb8UuFvS+yTNl7SNpP1mMxS2zbnA4yT9taQ5kl4J7Es2yqpTLGZ9c1KwproHeBpwiaTfkyWD64B3R8SZwHHA6fn7vgbsHBE/Af4FuJhsB/snwH+3fef3geuBX0lqdQKvBPbNRyN9LSIeJGvjfwpwC3AnWRLaYbYLFBG/AV4MvJusY/y9wIvbOqRPAF4m6S5JJ87279loki+yY2ZmLa4pmJnZJCcFMzOb5KRgZmaTnBTMzGxSrc9T2HXXXWN8fLzqMMzMauXyyy+/MyLGOr1W66QwPj7O6tWrqw7DzKxWJE09M36Sm4/MzGySk4KZmU1yUjAzs0lOCmZmNslJwczMJjkpmJVtYgIuuyy7N0uMk4JZmVatgj33hIMPzu5Xrao6IrMtOCmYlWViAlasgI0bYcOG7H7FCtcYLClOCmZlWbsW5s3bsmzu3KzcLBFOCmZlGR+H++/fsmzTpqzcLBFOCilwx+NoGBuDlSth/nxYuDC7X7kyKzdLhJNC1dzxOFqWL4dbb4Xzz8/uly+vOiKzLRSWFCR9TtJ6Sdd1eO09kkLSrvlzSTpR0k2SrpG0f1FxJcUdj6NpbAyWLXMNwZJUZE3hVOAFUwsl7Q4cDPyirfgQYO/8diTwbwXGlQ53PJpZYgpLChHxA+C3HV46HngvEG1lhwGfj8yPgR0lLSoqtmS449HMElNqn4KkQ4FfRsTVU17aDbit7fm6vKzZ3PFoZokp7SI7kh4KfAD4804vdyiLDmVIOpKsiYk99thjaPFVZvlyOOigrMlofNwJwcwqVWZN4THAo4GrJa0FFgNXSHokWc1g97b3LgZu7/QlEXFyRCyNiKVjKexAhzGcdBgdjx7WalZPif3vlpYUIuLaiHh4RIxHxDhZItg/In4FnAO8Nh+F9HRgQ0TcUVZsA0tlOGkqcVhzJbbjaowE/3cV0bGVZvZfLK0CngvsCvwa+HBErGx7fS2wNCLulCTgJLLRSn8AXh8RPS++vHTp0qjsGs0TE9lK3Lhxc9n8+dnY8zJrMKnEYc21alU2VHrevGxgxMqVPr9iGCr835V0eUQs7fRaYX0KETHtVpPXFlqPA3hrUbEUojWctH2FtoaTlrkzTiUOa6b2c2la29iKFVk/WPv2NTHhfrF+Jfq/6zOaB5XKcNJU4rBmmsm5NAk2gdRCov+7TgqDSmU4aSpxWDP12nH5rPzBJfq/W9qQ1EZKZThpKnFY87R2XCtWZDWETZu23HEl2gRSGwn+7xbW0VyGSjuazUZJtz4DD3Sopek6mt18ZGa9dTuXZmoTyHbbwbHHVhOjDYWTgpnNTms68L/9W5DgE59wh3ONOSmY2XB85CPucG4AJwUzmz1PA98YTgpmNnuJjrm3/jkpjKI6zmNTx5hHSaJj7q1/Tgqjpo5nn9Yx5lHk6083gs9TGCV1HFNex5jNEufzFCxTx87AOsbc4iYvqyEnhVFSx87AOsYMbvKy2nJSGCV17AysY8yzmSTOtQurmCfEGzUJTsDVU91iHnSSOF/MxhLgjmazYRukc9wd6lYidzSblWmQJq86d6hbo7j5yKwI/TZ51bVD3RrHNYVO3Nlnw9Btuulu761bh7o1UmFJQdLnJK2XdF1b2ccl3SDpGkn/KWnHttfeL+kmST+V9BdFxdWThxJaVXxGsCWgyJrCqcALppSdB+wXEU8Cfga8H0DSvsCrgCfmn/m0pG0KjK0zX2/WqtZP7cKsAIUlhYj4AfDbKWXfi4gH8qc/Bhbnjw8DvhwR90XELcBNwAFFxdaVO/vMRoubirdSZZ/C/wG+nT/eDbit7bV1edlWJB0pabWk1RPDXpHu7DMrX1U75n6bikckgVSSFCR9AHgA+FKrqMPbOp5AEREnR8TSiFg6Nuwqtjv7zMpVRh9ep515v03FI9TXWHpSkHQE8GLg1bH5zLl1wO5tb1sM3F52bIA7+8zKUkYfXredeT9NxSPW11hqUpD0AuB9wKER8Ye2l84BXiVpW0mPBvYGLi0zti24s89sS0U0nRTdhzfdzryfpuIR62ssckjqKuBiYB9J6yStAE4CtgfOk3SVpM8ARMT1wFeAnwDfAd4aEQ8WFZuZ9aGfppN+kkfRfXjT7cz7aSoedpyp901ERG1vS5YsCTMr0Pr1EfPnR8Dm2/z5WflUp5+evbbDDtn96af3/v7WZxYunPlnhhn7+vURl17aeXmKiHOQ36gAwOrosl/1hHjWPBMT6c2ommJMM3HZZVkNYcOGzWULF2Z9bsuWbS6bzYR+Rf42rZln587Nju5nM/PsbONMaNLD6SbE89xH1iwpTj89NaZjj4WXvhTuvTf9JDHTppNu7eu9pguH7PWifoNhTrs+2zgHnVK9ZJ77yJojxVEinWL60Idg333hOc9Jf3jjTNveFyzYcmcH2fMFC8qLtZtUBo7U5DwoJwVrjhRHiXSKqWXjxjQSVy8zGaZ9771Zwmi33XZZuWX66dyusDPazUfWHCkeiXWKaaoEmxC20qvppNNvLKVxFNzeFwDV9u3MpDmr4iZQ1xSsOVI8I709pm6qTlzDkOJvD1sOp128GHbbrfqzkqdrzkqgCdSjj6x5UhzpMzEBn/0sHHdc9vyPf9ycKFLoDB+WlH77TqN92qV4udOZjvaaJY8+stFS5GiWQY2NwQc/CG96U7bTXLCgHqOP+pXSb99ptE+7FJvtEmgCdVIwK1NKO82m69Wfk2Kz3dhY1lx00kmby1asKHWbcZ+CmTXT1H6OefOy2kFKfR5TTUxkcbVbubLUPgXXFMzKkFJbe1FSXMapo30gvRjbJXCCm2sKZkUbhbn4U17G9tE+U0f+pDY5XQJ9Ck4KZkVKYIhh4eq6jCkmsgSG9jopmBUpxbOsh62Oy5hyIqv4Ql/uUzArUgLNAYWr4zIm0HY/rQpHqbmmYFakBJoDClfHZaxjIiuJz2huuhRHhIyiUVgPdVvGYV5roWamO6PZSaHJUry2gFlK6pbIhsRJYRQldJUnM0vLdEnBfQpNVccRIWZWucKSgqTPSVov6bq2sp0lnSfpxvx+p7xckk6UdJOkayTtX1RcI8Mdac2X2olX1ghF1hROBV4wpewY4IKI2Bu4IH8OcAiwd347Evi3AuMaDXUcEWIzl+KJV9YIhfYpSBoHvhkR++XPfwo8NyLukLQIuCgi9pH02fzxqqnvm+773acwAyPakdZo7i+yWUqpT+ERrR19fv/wvHw34La2963Ly7Yi6UhJqyWtnnC1ubf2uV7c3NAM7i+yAqXS0awOZR2rMBFxckQsjYilYz4qmrk6Nzekksy6xVF2fO4vsgKVnRR+nTcbkd+vz8vXAbu3vW8xcHvJsTVXyvO89JJKMusWRxXxub/IClR2UjgHOCJ/fATw9bby1+ajkJ4ObOjVn2B9qGtzQyrJrFsca9ZUF98gk6alUuOypBU5JHUVcDGwj6R1klYAHwUOlnQjcHD+HOBc4GbgJuDfgbcUFddISr25odvOKpVktnYtzJkyd+TcuXDppdXGN/XaANNJpcZlyStsltSI6Hbo8vwO7w3grUXFMtJao4+OPx6OPnrLeV5SaG6YbiqOVJLZFVfAPfdsHccBB6QRXy/tNZ3WiKUVK7IrkqWwDVhSUulotiK0Hx0efXSWGCqao72jXs1DKbSdT0xkv91Uxx8PT3hC9fHNRCo1LqsFX0+hqTodHR59dFpj2Wcyp/3Ua+yWHXunGLffHvbfP434ZiKVGlfdjcg5P64pNFUdjg5nurPqp+182DrF+MADW8Y4k/iq7ORNocZVdyPUJ+Ok0FR1ODqsw85qGDGmsEOp+BKPtZbKKLiSeOrsJkvpIiLTVb27vZZSdX3QWDwlRf1ddlmW0Dds2Fy2cGGWYJctqy6uWUhpmgsrUypHh72OlDs1v6RwdD0MdWjGa7rZNt3VodY9RE4KTVdlezwMVvVOrbo+mwQ1YjuU5Azj4KIOzZxD5KRgmxXRGTrIkXJKR9ezTVAjtkNJyjAPLlKpdZfAScEyRTXXDHKknNLR9TAS1AjtUJIy7IOLqmvdJXFSsGKbawY5Up7t0fUwazzDSlAjskNJSkoHFzXipGDFN9cMcqQ86NH1sGs8bv6pL6+7gXhIqjVn2GSRy5HS8Fjrj9fdVjwk1aZX1yOqqc1ERdZ43PxTX153ffHcR5apwxw+7TrNrnrQQW5DNpsl1xRss7ocUXXrGId61nhGmS/8kxwnBauf6ZqJPPyzProNCnCiqJSbj6x+eg01HBtz7SB13S78c/fd2RTvnS66ZKVwTcHqp64d47ZZp9renDnwjncM/3yZsmseNa/pOClYPbmZqN461fbuv3/4o8fKnlixARM5VpIUJB0t6XpJ10laJWk7SY+WdImkGyWdIWle72+ykVaXjnHbWqfa3gknZBcwajeb0WNlT6yY2kSOAyo9KUjaDXg7sDQi9gO2AV4FfAw4PiL2Bu4CVpQdm5mVaGpt701vGm6zYNkTK6Y0keMsDJwUJJ0xi787B5gvaQ7wUOAO4HnAWfnrpwGHz+L7zawOptb2htks2O/cR77uAjC7msKBg3woIn4JfAL4BVky2ABcDvwuIlp1x3XAbp0+L+lISaslrZ6oWbXMzGZgWM2C/QxI8HUXJg0895GkX0TEHgN8bifgq8Argd8BZ+bPPxwRj83fsztwbkT8yXTf5bmPzKynXnMfDXvOrBrMtTTd3EfTnqcgaf9uLwFzB4znIOCWiJjI/8bZwDOAHSXNyWsLi4HbB/z++qnBRmRWW73OW2n1BbQnhVZfwCD/jzU/T6bXyWv/Ms1rNwz4N38BPF3SQ4GNwPOB1cCFwMuALwNHAF8f8PvrpdMcPh5eaVaehvQFDEslU2dL+gey5qMHgCuBN5D1IXwZ2Dkve01E3Dfd99S++agpU1ab1V3r4Gzu3CwhNPzgbDbNR381pSiAO4GrIuKeQQOKiA8DH55SfDNwwKDfWUvDrraa2WDqNktwgXo1H72kQ9nOwJMkrYiI7xcQ0+hwtdUsHTXvCxiWaZNCRLy+U7mkPYGvAE8rIqiR0RrCNrXa6g3TzCoy0CypEXGrpEFHH1k7V1vNLCEDJQVJ+wDTdgJbH1xttdnysGYbkl4dzd8g61xutzOwCHhNUUGZWR88rNmGaNohqZKeM6UogN8AN0bE/R0+UqraD0k1my0Pa7YBDDwkNSL+q8sXbiPp1RHxpWEEaGYD8rBmG7JpJ8STtFDS+yWdJOnPlTmK7JyCV5QTopl1Vfaw5ppfVcx66zVL6heAfYBryc46/h7ZVBSHRcRhBcdmZr2UOTNnA64qZr316lO4tjVTqaRtyM5m3mM2ZzMPk/sUzHJFjz5y30WjDNynAGxqPYiIByXdkkpCMLM2RQ9rdt/FyOiVFJ4s6e78sciulnZ3/jgiYmGh0Zn1w2P1i+MpWUbGtH0KEbFNRCzMb9tHxJy2x04Ilg63dxerIVcVs94qmTp7WNynYIDbu8vk2lgjzKZPwSx9bu8uj6dkabxeQ1LN0uf2brOhcVKw+nN7tw3KJ+NtxUnBmmH58qwP4fzzs3tPCGe9eHBCR+5oNrPRM+KDE6braHZNwcxGT2twQrvW4IQRV0lSkLSjpLMk3SBpjaQDJe0s6TxJN+b3O1URm5mNAA9O6KqqmsIJwHci4vHAk4E1wDHABRGxN3BB/tzMbPg8OKGr0vsUJC0Ergb2irY/LumnwHMj4g5Ji4CLImKf6b7LfQq2BZ9Y1QxlrscR3WZS61PYC5gA/kPSlZJOkfQw4BERcQdAfv/wTh+WdKSk1ZJWT3gYWX0NeyigR5I0Q9nrcWwMli0bqYTQSxU1haXAj4FnRsQlkk4A7gaOiogd2953V0RM26/gmkJNDfuawiM+kqQxmrQeE6+BpFZTWAesi4hL8udnAfsDv86bjcjv11cQmxVtYiJLCBs3woYN2f2KFbOrMXgkSTM0ZT3WvNZaelKIiF8Bt0lq9Rc8H/gJcA5wRF52BPD1smOzEhTxj++RJM3QhPVYxEFPyaoafXQU8CVJ1wBPAT4CfBQ4WNKNwMH5c2uafv/xZ9L34JEkzdCE9diA2o7PaLbytfoU5s7NEkK3PoV++x4Sb8e1GarzeqxJv8h0fQpOClaNXv/4NfnnsjZ13pkP00wPeirk6ylYenrNy+9rJNTLsEeU1dny5XDQQbVNkJ77yNLUhE7HUdGAztWhq/H5D04KlqYmdDqOigZ0rtpmbj6ydNW8Gj4yXKtrFNcUrLcqr05V42r4yGiv1S1YANtuC8cf73XWTeJXe3NSsOnV/OxMK8ny5Vki2LQpa0o6+mhvK53U4P/JQ1KtOw8LtZnyttJbQr9RanMfWV24A9FmyttKb51+ozlz4Nxzk2pKclKw7tyBaDPlbaW3Tr/RPffAUUcl1ZTkpGDdpTosNPGOupGU6raSkvbfaPvtN5ffc09S53a4T8F6S2n6Ap85m7aUtpVUTUxkTUZHHZUlhJaFC+H887PRdgXz3EfWDAl11JnNSsXbsjuarRncmWlNkXBzm89otvpwZ6Y1SaJn7LumYPWR8NGV2UASPGPfNQWrl0SPrsyawknB6qfXtRjMbGBuPjIzs0mVJQVJ20i6UtI38+ePlnSJpBslnSFpXq/vMDOz4aqypvAOYE3b848Bx0fE3sBdwIpKojIzG2GVJAVJi4EXAafkzwU8Dzgrf8tpwOFVxGZmNsqqqil8Engv8L/5812A30XEA/nzdcBuVQRmZjbKSk8Kkl4MrI+Iy9uLO7y14/wbko6UtFrS6okEJo9KkieMM7MBVVFTeCZwqKS1wJfJmo0+CewoqTVEdjFwe6cPR8TJEbE0IpaOeVji1qq+spMTklmtlZ4UIuL9EbE4IsaBVwHfj4hXAxcCL8vfdgTw9bJjq72JiWwG0Y0bYcOG8qfjrTohmdmspXSewvuAd0m6iayPYWXF8dRPlRPGVZ2QzGwoKj2jOSIuAi7KH98MHFBlPLVX5YRxrYTUPhVwKyG5mc+sNlKqKdhsVTlhXFkJyX0WZoVyUmia5cuzC3Wcf352X9ZVycpISO6zMCucr7xmw1XU5Rh91TWzoZnuymueJdWGq6gZTN1nYVYKNx9ZPfiqa2alcFKwevBV18xK4eYjqw9fdc2scE4KVi++6lraihpoYKVx85GZDYeHDDeCk8IoqvMJYHWOvclGYZqTfra9Gm+nTgqjps5Hc3WOvemqnHerDP1sezXfTn3y2iip8wlgdY59FDR5/fSzbDX5HaY7ec01hVFS56O5Osc+Cpo8ZLifba8B26lHH42SOp8AVufYR0VThwz3s+2Nj8Mf/rBl2caNtdpOXVMYJXU+mqtz7KNkbAyWLWvWeul325Omf5449ymMojqPJa9z7FZvM9n2Lrss62DesGFz2cKF2azFy5aVEeWMeEI821KdTwCrc+xWbzPZ9hrQzOnmIzOzYWlAM6drCmZmw1TzDncnBbOU1LHPJPWYq4ivxs2cpTcfSdpd0oWS1ki6XtI78vKdJZ0n6cb8fqeyY+tbjU9lL4x/k8HV8UzY1GPuFZ+3161FRKk3YBGwf/54e+BnwL7APwPH5OXHAB/r9V1LliyJypx+esT8+RE77JDdn356dbGkwr/J4Navz34z2HybPz8rT1XqMfeKb4S3V2B1dNmvll5TiIg7IuKK/PE9wBpgN+Aw4LT8bacBh5cd24yNwuRf/UrpN6nj0V8dz4RNPebp4ktpe01MpaOPJI0DTwUuAR4REXdAljiAh3f5zJGSVktaPVHVCkz9n6EKqfwmqTdndFO3oYwTE3DXXWnHPN1vmsr2mqDKkoKkBcBXgXdGxN0z/VxEnBwRSyNi6VhVHTl1+wcuQwq/SZ2P/uo0lLGVeF/xCnjggWznmmLM0/2mKWyviaokKUiaS5YQvhQRZ+fFv5a0KH99EbC+ithmpE7/wGVJ4Tep+9Hf8uXZbJrnn5/dL19edURbm5p4N22ChzwEzjwzzZi7/aYpbK+JKn2aC0ki6zP4bUS8s63848BvIuKjko4Bdo6I9073XZVPc5H6ULwqVPmbpDRtcVO3jZpM4zBjTV1PPaQ2zcUzgb8BrpV0VV52LPBR4CuSVgC/AF5eQWz9qfFY5MJU+Zu0jv5WrMhqCJs2VXP0t2pVFsO8eVkTxcqV6R1BD6ppzS7+H96KJ8Sz3up2NOXaSrFaSa898TYl6Y0IX2THBlfH0TxVTt9c936NmahD30e7Og5RrpCTgnVX59E8VWla80o3dbluQh0PairmpGDdjcJR77B5VEs6fFAzEE+IZ92NylHvsNV8lszGaB3UtPfvtA5qvE66ck3BuvNR7+Dq0rxShqra9H1QMxAnBZte3ToVLS1Vtun7oGYgHpJqZsXoNjz38svh3nvLa1orcohy3YZr5zwk1cyK1amJqNNAhQh46lPLrTkU1ZTX0JFNTgpmNjvddo6d2vT/+Ee47776jwZq8MgmJwWzmeqnw3RUTpiabuc4tU1/222zx+2qHuI86Hpq8HBtJwWzmeinqaChzQod9do5tg9UuPLKrT9f5Wig2aynXiOb6nxQ0O2SbHW4VXo5Thsd/Vx2MvVLVA5bv8vbugTmwoXVXgJzGOup27LU4DKfpHQ5TrPa6aepoMHNCh31O+wzlSHOw1hPnZalAX0NPqPZrJd+ToIaxROm+j2DO4Xpqoe1nqYuSwPOonZNwayXfo6GR/WEqbqdwV3UemrAQYFPXjObqX5OVKrpSU0jp4j1VIPrTUx38pqTgpnZsCV+UJDa5TjNzJothX6TAblPwczMJjkpmJnZJCcFMzOb5KRgZmaTnBTMzGxSrYekSpoAbq06jiHYFbiz6iBK4mVtrlFa3rov654R0XF4VK2TQlNIWt1tzHDTeFmba5SWt8nL6uYjMzOb5KRgZmaTnBTScHLVAZTIy9pco7S8jV1W9ymYmdkk1xTMzGySk4KZmU1yUhgCSTtKOkvSDZLWSDqw7bX3SApJu+bPXy3pmvz2P5Ke3OO7PyXp3rbn20o6Q9JNki6RNF7UcnWJp8xlfZ2kCUlX5bc3FLdkXWMa+vJKOlXSLW3L9ZS8XJJOzNftNZL2L2cpJ+Mqc1mfK2lDW/nflbOUk3EVsaySdJykn+Xf+fa28srWa9+6XbzZt5nfgNOAN+SP5wE75o93B75LdoLdrnnZM4Cd8seHAJdM871LgS8A97aVvQX4TP74VcAZDV7W1wEnNW3dAqcCL+tQ/kLg24CAp0/3ezVgWZ8LfLNh6/X1wOeBh+TPH57Ceu37t6k6gLrfgIXALeSd9lNeOwt4MrC2tYFNeX0n4Jddvncb4EJg0ZQd5XeBA/PHc8jOqtzqbzdkWStNCgUub7cd5WeB5W3PfwosauiyVpYUClzWS4HHprReB7m5+Wj29gImgP+QdKWkUyQ9TNKhZBvP1dN8dgXZEUQnbwPOiYg7ppTvBtwGEBEPABuAXWa1BDNX9rICvDSvcp8laffZhd+3opYX4Lh8uY6XtG1eNrluc+vysjKUvawAB0q6WtK3JT1xCMswU0Ut62OAV0panS/T3nl5leu1f1VnpbrfyJo9HgCelj8/Afg4cAmwQ162lilHHcCfAWuAXTp856OAHwFz8uftR8/XA4vbnv+803c0ZFl3AbbNH78Z+H7d123++iKypoRtyZox/i4v/xbwrLb3XQAsaeiyLgQW5I9fCNzYgPV6L/Du/PFfAT+ser0O9PtUHUDdb8AjgbVtz5+dr/T1+Ya1Nt8AfwE8Mn/Pk8h25o/r8p0vAn7V9vn/BW7KX6uy+ajUZZ3yvm2ADXVftx3+xnPJm1Gotvmo1GXt8NpaOjTX1GlZgeYYvDwAAASQSURBVBuA8fyxWttrlet1kJubj2YpIn4F3CZpn7zo+cAVEfHwiBiPiHGy6uL+EfErSXsAZwN/ExE/6/Kd34qIR7Z9/g8R8dj85XOAI/LHLyM7eo5ilm6ruEpdVkmL2t56KNlRWmmKWF7YvFySBBwOXJe/dA7w2ny0ytPJdiqdmtSGruxllfTIvAxJB5CNhPxNMUu3paKWFfga8Lz88XOA1nsrW68DqTorNeEGPAVYDVxDtmHsNOX1tWweyXAKcBdwVX5b3fa+c4FHdfj+9iaV7YAzgZvIOrb2avCy/l+y5rKryTqiH9+EdQt8H7iWbAf5RTY3owj4V7Ij0muBpQ1e1re1rdsfA89owLLuSNZUdC1wMfDkFNZrvzdPc2FmZpPcfGRmZpOcFMzMbJKTgpmZTXJSMDOzSU4KZmY2yUnBzMwmOSlYo0n6gKTr87l3rpL0tJL//kMlfSufovl6SR+d4eeulrSq6PjMpppTdQBmRcnnyH8x2Zmp9+Xz488r8e8rf/iJiLhQ0jzgAkmHRETXCeQkPYHsgO1PJT0sIn5fRrxm4JqCNdsi4M6IuA8gIu6MiNslLZH0X5Iul/TdtqkYLpL0MUmX5hdKeXZe/sS87Kq8xrF3Xv4uSdflt3fmZeP5BVY+DVwBjEXEhfnfvz8vW9wj7r8mu7bE98im90DSEyRd2npD/neuyR+/MK+J/Ci/mMs3h/T72QhyUrAm+x6we76D/7Sk50iaC3yKbI7/JcDngOPaPjMnIg4A3gl8OC97M3BCRDyFbIbNdZKWkF1U5WlkF055o6Sn5u/fB/h8RDw1Im5tfbGkHYGXkE2+Np1XAmcAq4DlABGxBpgnaa+293xF0nZkE64dEhHPAsb6+YHMpnJSsMaKiHuBJcCRZPPnnwG8CdgPOE/SVcAH2fLI/ez8/nJgPH98MXCspPcBe0bERuBZwH9GxO/zv3M22WybALdGxI/bY5E0h2wnf2JE3NwtZknLgIk8mVwA7C9pp/zlrwCvyB+3EsfjgZsj4pa83P0QNivuU7BGi4gHgYuAiyRdC7wVuD4iDuzykfvy+wfJ/z8i4nRJl5BN8/1dZdeKVpfPA3TqAziZ7JoBn+wR8nLg8ZLW5s8XAi8lm5TtDOBMSWdnYcWNbbUTs6FwTcEaS9I+bVe/gmxmzDXAWN4JjaS5va76lTfZ3BwRJ5JNg/wk4AfA4fnooocBfwn8sMvn/wnYgaxJarq/8xDg5cCTYvMUzoexuQnp52TJ6kNkCQKyOfz3kjSeP3/ldH/DrBfXFKzJFgCfytvyHyCbbvxIsqP2EyXtQPY/8EmyaZy7eSXwGkmbyC4I9I8R8VtJp5JNXw5wSkRc2bZzBkDSYuADZDvvK/IBSSdFxCkd/s6fkl0O8pdtZT8A9pW0KLI5+M8gu0rYowEiYqOktwDfkXRnWzxmA/HU2WY1J2lBRNybD4H9V7JmquOrjsvqyc1HZvX3xrzT/HqyZqrPVhyP1ZhrCmYVkPQBsv6DdmdGxHGd3m9WFicFMzOb5OYjMzOb5KRgZmaTnBTMzGySk4KZmU36/9f6+LVVoJGAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot \n",
    "df_avg1.plot(kind = 'scatter', \n",
    "        x = 'Sensor2_Avg', \n",
    "        y = 'RUL', \n",
    "        color = 'red') \n",
    "  \n",
    "# set the title \n",
    "plt.title('ScatterPlot') \n",
    "  \n",
    "# show the plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot \n",
    "df_avg1.plot(kind = 'scatter', \n",
    "        x = 'Sensor3_Avg', \n",
    "        y = 'RUL', \n",
    "        color = 'red') \n",
    "  \n",
    "# set the title \n",
    "plt.title('ScatterPlot') \n",
    "  \n",
    "# show the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot \n",
    "df_avg1.plot(kind = 'scatter', \n",
    "        x = 'Sensor4_Avg', \n",
    "        y = 'RUL', \n",
    "        color = 'red') \n",
    "  \n",
    "# set the title \n",
    "plt.title('ScatterPlot') \n",
    "  \n",
    "# show the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot \n",
    "df_avg1.plot(kind = 'scatter', \n",
    "        x = 'Sensor7_Avg', \n",
    "        y = 'RUL', \n",
    "        color = 'red') \n",
    "  \n",
    "# set the title \n",
    "plt.title('ScatterPlot') \n",
    "  \n",
    "# show the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot \n",
    "df_avg1.plot(kind = 'bar', \n",
    "        x = 'Sensor4_Avg', \n",
    "        y = 'RUL', \n",
    "        color = 'red') \n",
    "  \n",
    "# set the title \n",
    "plt.title('BarPlot') \n",
    "  \n",
    "# show the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot \n",
    "df_avg1.plot(kind = 'kde', \n",
    "        x = 'RUL', \n",
    "        y = 'Sensor4_Avg', \n",
    "        color = 'red') \n",
    "  \n",
    "# set the title \n",
    "plt.title('KdePlot') \n",
    "  \n",
    "# show the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg1 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD001_avg_col_dropped.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor11_Avg</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "      <th>Sensor21_Avg</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>642.621042</td>\n",
       "      <td>1589.485521</td>\n",
       "      <td>1407.262135</td>\n",
       "      <td>553.439427</td>\n",
       "      <td>9048.265833</td>\n",
       "      <td>47.514063</td>\n",
       "      <td>521.459427</td>\n",
       "      <td>2388.110833</td>\n",
       "      <td>8128.913542</td>\n",
       "      <td>8.436555</td>\n",
       "      <td>392.854167</td>\n",
       "      <td>38.840052</td>\n",
       "      <td>23.306310</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642.423031</td>\n",
       "      <td>1587.581533</td>\n",
       "      <td>1403.757247</td>\n",
       "      <td>553.795993</td>\n",
       "      <td>9049.902927</td>\n",
       "      <td>47.395958</td>\n",
       "      <td>521.780592</td>\n",
       "      <td>2388.075854</td>\n",
       "      <td>8131.658467</td>\n",
       "      <td>8.422551</td>\n",
       "      <td>392.351916</td>\n",
       "      <td>38.906376</td>\n",
       "      <td>23.343887</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642.545363</td>\n",
       "      <td>1588.757709</td>\n",
       "      <td>1405.981564</td>\n",
       "      <td>553.575196</td>\n",
       "      <td>9048.757151</td>\n",
       "      <td>47.471285</td>\n",
       "      <td>521.570782</td>\n",
       "      <td>2388.098771</td>\n",
       "      <td>8129.803520</td>\n",
       "      <td>8.431322</td>\n",
       "      <td>392.631285</td>\n",
       "      <td>38.865140</td>\n",
       "      <td>23.323317</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>642.606984</td>\n",
       "      <td>1589.302804</td>\n",
       "      <td>1406.959841</td>\n",
       "      <td>553.475714</td>\n",
       "      <td>9048.415238</td>\n",
       "      <td>47.502487</td>\n",
       "      <td>521.484233</td>\n",
       "      <td>2388.107460</td>\n",
       "      <td>8129.170794</td>\n",
       "      <td>8.435278</td>\n",
       "      <td>392.804233</td>\n",
       "      <td>38.845873</td>\n",
       "      <td>23.310315</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>642.448922</td>\n",
       "      <td>1587.766022</td>\n",
       "      <td>1404.140409</td>\n",
       "      <td>553.753717</td>\n",
       "      <td>9049.710446</td>\n",
       "      <td>47.409368</td>\n",
       "      <td>521.728699</td>\n",
       "      <td>2388.080186</td>\n",
       "      <td>8131.302937</td>\n",
       "      <td>8.424452</td>\n",
       "      <td>392.423792</td>\n",
       "      <td>38.898327</td>\n",
       "      <td>23.339687</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor7_Avg  Sensor9_Avg  \\\n",
       "0   642.621042  1589.485521  1407.262135   553.439427  9048.265833   \n",
       "1   642.423031  1587.581533  1403.757247   553.795993  9049.902927   \n",
       "2   642.545363  1588.757709  1405.981564   553.575196  9048.757151   \n",
       "3   642.606984  1589.302804  1406.959841   553.475714  9048.415238   \n",
       "4   642.448922  1587.766022  1404.140409   553.753717  9049.710446   \n",
       "\n",
       "   Sensor11_Avg  Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  \\\n",
       "0     47.514063    521.459427   2388.110833   8128.913542      8.436555   \n",
       "1     47.395958    521.780592   2388.075854   8131.658467      8.422551   \n",
       "2     47.471285    521.570782   2388.098771   8129.803520      8.431322   \n",
       "3     47.502487    521.484233   2388.107460   8129.170794      8.435278   \n",
       "4     47.409368    521.728699   2388.080186   8131.302937      8.424452   \n",
       "\n",
       "   Sensor17_Avg  Sensor20_Avg  Sensor21_Avg  RUL  \n",
       "0    392.854167     38.840052     23.306310  112  \n",
       "1    392.351916     38.906376     23.343887   98  \n",
       "2    392.631285     38.865140     23.323317   69  \n",
       "3    392.804233     38.845873     23.310315   82  \n",
       "4    392.423792     38.898327     23.339687   91  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1800 with 14 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in df_avg1:\n",
    "    if plotnumber<=16 :\n",
    "        ax = plt.subplot(4,4,plotnumber)\n",
    "        sns.distplot(df_avg1[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_avg1.drop(labels='RUL', axis=1)\n",
    "y=df_avg1['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x2160 with 13 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,30), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in x:\n",
    "    if plotnumber<=21 :\n",
    "        ax = plt.subplot(5,3,plotnumber)\n",
    "        plt.scatter(x[column],y)\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        plt.ylabel('RUL',fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler =StandardScaler()\n",
    "\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "variables = x_scaled\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(variables, i) for i in range(variables.shape[1])]\n",
    "vif[\"Features\"] = x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>438.115691</td>\n",
       "      <td>Sensor2_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>694.077613</td>\n",
       "      <td>Sensor3_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1846.383539</td>\n",
       "      <td>Sensor4_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2298.848749</td>\n",
       "      <td>Sensor7_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263.654418</td>\n",
       "      <td>Sensor9_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2403.311286</td>\n",
       "      <td>Sensor11_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1803.274336</td>\n",
       "      <td>Sensor12_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2142.084756</td>\n",
       "      <td>Sensor13_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>798.932794</td>\n",
       "      <td>Sensor14_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1957.969438</td>\n",
       "      <td>Sensor15_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1282.880096</td>\n",
       "      <td>Sensor17_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1270.291991</td>\n",
       "      <td>Sensor20_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>713.562020</td>\n",
       "      <td>Sensor21_Avg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            VIF      Features\n",
       "0    438.115691   Sensor2_Avg\n",
       "1    694.077613   Sensor3_Avg\n",
       "2   1846.383539   Sensor4_Avg\n",
       "3   2298.848749   Sensor7_Avg\n",
       "4    263.654418   Sensor9_Avg\n",
       "5   2403.311286  Sensor11_Avg\n",
       "6   1803.274336  Sensor12_Avg\n",
       "7   2142.084756  Sensor13_Avg\n",
       "8    798.932794  Sensor14_Avg\n",
       "9   1957.969438  Sensor15_Avg\n",
       "10  1282.880096  Sensor17_Avg\n",
       "11  1270.291991  Sensor20_Avg\n",
       "12   713.562020  Sensor21_Avg"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = np.array(x)\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(variables, i) for i in range(13)]\n",
    "vif[\"Features\"] = x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.034580e+10</td>\n",
       "      <td>Sensor2_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.359769e+09</td>\n",
       "      <td>Sensor3_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.853099e+09</td>\n",
       "      <td>Sensor4_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.318754e+10</td>\n",
       "      <td>Sensor7_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.963808e+10</td>\n",
       "      <td>Sensor9_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.116370e+09</td>\n",
       "      <td>Sensor11_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.988761e+10</td>\n",
       "      <td>Sensor12_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.166829e+10</td>\n",
       "      <td>Sensor13_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.166189e+10</td>\n",
       "      <td>Sensor14_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.481593e+09</td>\n",
       "      <td>Sensor15_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.120599e+09</td>\n",
       "      <td>Sensor17_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.981275e+09</td>\n",
       "      <td>Sensor20_Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.959164e+09</td>\n",
       "      <td>Sensor21_Avg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VIF      Features\n",
       "0   4.034580e+10   Sensor2_Avg\n",
       "1   3.359769e+09   Sensor3_Avg\n",
       "2   1.853099e+09   Sensor4_Avg\n",
       "3   3.318754e+10   Sensor7_Avg\n",
       "4   5.963808e+10   Sensor9_Avg\n",
       "5   2.116370e+09  Sensor11_Avg\n",
       "6   2.988761e+10  Sensor12_Avg\n",
       "7   7.166829e+10  Sensor13_Avg\n",
       "8   5.166189e+10  Sensor14_Avg\n",
       "9   4.481593e+09  Sensor15_Avg\n",
       "10  3.120599e+09  Sensor17_Avg\n",
       "11  1.981275e+09  Sensor20_Avg\n",
       "12  1.959164e+09  Sensor21_Avg"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data visualisation\n",
    "# Look at correlations between features and the label\n",
    "\n",
    "# Set figure size \n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# Plot a correlation matrix\n",
    "plt.imshow(df_avg1.corr(),  interpolation='nearest', aspect='auto')\n",
    "\n",
    "# Display legend showing what the colours mean\n",
    "plt.colorbar()\n",
    "\n",
    "# Add tick marks and feature names\n",
    "tick_marks = [i for i in range(len(df_avg1.columns))]\n",
    "plt.xticks(tick_marks, df_avg1.columns, rotation='vertical')\n",
    "plt.yticks(tick_marks, df_avg1.columns)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=x_scaled, columns= x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(df)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=4)\n",
    "pca = PCA(n_components=3)\n",
    "new_data = pca.fit_transform(df)\n",
    "# This will be the new data fed to the algorithm.\n",
    "#principal_Df = pd.DataFrame(data = new_data\n",
    "#             , columns = ['principal component 1', 'principal component 2','principal component 3','principal component 4'])\n",
    "principal_Df = pd.DataFrame(data = new_data\n",
    "             , columns = ['principal component 1', 'principal component 2','principal component 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>principal component 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.122723</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.113245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.736722</td>\n",
       "      <td>0.333311</td>\n",
       "      <td>-0.103070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.453923</td>\n",
       "      <td>-0.122032</td>\n",
       "      <td>-0.050520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.216810</td>\n",
       "      <td>0.047429</td>\n",
       "      <td>0.131668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.511543</td>\n",
       "      <td>0.297765</td>\n",
       "      <td>-0.101712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2  principal component 3\n",
       "0              -5.122723               0.033101               0.113245\n",
       "1               4.736722               0.333311              -0.103070\n",
       "2              -1.453923              -0.122032              -0.050520\n",
       "3              -4.216810               0.047429               0.131668\n",
       "4               3.511543               0.297765              -0.101712"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principal_Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>principal component 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.159698</td>\n",
       "      <td>1.421303</td>\n",
       "      <td>0.229846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-3.415259</td>\n",
       "      <td>0.152242</td>\n",
       "      <td>0.044716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.081635</td>\n",
       "      <td>-0.600591</td>\n",
       "      <td>0.064584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-3.108045</td>\n",
       "      <td>-0.062622</td>\n",
       "      <td>0.077473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-3.773592</td>\n",
       "      <td>0.124045</td>\n",
       "      <td>0.049086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    principal component 1  principal component 2  principal component 3\n",
       "95               7.159698               1.421303               0.229846\n",
       "96              -3.415259               0.152242               0.044716\n",
       "97               3.081635              -0.600591               0.064584\n",
       "98              -3.108045              -0.062622               0.077473\n",
       "99              -3.773592               0.124045               0.049086"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principal_Df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD001_avg_col_dropped.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1=data_rf.drop(labels='RUL', axis=1)\n",
    "#y1=data_rf['RUL']\n",
    "x1 = principal_Df\n",
    "y1=data_rf['RUL']\n",
    "scaled_y1 = scaler.fit_transform(np.array(y1).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1,test_x1,train_y1,test_y1=train_test_split(x1,y1,test_size=0.5,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=None,\n",
       "                      oob_score=False, random_state=101, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators=5,criterion='mse',min_samples_split=2,max_features='auto',bootstrap=False,random_state=101,verbose=0)\n",
    "model_rf.fit(train_x1, train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6972987095309683"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_rf(x,y):\n",
    "    r2 = model_rf.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6775573210221184"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6997942762401257"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8106504246905686"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16556124,  0.75753892,  0.6275926 ,  1.59978359,  1.59978359,\n",
       "        0.10780732, -0.15689815, -1.42026516, -0.30128295, -0.30128295,\n",
       "        0.42064105,  0.73507906, -1.45154853,  0.10780732,  0.73507906,\n",
       "        0.27144343,  0.73507906, -1.33604069, -0.74406301, -0.92695042,\n",
       "        0.05967905,  0.73507906, -0.42160362,  0.51689759,  0.95005199,\n",
       "        0.42064105, -0.15689815, -0.39753949, -0.15689815,  0.37251279,\n",
       "       -0.66224495,  1.59978359,  1.26288573, -0.31331502,  0.10780732,\n",
       "        0.46876932, -0.39753949, -0.74406301, -1.42026516, -0.66224495,\n",
       "        1.20994463, -0.66224495, -0.30128295, -0.15689815, -0.21705848,\n",
       "       -0.08470575,  1.16662919,  0.75753892, -0.022139  , -1.14352762])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.predict(test_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.02224439],\n",
       "       [-0.51786015],\n",
       "       [-0.90288629],\n",
       "       [ 1.09443679],\n",
       "       [-1.33604069],\n",
       "       [ 0.95005199],\n",
       "       [ 0.97411612],\n",
       "       [-0.44566775],\n",
       "       [ 0.08374318],\n",
       "       [-1.62481029],\n",
       "       [ 1.02224439],\n",
       "       [-1.43229722],\n",
       "       [ 0.15593558],\n",
       "       [ 0.92598786],\n",
       "       [-1.62481029],\n",
       "       [-1.45636136],\n",
       "       [-1.62481029],\n",
       "       [ 0.73347479],\n",
       "       [-1.60074616],\n",
       "       [-1.33604069],\n",
       "       [ 0.54096172],\n",
       "       [ 0.51689759],\n",
       "       [ 1.47946293],\n",
       "       [ 1.21475746],\n",
       "       [-0.61411669],\n",
       "       [-1.14352762],\n",
       "       [ 1.45539879],\n",
       "       [-0.22909055],\n",
       "       [-1.55261789],\n",
       "       [-0.49379602],\n",
       "       [ 0.80566719],\n",
       "       [ 1.47946293],\n",
       "       [ 0.22812799],\n",
       "       [ 0.15593558],\n",
       "       [-0.61411669],\n",
       "       [ 0.34844865],\n",
       "       [ 0.17999972],\n",
       "       [ 1.43133466],\n",
       "       [-1.14352762],\n",
       "       [ 0.87785959],\n",
       "       [ 0.58908999],\n",
       "       [ 1.47946293],\n",
       "       [ 1.04630852],\n",
       "       [ 0.34844865],\n",
       "       [ 0.27625625],\n",
       "       [ 0.49283345],\n",
       "       [-1.31197656],\n",
       "       [-1.38416896],\n",
       "       [ 0.03561492],\n",
       "       [-0.99914282]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines : SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_svr = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD001_avg_col_dropped.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x2=data_svr.drop(labels='RUL', axis=1)\n",
    "x2=principal_Df\n",
    "y2=data_svr['RUL']\n",
    "scaled_y2 = scaler.fit_transform(np.array(y2).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x2,test_x2,train_y2,test_y2=train_test_split(x2,scaled_y2,test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1, cache_size=200, coef0=0.0, degree=8, epsilon=0.2,\n",
       "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svr = SVR(kernel='linear',degree=8,C=1,epsilon=0.2)\n",
    "model_svr.fit(train_x2, train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.006262217160103668"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svr.score(train_x2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_svr(x,y):\n",
    "    r2 = model_svr.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04718025032941475"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_svr(train_x2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20551632044179913"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svr.score(test_x2,test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.29481382565971015"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_svr(test_x2,test_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussion Process Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF,DotProduct, WhiteKernel,Kernel,Matern,RationalQuadratic,ConstantKernel,ExpSineSquared\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gpr = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD001_avg_col_dropped.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x3=data_gpr.drop(labels='RUL', axis=1)\n",
    "x3=principal_Df\n",
    "y3=data_gpr['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x3,test_x3,train_y3,test_y3=train_test_split(x3,y3,test_size=0.3,random_state=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
       "                         n_restarts_optimizer=0, normalize_y=False,\n",
       "                         optimizer='fmin_l_bfgs_b', random_state=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpr = GaussianProcessRegressor()\n",
    "model_gpr.fit(train_x3, train_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6220020182835041"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpr.score(train_x3,train_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_gpr(x,y):\n",
    "    r2 = model_gpr.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-388.5611613377326"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_gpr(train_x2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-860.265143077681"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpr.score(test_x2,test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scalled_x3 = scaler.fit_transform(x3)\n",
    "\n",
    "scalled_y3 = scaler.fit_transform(np.array(y3).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.52426402,  1.37610902,  1.38035942, ...,  1.43487334,\n",
       "        -1.47409532, -1.5019954 ],\n",
       "       [-1.43783469, -1.26101396, -1.22743127, ..., -1.2226755 ,\n",
       "         1.35894204,  1.16965062],\n",
       "       [ 0.39216487,  0.36805211,  0.4275582 , ...,  0.25554274,\n",
       "        -0.40247997, -0.29279888],\n",
       "       ...,\n",
       "       [-0.72658558, -0.97192122, -0.99530193, ..., -0.91398182,\n",
       "         0.87574156,  0.96841798],\n",
       "       [ 0.96367714,  0.90892442,  0.84768408, ...,  0.80504372,\n",
       "        -0.87831045, -0.82092523],\n",
       "       [ 1.04419465,  1.11229692,  1.07036437, ...,  1.06889288,\n",
       "        -1.0342201 , -1.10934838]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87785959],\n",
       "       [ 0.54096172],\n",
       "       [-0.15689815],\n",
       "       [ 0.15593558],\n",
       "       [ 0.37251279],\n",
       "       [ 0.42064105],\n",
       "       [ 0.37251279],\n",
       "       [ 0.46876932],\n",
       "       [ 0.85379546],\n",
       "       [ 0.49283345],\n",
       "       [ 0.51689759],\n",
       "       [ 1.16662919],\n",
       "       [ 0.46876932],\n",
       "       [ 0.75753892],\n",
       "       [ 0.17999972],\n",
       "       [ 0.20406385],\n",
       "       [-0.61411669],\n",
       "       [-1.14352762],\n",
       "       [ 0.27625625],\n",
       "       [-1.43229722],\n",
       "       [-0.44566775],\n",
       "       [ 0.85379546],\n",
       "       [ 0.90192372],\n",
       "       [-1.33604069],\n",
       "       [ 1.67197599],\n",
       "       [ 1.04630852],\n",
       "       [-0.22909055],\n",
       "       [ 0.51689759],\n",
       "       [ 0.34844865],\n",
       "       [ 0.95005199],\n",
       "       [-1.62481029],\n",
       "       [-0.66224495],\n",
       "       [ 0.73347479],\n",
       "       [-1.64887443],\n",
       "       [-1.55261789],\n",
       "       [-1.36010482],\n",
       "       [-1.31197656],\n",
       "       [-0.61411669],\n",
       "       [ 1.59978359],\n",
       "       [-1.14352762],\n",
       "       [-1.38416896],\n",
       "       [-1.57668203],\n",
       "       [-0.39753949],\n",
       "       [ 0.80566719],\n",
       "       [ 0.92598786],\n",
       "       [-0.68630909],\n",
       "       [ 1.43133466],\n",
       "       [ 0.39657692],\n",
       "       [-1.31197656],\n",
       "       [ 0.08374318],\n",
       "       [ 0.92598786],\n",
       "       [-1.11946349],\n",
       "       [-1.19165589],\n",
       "       [ 0.51689759],\n",
       "       [ 1.47946293],\n",
       "       [-1.45636136],\n",
       "       [ 0.66128239],\n",
       "       [-0.92695042],\n",
       "       [ 0.92598786],\n",
       "       [ 0.58908999],\n",
       "       [-1.31197656],\n",
       "       [-0.51786015],\n",
       "       [-0.08470575],\n",
       "       [-1.14352762],\n",
       "       [ 1.26288573],\n",
       "       [-1.48042549],\n",
       "       [ 0.03561492],\n",
       "       [-1.62481029],\n",
       "       [ 1.09443679],\n",
       "       [ 0.44470519],\n",
       "       [ 1.02224439],\n",
       "       [-0.61411669],\n",
       "       [ 1.33507813],\n",
       "       [ 1.21475746],\n",
       "       [ 0.90192372],\n",
       "       [-1.57668203],\n",
       "       [-0.99914282],\n",
       "       [ 0.75753892],\n",
       "       [-0.30128295],\n",
       "       [ 0.34844865],\n",
       "       [-1.62481029],\n",
       "       [-1.60074616],\n",
       "       [ 1.47946293],\n",
       "       [-0.42160362],\n",
       "       [ 1.02224439],\n",
       "       [ 0.32438452],\n",
       "       [ 0.97411612],\n",
       "       [ 0.95005199],\n",
       "       [ 1.45539879],\n",
       "       [-1.14352762],\n",
       "       [-0.90288629],\n",
       "       [-1.33604069],\n",
       "       [ 0.22812799],\n",
       "       [-0.49379602],\n",
       "       [ 1.26288573],\n",
       "       [ 1.47946293],\n",
       "       [ 0.15593558],\n",
       "       [-0.39753949],\n",
       "       [ 0.99818026],\n",
       "       [-1.33604069]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalled_y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x3_scalled,test_x3_scalled,train_y3_scalled,test_y3_scalled=train_test_split(scalled_x3,scalled_y3,test_size=0.3,random_state=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
       "                         n_restarts_optimizer=0, normalize_y=False,\n",
       "                         optimizer='fmin_l_bfgs_b', random_state=None)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpr = GaussianProcessRegressor()\n",
    "model_gpr.fit(train_x3_scalled, train_y3_scalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6220277688942146"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpr.score(train_x3_scalled,train_y3_scalled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitNumber</th>\n",
       "      <th>Time</th>\n",
       "      <th>Setting1</th>\n",
       "      <th>Setting2</th>\n",
       "      <th>Setting3</th>\n",
       "      <th>Sensor1</th>\n",
       "      <th>Sensor2</th>\n",
       "      <th>Sensor3</th>\n",
       "      <th>Sensor4</th>\n",
       "      <th>Sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor14</th>\n",
       "      <th>Sensor15</th>\n",
       "      <th>Sensor16</th>\n",
       "      <th>Sensor17</th>\n",
       "      <th>Sensor18</th>\n",
       "      <th>Sensor19</th>\n",
       "      <th>Sensor20</th>\n",
       "      <th>Sensor21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>BIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnitNumber  Time  Setting1  Setting2  Setting3  Sensor1  Sensor2  Sensor3  \\\n",
       "0           1     1   -0.0007   -0.0004       100   518.67   641.82  1589.70   \n",
       "1           1     2    0.0019   -0.0003       100   518.67   642.15  1591.82   \n",
       "2           1     3   -0.0043    0.0003       100   518.67   642.35  1587.99   \n",
       "3           1     4    0.0007    0.0000       100   518.67   642.35  1582.79   \n",
       "4           1     5   -0.0019   -0.0002       100   518.67   642.37  1582.85   \n",
       "\n",
       "   Sensor4  Sensor5  ...  Sensor14  Sensor15  Sensor16  Sensor17  Sensor18  \\\n",
       "0  1400.60    14.62  ...   8138.62    8.4195      0.03       392      2388   \n",
       "1  1403.14    14.62  ...   8131.49    8.4318      0.03       392      2388   \n",
       "2  1404.20    14.62  ...   8133.23    8.4178      0.03       390      2388   \n",
       "3  1401.87    14.62  ...   8133.83    8.3682      0.03       392      2388   \n",
       "4  1406.22    14.62  ...   8133.80    8.4294      0.03       393      2388   \n",
       "\n",
       "   Sensor19  Sensor20  Sensor21  RUL  BIN  \n",
       "0       100     39.06   23.4190  191    0  \n",
       "1       100     39.00   23.4236  190    0  \n",
       "2       100     38.95   23.3442  189    0  \n",
       "3       100     38.88   23.3739  188    0  \n",
       "4       100     38.90   23.4044  187    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['UnitNumber','Time','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','Sensor6','Sensor8','Sensor13','BIN'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor2</th>\n",
       "      <th>Sensor3</th>\n",
       "      <th>Sensor4</th>\n",
       "      <th>Sensor7</th>\n",
       "      <th>Sensor9</th>\n",
       "      <th>Sensor11</th>\n",
       "      <th>Sensor12</th>\n",
       "      <th>Sensor14</th>\n",
       "      <th>Sensor15</th>\n",
       "      <th>Sensor17</th>\n",
       "      <th>Sensor20</th>\n",
       "      <th>Sensor21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>554.36</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>392</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>553.75</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>392</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>554.26</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>390</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>554.45</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>392</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>554.00</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>393</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor2  Sensor3  Sensor4  Sensor7  Sensor9  Sensor11  Sensor12  Sensor14  \\\n",
       "0   641.82  1589.70  1400.60   554.36  9046.19     47.47    521.66   8138.62   \n",
       "1   642.15  1591.82  1403.14   553.75  9044.07     47.49    522.28   8131.49   \n",
       "2   642.35  1587.99  1404.20   554.26  9052.94     47.27    522.42   8133.23   \n",
       "3   642.35  1582.79  1401.87   554.45  9049.48     47.13    522.86   8133.83   \n",
       "4   642.37  1582.85  1406.22   554.00  9055.15     47.28    522.19   8133.80   \n",
       "\n",
       "   Sensor15  Sensor17  Sensor20  Sensor21  RUL  \n",
       "0    8.4195       392     39.06   23.4190  191  \n",
       "1    8.4318       392     39.00   23.4236  190  \n",
       "2    8.4178       390     38.95   23.3442  189  \n",
       "3    8.3682       392     38.88   23.3739  188  \n",
       "4    8.4294       393     38.90   23.4044  187  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor2</th>\n",
       "      <th>Sensor3</th>\n",
       "      <th>Sensor4</th>\n",
       "      <th>Sensor7</th>\n",
       "      <th>Sensor9</th>\n",
       "      <th>Sensor11</th>\n",
       "      <th>Sensor12</th>\n",
       "      <th>Sensor14</th>\n",
       "      <th>Sensor15</th>\n",
       "      <th>Sensor17</th>\n",
       "      <th>Sensor20</th>\n",
       "      <th>Sensor21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20626</th>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>551.43</td>\n",
       "      <td>9065.52</td>\n",
       "      <td>48.07</td>\n",
       "      <td>519.49</td>\n",
       "      <td>8137.60</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>397</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>550.86</td>\n",
       "      <td>9065.11</td>\n",
       "      <td>48.04</td>\n",
       "      <td>519.68</td>\n",
       "      <td>8136.50</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>395</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>550.94</td>\n",
       "      <td>9065.90</td>\n",
       "      <td>48.09</td>\n",
       "      <td>520.01</td>\n",
       "      <td>8141.05</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>398</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>550.68</td>\n",
       "      <td>9073.72</td>\n",
       "      <td>48.39</td>\n",
       "      <td>519.67</td>\n",
       "      <td>8139.29</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>395</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>550.79</td>\n",
       "      <td>9061.48</td>\n",
       "      <td>48.20</td>\n",
       "      <td>519.30</td>\n",
       "      <td>8137.33</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>396</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sensor2  Sensor3  Sensor4  Sensor7  Sensor9  Sensor11  Sensor12  \\\n",
       "20626   643.49  1597.98  1428.63   551.43  9065.52     48.07    519.49   \n",
       "20627   643.54  1604.50  1433.58   550.86  9065.11     48.04    519.68   \n",
       "20628   643.42  1602.46  1428.18   550.94  9065.90     48.09    520.01   \n",
       "20629   643.23  1605.26  1426.53   550.68  9073.72     48.39    519.67   \n",
       "20630   643.85  1600.38  1432.14   550.79  9061.48     48.20    519.30   \n",
       "\n",
       "       Sensor14  Sensor15  Sensor17  Sensor20  Sensor21  RUL  \n",
       "20626   8137.60    8.4956       397     38.49   22.9735    4  \n",
       "20627   8136.50    8.5139       395     38.30   23.1594    3  \n",
       "20628   8141.05    8.5646       398     38.44   22.9333    2  \n",
       "20629   8139.29    8.5389       395     38.29   23.0640    1  \n",
       "20630   8137.33    8.5036       396     38.37   23.0522    0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Data_for_Model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1800 with 13 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=16 :\n",
    "        ax = plt.subplot(4,4,plotnumber)\n",
    "        sns.distplot(data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(labels='RUL', axis=1)\n",
    "y=data['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x2160 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,30), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in x:\n",
    "    if plotnumber<=21 :\n",
    "        ax = plt.subplot(5,3,plotnumber)\n",
    "        plt.scatter(x[column],y)\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        plt.ylabel('RUL',fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler =StandardScaler()\n",
    "\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "variables = x_scaled\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(variables, i) for i in range(variables.shape[1])]\n",
    "vif[\"Features\"] = x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.606320</td>\n",
       "      <td>Sensor2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.273169</td>\n",
       "      <td>Sensor3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.453606</td>\n",
       "      <td>Sensor4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.196527</td>\n",
       "      <td>Sensor7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.819826</td>\n",
       "      <td>Sensor9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.750353</td>\n",
       "      <td>Sensor11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.090642</td>\n",
       "      <td>Sensor12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.765537</td>\n",
       "      <td>Sensor14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.243225</td>\n",
       "      <td>Sensor15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.532491</td>\n",
       "      <td>Sensor17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.025062</td>\n",
       "      <td>Sensor20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.063351</td>\n",
       "      <td>Sensor21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VIF  Features\n",
       "0    2.606320   Sensor2\n",
       "1    2.273169   Sensor3\n",
       "2    4.453606   Sensor4\n",
       "3    4.196527   Sensor7\n",
       "4   17.819826   Sensor9\n",
       "5    5.750353  Sensor11\n",
       "6    5.090642  Sensor12\n",
       "7   16.765537  Sensor14\n",
       "8    3.243225  Sensor15\n",
       "9    2.532491  Sensor17\n",
       "10   3.025062  Sensor20\n",
       "11   3.063351  Sensor21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data visualisation\n",
    "# Look at correlations between features and the label\n",
    "\n",
    "# Set figure size \n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# Plot a correlation matrix\n",
    "plt.imshow(data.corr(),  interpolation='nearest', aspect='auto')\n",
    "\n",
    "# Display legend showing what the colours mean\n",
    "plt.colorbar()\n",
    "\n",
    "# Add tick marks and feature names\n",
    "tick_marks = [i for i in range(len(data.columns))]\n",
    "plt.xticks(tick_marks, data.columns, rotation='vertical')\n",
    "plt.yticks(tick_marks, data.columns)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=x_scaled, columns= x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(df)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=7)\n",
    "new_data = pca.fit_transform(df)\n",
    "# This will be the new data fed to the algorithm.\n",
    "\n",
    "principal_Df = pd.DataFrame(data = new_data\n",
    "             , columns = ['principal component 1', 'principal component 2','principal component 3','principal component 4','principal component 5','principal component 6','principal component 7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>principal component 3</th>\n",
       "      <th>principal component 4</th>\n",
       "      <th>principal component 5</th>\n",
       "      <th>principal component 6</th>\n",
       "      <th>principal component 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.761120</td>\n",
       "      <td>-0.314558</td>\n",
       "      <td>0.820842</td>\n",
       "      <td>0.628245</td>\n",
       "      <td>-0.337177</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.626536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.265083</td>\n",
       "      <td>-0.686820</td>\n",
       "      <td>0.952779</td>\n",
       "      <td>0.285684</td>\n",
       "      <td>-0.026963</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.658051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.925173</td>\n",
       "      <td>-0.278908</td>\n",
       "      <td>0.607722</td>\n",
       "      <td>-1.102155</td>\n",
       "      <td>-0.438206</td>\n",
       "      <td>0.227749</td>\n",
       "      <td>0.099156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.705031</td>\n",
       "      <td>-0.136286</td>\n",
       "      <td>-0.369720</td>\n",
       "      <td>-0.057771</td>\n",
       "      <td>0.194052</td>\n",
       "      <td>-0.129542</td>\n",
       "      <td>-1.244472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.272433</td>\n",
       "      <td>-0.265696</td>\n",
       "      <td>-0.725754</td>\n",
       "      <td>0.362303</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>-0.492295</td>\n",
       "      <td>0.233475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2  principal component 3  \\\n",
       "0              -2.761120              -0.314558               0.820842   \n",
       "1              -2.265083              -0.686820               0.952779   \n",
       "2              -2.925173              -0.278908               0.607722   \n",
       "3              -3.705031              -0.136286              -0.369720   \n",
       "4              -2.272433              -0.265696              -0.725754   \n",
       "\n",
       "   principal component 4  principal component 5  principal component 6  \\\n",
       "0               0.628245              -0.337177               0.022542   \n",
       "1               0.285684              -0.026963              -0.314563   \n",
       "2              -1.102155              -0.438206               0.227749   \n",
       "3              -0.057771               0.194052              -0.129542   \n",
       "4               0.362303               0.056296              -0.492295   \n",
       "\n",
       "   principal component 7  \n",
       "0               0.626536  \n",
       "1               0.658051  \n",
       "2               0.099156  \n",
       "3              -1.244472  \n",
       "4               0.233475  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principal_Df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_rf = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Data_for_Model.csv\",header='infer')\n",
    "#data_xgb = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Data_for_Model.csv\",header='infer')\n",
    "#data_rf = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitNumber</th>\n",
       "      <th>Time</th>\n",
       "      <th>Setting1</th>\n",
       "      <th>Setting2</th>\n",
       "      <th>Setting3</th>\n",
       "      <th>Sensor1</th>\n",
       "      <th>Sensor2</th>\n",
       "      <th>Sensor3</th>\n",
       "      <th>Sensor4</th>\n",
       "      <th>Sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor14</th>\n",
       "      <th>Sensor15</th>\n",
       "      <th>Sensor16</th>\n",
       "      <th>Sensor17</th>\n",
       "      <th>Sensor18</th>\n",
       "      <th>Sensor19</th>\n",
       "      <th>Sensor20</th>\n",
       "      <th>Sensor21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>BIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnitNumber  Time  Setting1  Setting2  Setting3  Sensor1  Sensor2  Sensor3  \\\n",
       "0           1     1   -0.0007   -0.0004       100   518.67   641.82  1589.70   \n",
       "1           1     2    0.0019   -0.0003       100   518.67   642.15  1591.82   \n",
       "2           1     3   -0.0043    0.0003       100   518.67   642.35  1587.99   \n",
       "3           1     4    0.0007    0.0000       100   518.67   642.35  1582.79   \n",
       "4           1     5   -0.0019   -0.0002       100   518.67   642.37  1582.85   \n",
       "\n",
       "   Sensor4  Sensor5  ...  Sensor14  Sensor15  Sensor16  Sensor17  Sensor18  \\\n",
       "0  1400.60    14.62  ...   8138.62    8.4195      0.03       392      2388   \n",
       "1  1403.14    14.62  ...   8131.49    8.4318      0.03       392      2388   \n",
       "2  1404.20    14.62  ...   8133.23    8.4178      0.03       390      2388   \n",
       "3  1401.87    14.62  ...   8133.83    8.3682      0.03       392      2388   \n",
       "4  1406.22    14.62  ...   8133.80    8.4294      0.03       393      2388   \n",
       "\n",
       "   Sensor19  Sensor20  Sensor21  RUL  BIN  \n",
       "0       100     39.06   23.4190  191    0  \n",
       "1       100     39.00   23.4236  190    0  \n",
       "2       100     38.95   23.3442  189    0  \n",
       "3       100     38.88   23.3739  188    0  \n",
       "4       100     38.90   23.4044  187    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1=data_rf.drop(labels='RUL', axis=1)\n",
    "x1=data_xgb.drop(labels=['UnitNumber','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y1=data_rf['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1,test_x1,train_y1,test_y1=train_test_split(x1,y1,test_size=0.2,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_split=5,\n",
       "                      n_estimators=40, random_state=101)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators=40,criterion='mse',min_samples_split=5,max_features='log2',bootstrap=False,random_state=101,verbose=0)\n",
    "model_rf.fit(train_x1, train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953655943090917"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16504, 16)"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_rf(x,y):\n",
    "    r2 = model_rf.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995361096796442"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7219958312859408"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209135766145478"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "'max_depth': [3,5,6,10,20],\n",
    "'n_estimators':[10,20,40,50,75,100,200],\n",
    "'max_features':[\"auto\", \"sqrt\", \"log2\"],\n",
    "'min_samples_split':[1,2,3,5,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(RandomForestRegressor(),param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 525 candidates, totalling 2625 fits\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10, score=0.671, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10, score=0.681, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10, score=0.681, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10, score=0.673, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=10, score=0.680, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20, score=0.672, total=   0.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20, score=0.680, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20, score=0.685, total=   0.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20, score=0.676, total=   0.9s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=20, score=0.680, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40, score=0.673, total=   1.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40, score=0.683, total=   1.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40, score=0.684, total=   1.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40, score=0.676, total=   1.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=40, score=0.681, total=   1.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50, score=0.672, total=   1.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50, score=0.681, total=   1.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50, score=0.684, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50, score=0.678, total=   1.9s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=50, score=0.680, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75, score=0.673, total=   2.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75, score=0.681, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75, score=0.686, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75, score=0.678, total=   2.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=75, score=0.682, total=   2.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100, score=0.673, total=   3.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100, score=0.682, total=   3.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100, score=0.685, total=   3.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100, score=0.678, total=   3.8s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=100, score=0.681, total=   3.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200, score=0.673, total=   7.9s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200, score=0.681, total=   7.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200, score=0.686, total=   6.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200, score=0.677, total=   6.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=2, n_estimators=200, score=0.681, total=   6.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10, score=0.676, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10, score=0.681, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10, score=0.682, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10, score=0.677, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=10, score=0.680, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20, score=0.673, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20, score=0.679, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20, score=0.684, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20, score=0.674, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=20, score=0.684, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40, score=0.669, total=   1.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40, score=0.683, total=   1.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40, score=0.686, total=   1.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40, score=0.678, total=   1.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=40, score=0.681, total=   1.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50, score=0.674, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50, score=0.681, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50, score=0.684, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50, score=0.678, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=50, score=0.682, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75, score=0.672, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75, score=0.683, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75, score=0.685, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75, score=0.677, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=75, score=0.682, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100, score=0.673, total=   3.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100, score=0.683, total=   3.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100, score=0.685, total=   3.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100, score=0.678, total=   3.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=100, score=0.680, total=   3.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200, score=0.674, total=   6.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200, score=0.682, total=   6.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200, score=0.685, total=   6.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200, score=0.678, total=   6.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=3, n_estimators=200, score=0.681, total=   8.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10, score=0.669, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10, score=0.680, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10, score=0.679, total=   0.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10, score=0.673, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=10, score=0.676, total=   0.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20, score=0.671, total=   0.9s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20, score=0.680, total=   0.8s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20, score=0.685, total=   0.8s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20, score=0.675, total=   0.8s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=20, score=0.680, total=   0.8s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40, score=0.674, total=   1.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40, score=0.683, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40, score=0.687, total=   1.8s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40, score=0.678, total=   1.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=40, score=0.680, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50, score=0.668, total=   1.9s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50, score=0.680, total=   1.8s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50, score=0.685, total=   2.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50, score=0.679, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=50, score=0.681, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75, score=0.673, total=   2.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75, score=0.682, total=   2.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75, score=0.686, total=   2.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75, score=0.677, total=   2.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=75, score=0.680, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100, score=0.671, total=   3.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100, score=0.682, total=   3.1s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100, score=0.685, total=   3.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100, score=0.677, total=   3.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=100, score=0.681, total=   3.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200, score=0.673, total=   6.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200, score=0.682, total=   6.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200, score=0.686, total=   6.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200, score=0.678, total=   6.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=5, n_estimators=200, score=0.681, total=   6.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10, score=0.673, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10, score=0.681, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10, score=0.683, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10, score=0.677, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=10, score=0.677, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20, score=0.671, total=   0.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20, score=0.683, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20, score=0.686, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20, score=0.679, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=20, score=0.680, total=   0.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40, score=0.673, total=   1.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40, score=0.680, total=   1.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40, score=0.685, total=   1.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40, score=0.676, total=   1.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=40, score=0.682, total=   1.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50, score=0.671, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50, score=0.682, total=   1.8s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50, score=0.684, total=   1.7s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50, score=0.678, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=50, score=0.683, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75, score=0.672, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75, score=0.683, total=   2.5s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75, score=0.685, total=   3.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75, score=0.677, total=   3.4s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=75, score=0.682, total=   3.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100, score=0.674, total=   4.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100, score=0.682, total=   4.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100, score=0.685, total=   4.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100, score=0.678, total=   4.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=100, score=0.682, total=   4.2s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200, score=0.673, total=   8.0s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200, score=0.682, total=   6.6s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200, score=0.686, total=   6.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200, score=0.678, total=   6.3s\n",
      "[CV] max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=auto, min_samples_split=6, n_estimators=200, score=0.681, total=   6.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.650, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.682, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.673, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.664, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.666, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.648, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.669, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.659, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.658, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.653, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.671, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.657, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.665, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.670, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.676, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.656, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.676, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.679, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.669, total=   0.7s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.668, total=   0.7s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.661, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.675, total=   1.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.673, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.668, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.663, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.665, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.672, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.671, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.672, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.667, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.660, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.673, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.667, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.662, total=   2.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.671, total=   2.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.653, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.661, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.672, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.622, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.673, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.657, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.659, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.649, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.676, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.671, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.663, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.666, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.669, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.671, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.659, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.667, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.665, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.673, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.657, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.659, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.666, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.666, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.673, total=   0.9s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.666, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.670, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.668, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.675, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.669, total=   1.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.666, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.672, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.665, total=   2.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.672, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.670, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.672, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.669, total=   2.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.663, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.654, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.668, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.654, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.646, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.664, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.677, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.670, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.679, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.659, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.669, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.670, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.675, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.657, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.664, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.666, total=   0.6s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.665, total=   0.7s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.666, total=   0.6s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.660, total=   0.6s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.659, total=   0.6s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.662, total=   0.9s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.671, total=   0.9s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.671, total=   0.9s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.672, total=   0.9s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.668, total=   0.9s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.657, total=   1.3s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.670, total=   1.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.674, total=   1.3s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.674, total=   1.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.671, total=   1.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.667, total=   2.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.669, total=   2.7s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.673, total=   2.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.666, total=   2.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.662, total=   2.3s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.646, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.664, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.665, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.655, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.653, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.655, total=   0.3s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.663, total=   0.3s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.682, total=   0.3s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.668, total=   0.3s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.667, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.660, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.675, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.674, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.665, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.676, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.673, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.662, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.671, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.664, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.659, total=   0.5s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.668, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.669, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.669, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.662, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.672, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.663, total=   1.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.670, total=   1.1s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.669, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.674, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.669, total=   1.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.664, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.671, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.673, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.670, total=   2.0s\n",
      "[CV] max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.665, total=   2.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10, score=0.671, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10, score=0.665, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10, score=0.659, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10, score=0.662, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=10, score=0.659, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20, score=0.661, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20, score=0.664, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20, score=0.652, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20, score=0.655, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=20, score=0.654, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40, score=0.670, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40, score=0.672, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40, score=0.666, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40, score=0.679, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=40, score=0.649, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50, score=0.666, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50, score=0.670, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50, score=0.676, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50, score=0.663, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=50, score=0.660, total=   0.6s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75, score=0.660, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75, score=0.673, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75, score=0.676, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75, score=0.667, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=75, score=0.663, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100, score=0.660, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100, score=0.672, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100, score=0.674, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100, score=0.666, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=100, score=0.673, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200, score=0.661, total=   2.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200, score=0.672, total=   2.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200, score=0.671, total=   2.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200, score=0.669, total=   2.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=2, n_estimators=200, score=0.669, total=   2.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10, score=0.631, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10, score=0.648, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10, score=0.677, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10, score=0.658, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=10, score=0.663, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20, score=0.665, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20, score=0.663, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20, score=0.676, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20, score=0.661, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=20, score=0.656, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40, score=0.659, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40, score=0.665, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40, score=0.666, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40, score=0.659, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=40, score=0.658, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50, score=0.672, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50, score=0.653, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50, score=0.666, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50, score=0.679, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=50, score=0.671, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75, score=0.664, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75, score=0.674, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75, score=0.669, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75, score=0.669, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=75, score=0.671, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100, score=0.651, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100, score=0.665, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100, score=0.680, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100, score=0.669, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=100, score=0.667, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200, score=0.665, total=   2.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200, score=0.673, total=   2.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200, score=0.677, total=   2.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200, score=0.670, total=   2.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=3, n_estimators=200, score=0.664, total=   2.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10, score=0.650, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10, score=0.663, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10, score=0.668, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10, score=0.621, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=10, score=0.659, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20, score=0.657, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20, score=0.685, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20, score=0.636, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20, score=0.660, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=20, score=0.656, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40, score=0.664, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40, score=0.665, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40, score=0.680, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40, score=0.659, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=40, score=0.676, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50, score=0.652, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50, score=0.667, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50, score=0.686, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50, score=0.673, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=50, score=0.669, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75, score=0.663, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75, score=0.674, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75, score=0.675, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75, score=0.671, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=75, score=0.657, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100, score=0.665, total=   1.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100, score=0.667, total=   1.3s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100, score=0.670, total=   1.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100, score=0.667, total=   1.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=100, score=0.671, total=   1.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200, score=0.669, total=   2.3s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200, score=0.669, total=   2.6s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200, score=0.669, total=   2.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200, score=0.668, total=   2.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=5, n_estimators=200, score=0.670, total=   2.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10, score=0.620, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10, score=0.682, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10, score=0.649, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10, score=0.662, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=10, score=0.661, total=   0.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20, score=0.679, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20, score=0.677, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20, score=0.681, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20, score=0.660, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=20, score=0.674, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40, score=0.639, total=   0.6s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40, score=0.665, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40, score=0.673, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40, score=0.676, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=40, score=0.669, total=   0.5s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50, score=0.663, total=   0.6s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50, score=0.670, total=   0.6s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50, score=0.652, total=   0.6s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50, score=0.666, total=   0.6s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=50, score=0.674, total=   0.6s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75, score=0.660, total=   0.9s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75, score=0.654, total=   0.9s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75, score=0.671, total=   1.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75, score=0.666, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=75, score=0.672, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100, score=0.661, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100, score=0.665, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100, score=0.666, total=   1.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100, score=0.665, total=   1.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=100, score=0.669, total=   1.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200, score=0.666, total=   2.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200, score=0.668, total=   2.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200, score=0.674, total=   2.1s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200, score=0.671, total=   2.0s\n",
      "[CV] max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=3, max_features=log2, min_samples_split=6, n_estimators=200, score=0.668, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10, score=0.707, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10, score=0.710, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10, score=0.714, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10, score=0.708, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=10, score=0.712, total=   0.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20, score=0.709, total=   1.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20, score=0.711, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20, score=0.715, total=   1.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20, score=0.708, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=20, score=0.714, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40, score=0.709, total=   2.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40, score=0.713, total=   2.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40, score=0.716, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40, score=0.709, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=40, score=0.713, total=   2.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50, score=0.710, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50, score=0.713, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50, score=0.718, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50, score=0.709, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=50, score=0.714, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75, score=0.710, total=   3.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75, score=0.713, total=   3.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75, score=0.718, total=   3.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75, score=0.709, total=   3.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=75, score=0.714, total=   3.9s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100, score=0.710, total=   5.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100, score=0.713, total=   5.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100, score=0.717, total=   5.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100, score=0.710, total=   5.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=100, score=0.714, total=   6.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200, score=0.710, total=  12.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200, score=0.713, total=  12.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200, score=0.717, total=  10.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200, score=0.710, total=  10.3s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=2, n_estimators=200, score=0.714, total=  10.3s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10, score=0.707, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10, score=0.711, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10, score=0.716, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10, score=0.709, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=10, score=0.710, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20, score=0.709, total=   1.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20, score=0.714, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20, score=0.716, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20, score=0.711, total=   1.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=20, score=0.714, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40, score=0.708, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40, score=0.713, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40, score=0.717, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40, score=0.709, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=40, score=0.714, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50, score=0.709, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50, score=0.714, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50, score=0.716, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50, score=0.709, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=50, score=0.714, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75, score=0.710, total=   4.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75, score=0.713, total=   4.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75, score=0.717, total=   3.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75, score=0.710, total=   3.9s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=75, score=0.715, total=   3.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100, score=0.709, total=   5.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100, score=0.713, total=   5.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100, score=0.717, total=   5.9s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100, score=0.709, total=   6.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=100, score=0.714, total=   6.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200, score=0.710, total=  11.4s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200, score=0.713, total=  10.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200, score=0.717, total=  10.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200, score=0.710, total=  10.3s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=3, n_estimators=200, score=0.714, total=  10.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10, score=0.707, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10, score=0.711, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10, score=0.713, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10, score=0.706, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=10, score=0.710, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20, score=0.709, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20, score=0.712, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20, score=0.716, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20, score=0.710, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=20, score=0.713, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40, score=0.709, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40, score=0.712, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40, score=0.717, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40, score=0.709, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=40, score=0.713, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50, score=0.710, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50, score=0.712, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50, score=0.716, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50, score=0.709, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=50, score=0.713, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75, score=0.709, total=   3.9s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75, score=0.712, total=   3.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75, score=0.717, total=   3.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75, score=0.708, total=   4.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=75, score=0.715, total=   4.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100, score=0.709, total=   6.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100, score=0.713, total=   5.9s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100, score=0.717, total=   6.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100, score=0.709, total=   6.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=100, score=0.714, total=   5.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200, score=0.710, total=  10.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200, score=0.713, total=  10.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200, score=0.717, total=  10.3s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200, score=0.710, total=  10.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=5, n_estimators=200, score=0.715, total=  10.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10, score=0.706, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10, score=0.710, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10, score=0.715, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10, score=0.707, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=10, score=0.715, total=   0.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20, score=0.709, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20, score=0.711, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20, score=0.716, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20, score=0.709, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=20, score=0.715, total=   1.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40, score=0.709, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40, score=0.711, total=   2.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40, score=0.716, total=   2.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40, score=0.710, total=   2.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=40, score=0.714, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50, score=0.709, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50, score=0.713, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50, score=0.717, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50, score=0.709, total=   2.5s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=50, score=0.715, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75, score=0.710, total=   4.3s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75, score=0.713, total=   4.4s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75, score=0.717, total=   4.8s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75, score=0.710, total=   4.4s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=75, score=0.714, total=   4.7s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100, score=0.710, total=   5.9s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100, score=0.712, total=   5.6s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100, score=0.718, total=   5.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100, score=0.709, total=   5.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=100, score=0.714, total=   5.1s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200, score=0.710, total=  10.3s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200, score=0.713, total=  10.4s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200, score=0.717, total=  10.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200, score=0.710, total=  10.2s\n",
      "[CV] max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=auto, min_samples_split=6, n_estimators=200, score=0.715, total=  10.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.699, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.701, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.710, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.695, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.704, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.702, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.699, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.706, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.705, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.708, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.697, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.704, total=   0.7s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.706, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.702, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.707, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.704, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.708, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.710, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.703, total=   0.9s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.707, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.700, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.710, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.712, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.708, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.709, total=   1.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.707, total=   1.5s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.707, total=   1.7s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.712, total=   2.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.704, total=   1.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.708, total=   1.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.703, total=   3.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.708, total=   3.7s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.711, total=   3.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.706, total=   3.9s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.709, total=   3.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.704, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.705, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.699, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.698, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.701, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.695, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.706, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.715, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.705, total=   0.5s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.709, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.698, total=   0.7s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.706, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.712, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.704, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.708, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.703, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.709, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.712, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.705, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.708, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.702, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.707, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.711, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.704, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.704, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.703, total=   1.5s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.708, total=   1.5s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.714, total=   1.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.705, total=   1.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.703, total=   1.5s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.704, total=   3.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.709, total=   3.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.708, total=   3.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.706, total=   3.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.706, total=   3.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.696, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.705, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.706, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.691, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.699, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.699, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.706, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.715, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.702, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.699, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.701, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.708, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.711, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.705, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.704, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.704, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.709, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.712, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.703, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.699, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.694, total=   1.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.706, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.710, total=   1.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.706, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.705, total=   1.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.705, total=   1.5s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.710, total=   1.5s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.710, total=   1.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.706, total=   1.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.707, total=   1.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.703, total=   3.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.707, total=   3.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.712, total=   3.1s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.707, total=   3.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.707, total=   3.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.696, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.712, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.700, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.702, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.697, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.694, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.702, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.702, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.701, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.706, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.699, total=   0.7s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.707, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.710, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.702, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.706, total=   0.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.706, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.703, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.713, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.707, total=   0.9s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.707, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.702, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.707, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.713, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.708, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.709, total=   1.2s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.702, total=   2.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.709, total=   1.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.706, total=   1.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.703, total=   1.8s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.705, total=   2.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.703, total=   3.7s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.708, total=   3.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.713, total=   4.0s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.706, total=   3.6s\n",
      "[CV] max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.708, total=   3.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10, score=0.702, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10, score=0.705, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10, score=0.713, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10, score=0.695, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=10, score=0.692, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20, score=0.689, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20, score=0.704, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20, score=0.711, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20, score=0.703, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=20, score=0.699, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40, score=0.701, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40, score=0.710, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40, score=0.710, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40, score=0.708, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=40, score=0.709, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50, score=0.699, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50, score=0.707, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50, score=0.712, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50, score=0.706, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=50, score=0.707, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75, score=0.703, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75, score=0.705, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75, score=0.710, total=   1.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75, score=0.708, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=75, score=0.705, total=   1.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100, score=0.704, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100, score=0.710, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100, score=0.709, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100, score=0.704, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=100, score=0.711, total=   1.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200, score=0.703, total=   3.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200, score=0.705, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200, score=0.712, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200, score=0.708, total=   3.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=2, n_estimators=200, score=0.708, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10, score=0.683, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10, score=0.707, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10, score=0.707, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10, score=0.699, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=10, score=0.700, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20, score=0.699, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20, score=0.706, total=   0.4s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20, score=0.713, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20, score=0.703, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=20, score=0.713, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40, score=0.702, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40, score=0.712, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40, score=0.710, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40, score=0.703, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=40, score=0.704, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50, score=0.701, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50, score=0.708, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50, score=0.712, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50, score=0.705, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=50, score=0.706, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75, score=0.699, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75, score=0.706, total=   1.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75, score=0.710, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75, score=0.705, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=75, score=0.708, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100, score=0.700, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100, score=0.706, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100, score=0.712, total=   1.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100, score=0.706, total=   1.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=100, score=0.708, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200, score=0.702, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200, score=0.706, total=   3.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200, score=0.711, total=   3.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200, score=0.707, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=3, n_estimators=200, score=0.707, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10, score=0.696, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10, score=0.698, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10, score=0.703, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10, score=0.700, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=10, score=0.697, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20, score=0.701, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20, score=0.707, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20, score=0.712, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20, score=0.701, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=20, score=0.706, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40, score=0.705, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40, score=0.701, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40, score=0.710, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40, score=0.707, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=40, score=0.703, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50, score=0.702, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50, score=0.705, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50, score=0.705, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50, score=0.703, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=50, score=0.708, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75, score=0.701, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75, score=0.708, total=   1.4s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75, score=0.712, total=   1.4s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75, score=0.704, total=   1.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=75, score=0.706, total=   1.4s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100, score=0.702, total=   1.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100, score=0.707, total=   2.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100, score=0.714, total=   1.9s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100, score=0.706, total=   1.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=100, score=0.708, total=   1.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200, score=0.702, total=   3.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200, score=0.707, total=   3.7s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200, score=0.712, total=   3.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200, score=0.704, total=   3.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=5, n_estimators=200, score=0.710, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10, score=0.691, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10, score=0.697, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10, score=0.710, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10, score=0.696, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=10, score=0.700, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20, score=0.703, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20, score=0.709, total=   0.4s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20, score=0.711, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20, score=0.694, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=20, score=0.706, total=   0.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40, score=0.697, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40, score=0.708, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40, score=0.713, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40, score=0.702, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=40, score=0.694, total=   0.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50, score=0.703, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50, score=0.706, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50, score=0.715, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50, score=0.704, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=50, score=0.708, total=   0.8s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75, score=0.706, total=   1.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75, score=0.702, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75, score=0.712, total=   1.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75, score=0.699, total=   1.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=75, score=0.709, total=   1.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100, score=0.701, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100, score=0.703, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100, score=0.710, total=   1.5s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100, score=0.707, total=   1.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=100, score=0.710, total=   1.6s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200, score=0.703, total=   3.2s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200, score=0.707, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200, score=0.710, total=   3.0s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200, score=0.706, total=   3.3s\n",
      "[CV] max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=5, max_features=log2, min_samples_split=6, n_estimators=200, score=0.708, total=   3.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10, score=0.712, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10, score=0.716, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10, score=0.719, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10, score=0.713, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=10, score=0.719, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20, score=0.717, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20, score=0.718, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20, score=0.720, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20, score=0.716, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=20, score=0.718, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40, score=0.718, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40, score=0.718, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40, score=0.722, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40, score=0.717, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=40, score=0.720, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50, score=0.716, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50, score=0.718, total=   3.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50, score=0.723, total=   3.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50, score=0.716, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=50, score=0.720, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75, score=0.716, total=   4.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75, score=0.719, total=   5.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75, score=0.724, total=   5.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75, score=0.717, total=   5.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=75, score=0.720, total=   5.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100, score=0.717, total=   7.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100, score=0.719, total=   6.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100, score=0.723, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100, score=0.717, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=100, score=0.720, total=   6.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200, score=0.717, total=  12.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200, score=0.718, total=  12.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200, score=0.723, total=  12.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200, score=0.717, total=  12.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=2, n_estimators=200, score=0.720, total=  12.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10, score=0.714, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10, score=0.717, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10, score=0.721, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10, score=0.715, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=10, score=0.717, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20, score=0.714, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20, score=0.717, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20, score=0.721, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20, score=0.714, total=   1.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=20, score=0.718, total=   1.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40, score=0.715, total=   2.8s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40, score=0.719, total=   2.8s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40, score=0.724, total=   3.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40, score=0.715, total=   2.8s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=40, score=0.721, total=   2.8s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50, score=0.715, total=   3.8s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50, score=0.719, total=   3.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50, score=0.724, total=   3.7s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50, score=0.716, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=50, score=0.720, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75, score=0.717, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75, score=0.719, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75, score=0.723, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75, score=0.717, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=75, score=0.721, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100, score=0.716, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100, score=0.719, total=   5.9s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100, score=0.723, total=   6.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100, score=0.716, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=100, score=0.720, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200, score=0.717, total=  11.9s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200, score=0.719, total=  11.9s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200, score=0.723, total=  13.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200, score=0.717, total=  14.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=3, n_estimators=200, score=0.720, total=  13.3s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10, score=0.712, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10, score=0.717, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10, score=0.722, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10, score=0.714, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=10, score=0.720, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20, score=0.716, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20, score=0.718, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20, score=0.719, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20, score=0.717, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=20, score=0.718, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40, score=0.716, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40, score=0.719, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40, score=0.721, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40, score=0.718, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=40, score=0.720, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50, score=0.716, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50, score=0.718, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50, score=0.722, total=   3.1s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50, score=0.718, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=50, score=0.720, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75, score=0.716, total=   4.7s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75, score=0.718, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75, score=0.722, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75, score=0.716, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=75, score=0.720, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100, score=0.716, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100, score=0.719, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100, score=0.724, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100, score=0.716, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=100, score=0.721, total=   6.9s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200, score=0.716, total=  14.7s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200, score=0.719, total=  13.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200, score=0.724, total=  12.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200, score=0.717, total=  12.3s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=5, n_estimators=200, score=0.720, total=  12.3s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10, score=0.712, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10, score=0.715, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10, score=0.721, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10, score=0.711, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=10, score=0.717, total=   0.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20, score=0.715, total=   1.3s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20, score=0.719, total=   1.3s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20, score=0.722, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20, score=0.715, total=   1.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=20, score=0.719, total=   1.3s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40, score=0.716, total=   2.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40, score=0.718, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40, score=0.724, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40, score=0.716, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=40, score=0.719, total=   2.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50, score=0.716, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50, score=0.719, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50, score=0.723, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50, score=0.717, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=50, score=0.721, total=   3.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75, score=0.716, total=   4.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75, score=0.719, total=   4.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75, score=0.723, total=   4.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75, score=0.718, total=   6.2s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=75, score=0.719, total=   4.7s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100, score=0.715, total=   6.4s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100, score=0.718, total=   6.3s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100, score=0.724, total=   6.0s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100, score=0.718, total=   4.8s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=100, score=0.720, total=   4.8s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200, score=0.717, total=   9.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200, score=0.719, total=   9.5s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200, score=0.724, total=   9.6s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200, score=0.717, total=   9.8s\n",
      "[CV] max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=auto, min_samples_split=6, n_estimators=200, score=0.720, total=   9.5s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.706, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.714, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.712, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.713, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.709, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.710, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.711, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.719, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.709, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.717, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.712, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.714, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.719, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.708, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.715, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.710, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.712, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.722, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.713, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.713, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.712, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.713, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.720, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.713, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.718, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.713, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.717, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.721, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.713, total=   1.5s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.718, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.712, total=   2.8s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.715, total=   2.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.720, total=   3.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.713, total=   3.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.716, total=   3.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.712, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.705, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.717, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.705, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.710, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.711, total=   0.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.713, total=   0.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.711, total=   0.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.710, total=   0.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.717, total=   0.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.709, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.713, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.720, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.713, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.713, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.711, total=   0.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.710, total=   1.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.717, total=   1.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.712, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.715, total=   0.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.711, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.715, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.721, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.715, total=   1.5s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.716, total=   1.5s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.710, total=   1.5s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.715, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.721, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.714, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.717, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.711, total=   2.8s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.714, total=   2.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.719, total=   2.8s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.715, total=   2.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.717, total=   2.8s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.707, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.701, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.712, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.703, total=   0.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.714, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.707, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.712, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.716, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.714, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.712, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.714, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.712, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.721, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.713, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.716, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.712, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.715, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.723, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.713, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.716, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.712, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.715, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.722, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.714, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.719, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.711, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.711, total=   1.5s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.722, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.714, total=   1.5s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.719, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.711, total=   2.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.715, total=   3.0s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.720, total=   2.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.714, total=   3.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.718, total=   2.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.705, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.715, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.706, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.708, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.713, total=   0.2s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.711, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.715, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.718, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.714, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.714, total=   0.3s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.707, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.713, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.717, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.712, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.718, total=   0.6s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.708, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.714, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.719, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.713, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.715, total=   0.7s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.712, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.718, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.721, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.713, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.716, total=   1.1s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.712, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.716, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.721, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.716, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.716, total=   1.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.712, total=   2.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.717, total=   2.9s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.722, total=   2.8s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.714, total=   3.4s\n",
      "[CV] max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.716, total=   3.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10, score=0.706, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10, score=0.711, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10, score=0.719, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10, score=0.708, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=10, score=0.712, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20, score=0.704, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20, score=0.717, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20, score=0.714, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20, score=0.705, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=20, score=0.715, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40, score=0.709, total=   0.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40, score=0.717, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40, score=0.721, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40, score=0.711, total=   0.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=40, score=0.715, total=   0.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50, score=0.711, total=   1.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50, score=0.711, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50, score=0.719, total=   1.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50, score=0.713, total=   0.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=50, score=0.714, total=   0.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75, score=0.711, total=   1.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75, score=0.717, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75, score=0.720, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75, score=0.714, total=   1.5s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=75, score=0.716, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100, score=0.710, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100, score=0.717, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100, score=0.721, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100, score=0.715, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=100, score=0.719, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200, score=0.711, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200, score=0.716, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200, score=0.721, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200, score=0.714, total=   2.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=2, n_estimators=200, score=0.716, total=   2.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10, score=0.708, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10, score=0.706, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10, score=0.715, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10, score=0.704, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=10, score=0.709, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20, score=0.709, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20, score=0.718, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20, score=0.718, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20, score=0.708, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=20, score=0.716, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40, score=0.709, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40, score=0.715, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40, score=0.719, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40, score=0.713, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=40, score=0.715, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50, score=0.714, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50, score=0.717, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50, score=0.718, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50, score=0.714, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=50, score=0.715, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75, score=0.708, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75, score=0.716, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75, score=0.722, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75, score=0.714, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=75, score=0.717, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100, score=0.710, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100, score=0.714, total=   1.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100, score=0.720, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100, score=0.713, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=100, score=0.715, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200, score=0.711, total=   3.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200, score=0.716, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200, score=0.719, total=   3.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200, score=0.715, total=   2.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=3, n_estimators=200, score=0.718, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10, score=0.700, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10, score=0.702, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10, score=0.716, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10, score=0.707, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=10, score=0.715, total=   0.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20, score=0.708, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20, score=0.714, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20, score=0.721, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20, score=0.706, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=20, score=0.713, total=   0.3s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40, score=0.713, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40, score=0.714, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40, score=0.717, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40, score=0.711, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=40, score=0.717, total=   0.6s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50, score=0.711, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50, score=0.714, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50, score=0.719, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50, score=0.712, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=50, score=0.717, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75, score=0.711, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75, score=0.712, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75, score=0.720, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75, score=0.715, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=75, score=0.715, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100, score=0.711, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100, score=0.714, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100, score=0.721, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100, score=0.713, total=   1.5s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=100, score=0.715, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200, score=0.711, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200, score=0.716, total=   2.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200, score=0.720, total=   2.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200, score=0.713, total=   3.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=5, n_estimators=200, score=0.715, total=   3.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10, score=0.705, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10, score=0.706, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10, score=0.714, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10, score=0.711, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=10, score=0.714, total=   0.2s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20, score=0.709, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20, score=0.709, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20, score=0.710, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20, score=0.710, total=   0.5s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=20, score=0.712, total=   0.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40, score=0.713, total=   0.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40, score=0.712, total=   0.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40, score=0.722, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40, score=0.713, total=   0.7s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=40, score=0.715, total=   0.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50, score=0.709, total=   1.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50, score=0.713, total=   0.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50, score=0.721, total=   0.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50, score=0.714, total=   1.1s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=50, score=0.712, total=   1.0s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75, score=0.709, total=   1.5s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75, score=0.713, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75, score=0.720, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75, score=0.713, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=75, score=0.717, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100, score=0.707, total=   1.9s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100, score=0.714, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100, score=0.721, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100, score=0.713, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=100, score=0.715, total=   1.4s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200, score=0.710, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200, score=0.716, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200, score=0.720, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200, score=0.713, total=   2.8s\n",
      "[CV] max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=6, max_features=log2, min_samples_split=6, n_estimators=200, score=0.717, total=   2.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10, score=0.710, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10, score=0.715, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10, score=0.720, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10, score=0.717, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=10, score=0.713, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20, score=0.718, total=   1.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20, score=0.723, total=   1.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20, score=0.727, total=   1.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20, score=0.722, total=   1.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=20, score=0.718, total=   1.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40, score=0.717, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40, score=0.723, total=   3.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40, score=0.728, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40, score=0.724, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=40, score=0.722, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50, score=0.720, total=   4.2s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50, score=0.724, total=   4.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50, score=0.729, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50, score=0.725, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=50, score=0.722, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75, score=0.722, total=   5.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75, score=0.726, total=   5.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75, score=0.728, total=   5.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75, score=0.725, total=   6.4s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=75, score=0.724, total=   7.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100, score=0.723, total=   9.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100, score=0.726, total=   9.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100, score=0.730, total=   7.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100, score=0.726, total=   7.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=100, score=0.725, total=   7.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200, score=0.722, total=  15.3s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200, score=0.726, total=  15.4s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200, score=0.729, total=  15.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200, score=0.727, total=  15.3s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200, score=0.725, total=  19.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10, score=0.709, total=   1.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10, score=0.713, total=   1.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10, score=0.720, total=   1.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10, score=0.708, total=   1.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=10, score=0.713, total=   1.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20, score=0.721, total=   2.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20, score=0.720, total=   2.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20, score=0.724, total=   1.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20, score=0.718, total=   1.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=20, score=0.722, total=   1.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40, score=0.720, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40, score=0.725, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40, score=0.726, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40, score=0.723, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=40, score=0.722, total=   3.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50, score=0.721, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50, score=0.723, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50, score=0.727, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50, score=0.725, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=50, score=0.724, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75, score=0.723, total=   5.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75, score=0.725, total=   5.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75, score=0.729, total=   5.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75, score=0.724, total=   5.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=75, score=0.725, total=   6.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100, score=0.722, total=   7.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100, score=0.726, total=   7.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100, score=0.729, total=   8.4s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100, score=0.725, total=  10.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=100, score=0.725, total=  11.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200, score=0.723, total=  18.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200, score=0.726, total=  15.3s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200, score=0.730, total=  15.4s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200, score=0.727, total=  15.4s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=3, n_estimators=200, score=0.725, total=  16.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10, score=0.715, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10, score=0.714, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10, score=0.719, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10, score=0.711, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=10, score=0.717, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20, score=0.717, total=   1.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20, score=0.717, total=   1.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20, score=0.724, total=   1.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20, score=0.723, total=   1.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=20, score=0.718, total=   1.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40, score=0.722, total=   4.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40, score=0.725, total=   4.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40, score=0.728, total=   4.2s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40, score=0.723, total=   3.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=40, score=0.725, total=   4.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50, score=0.721, total=   4.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50, score=0.726, total=   4.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50, score=0.730, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50, score=0.725, total=   3.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=50, score=0.724, total=   4.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75, score=0.722, total=   6.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75, score=0.725, total=   6.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75, score=0.729, total=   5.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75, score=0.725, total=   6.3s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=75, score=0.723, total=   5.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100, score=0.724, total=   7.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100, score=0.725, total=   7.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100, score=0.730, total=   7.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100, score=0.725, total=   7.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=100, score=0.726, total=   7.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200, score=0.723, total=  17.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200, score=0.726, total=  19.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200, score=0.730, total=  15.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200, score=0.726, total=  15.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=5, n_estimators=200, score=0.726, total=  19.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10, score=0.716, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10, score=0.712, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10, score=0.717, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10, score=0.717, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=10, score=0.709, total=   0.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20, score=0.715, total=   1.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20, score=0.722, total=   1.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20, score=0.726, total=   1.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20, score=0.722, total=   2.2s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=20, score=0.722, total=   2.3s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40, score=0.719, total=   4.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40, score=0.724, total=   6.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40, score=0.726, total=   7.3s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40, score=0.726, total=   5.9s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=40, score=0.720, total=   5.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50, score=0.723, total=   6.2s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50, score=0.725, total=   7.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50, score=0.728, total=   8.6s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50, score=0.725, total=   8.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=50, score=0.724, total=   8.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75, score=0.721, total=  12.5s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75, score=0.723, total=   9.4s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75, score=0.729, total=   8.3s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75, score=0.725, total=  10.2s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=75, score=0.725, total=  10.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100, score=0.723, total=  13.2s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100, score=0.725, total=  10.3s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100, score=0.729, total=  10.4s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100, score=0.724, total=  11.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=100, score=0.724, total=   9.1s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200, score=0.723, total=  18.4s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200, score=0.725, total=  20.7s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200, score=0.730, total=  17.8s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200, score=0.726, total=  18.0s\n",
      "[CV] max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=auto, min_samples_split=6, n_estimators=200, score=0.725, total=  18.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.715, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.721, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.724, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.715, total=   0.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.720, total=   0.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.719, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.721, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.729, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.722, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.718, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.721, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.727, total=   1.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.729, total=   1.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.726, total=   1.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.726, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.722, total=   1.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.724, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.730, total=   1.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.725, total=   1.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.725, total=   1.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.724, total=   2.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.728, total=   2.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.732, total=   2.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.726, total=   2.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.726, total=   2.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.724, total=   2.8s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.727, total=   2.8s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.732, total=   2.8s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.726, total=   2.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.727, total=   2.8s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.724, total=   5.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.728, total=   5.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.732, total=   5.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.727, total=   5.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.728, total=   5.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.716, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.721, total=   0.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.720, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.722, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.715, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.719, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.722, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.729, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.722, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.723, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.723, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.727, total=   1.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.733, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.725, total=   0.9s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.726, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.722, total=   1.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.726, total=   1.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.730, total=   1.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.725, total=   1.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.725, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.723, total=   2.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.727, total=   2.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.734, total=   2.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.726, total=   1.8s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.729, total=   2.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.724, total=   3.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.726, total=   2.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.733, total=   2.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.727, total=   2.9s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.728, total=   2.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.725, total=   5.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.727, total=   5.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.732, total=   5.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.726, total=   5.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.728, total=   5.0s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.712, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.717, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.725, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.717, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.718, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.719, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.724, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.726, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.720, total=   0.6s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.723, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.722, total=   0.9s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.725, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.731, total=   1.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.724, total=   1.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.726, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.722, total=   1.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.727, total=   1.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.730, total=   1.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.725, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.724, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.724, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.728, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.733, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.726, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.726, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.724, total=   2.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.727, total=   2.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.732, total=   2.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.727, total=   2.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.727, total=   2.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.724, total=   4.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.728, total=   4.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.733, total=   4.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.726, total=   4.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.728, total=   4.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.714, total=   0.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.718, total=   0.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.725, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.717, total=   0.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.714, total=   0.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.718, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.724, total=   0.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.727, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.720, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.722, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.722, total=   0.9s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.726, total=   0.9s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.730, total=   0.9s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.725, total=   0.9s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.726, total=   0.9s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.722, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.728, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.730, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.727, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.727, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.725, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.727, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.731, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.726, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.728, total=   1.7s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.724, total=   2.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.728, total=   2.3s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.734, total=   2.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.725, total=   2.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.729, total=   2.2s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.725, total=   4.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.729, total=   4.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.733, total=   4.5s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.726, total=   4.4s\n",
      "[CV] max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.727, total=   4.4s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.0s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10, score=0.718, total=   0.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10, score=0.719, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10, score=0.716, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10, score=0.720, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=10, score=0.720, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20, score=0.719, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20, score=0.724, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20, score=0.730, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20, score=0.722, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=20, score=0.720, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40, score=0.722, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40, score=0.727, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40, score=0.730, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40, score=0.723, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=40, score=0.726, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50, score=0.722, total=   1.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50, score=0.726, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50, score=0.731, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50, score=0.724, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50, score=0.727, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75, score=0.723, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75, score=0.726, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75, score=0.733, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75, score=0.726, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=75, score=0.727, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100, score=0.723, total=   2.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100, score=0.727, total=   2.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100, score=0.732, total=   2.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100, score=0.726, total=   2.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100, score=0.727, total=   2.4s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200, score=0.725, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200, score=0.727, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200, score=0.733, total=   4.8s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200, score=0.727, total=   5.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=2, n_estimators=200, score=0.729, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10, score=0.710, total=   0.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10, score=0.718, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10, score=0.723, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10, score=0.717, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=10, score=0.720, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20, score=0.717, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20, score=0.724, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20, score=0.727, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20, score=0.724, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=20, score=0.723, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40, score=0.721, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40, score=0.726, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40, score=0.729, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40, score=0.723, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=40, score=0.726, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50, score=0.720, total=   1.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50, score=0.727, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50, score=0.730, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50, score=0.724, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=50, score=0.726, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75, score=0.723, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75, score=0.727, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75, score=0.731, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75, score=0.725, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=75, score=0.729, total=   1.8s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100, score=0.724, total=   2.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100, score=0.728, total=   2.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100, score=0.732, total=   2.4s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100, score=0.726, total=   2.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=100, score=0.726, total=   2.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200, score=0.724, total=   4.6s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200, score=0.727, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200, score=0.733, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200, score=0.727, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=3, n_estimators=200, score=0.728, total=   4.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10, score=0.713, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10, score=0.722, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10, score=0.725, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10, score=0.716, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=10, score=0.717, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20, score=0.721, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20, score=0.724, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20, score=0.728, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20, score=0.722, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=20, score=0.726, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40, score=0.721, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40, score=0.726, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40, score=0.731, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40, score=0.726, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=40, score=0.728, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50, score=0.722, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50, score=0.728, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50, score=0.731, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50, score=0.724, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50, score=0.726, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75, score=0.723, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75, score=0.728, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75, score=0.732, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75, score=0.727, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=75, score=0.727, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100, score=0.723, total=   2.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100, score=0.727, total=   2.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100, score=0.732, total=   2.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100, score=0.726, total=   2.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100, score=0.727, total=   2.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200, score=0.725, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200, score=0.729, total=   4.6s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200, score=0.733, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200, score=0.728, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=5, n_estimators=200, score=0.727, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10, score=0.716, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10, score=0.715, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10, score=0.725, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10, score=0.716, total=   0.3s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=10, score=0.715, total=   0.2s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20, score=0.722, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20, score=0.724, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20, score=0.730, total=   0.4s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20, score=0.725, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=20, score=0.723, total=   0.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40, score=0.722, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40, score=0.728, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40, score=0.732, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40, score=0.724, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=40, score=0.726, total=   0.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50, score=0.722, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50, score=0.725, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50, score=0.732, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50, score=0.727, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=50, score=0.726, total=   1.1s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75, score=0.723, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75, score=0.728, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75, score=0.730, total=   1.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75, score=0.726, total=   2.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=75, score=0.727, total=   7.4s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100, score=0.725, total=   5.4s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100, score=0.727, total=   3.7s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100, score=0.732, total=   2.8s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100, score=0.725, total=   2.8s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=100, score=0.728, total=   2.9s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200, score=0.724, total=   5.6s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200, score=0.727, total=   5.6s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200, score=0.732, total=   5.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200, score=0.727, total=   5.5s\n",
      "[CV] max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=10, max_features=log2, min_samples_split=6, n_estimators=200, score=0.728, total=   5.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=auto, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10, score=0.694, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10, score=0.696, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10, score=0.704, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10, score=0.699, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=10, score=0.695, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20, score=0.711, total=   3.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20, score=0.706, total=   3.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20, score=0.718, total=   3.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20, score=0.714, total=   3.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=20, score=0.706, total=   3.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40, score=0.713, total=   6.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40, score=0.721, total=   6.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40, score=0.722, total=   6.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40, score=0.718, total=   6.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=40, score=0.718, total=   6.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50, score=0.717, total=   7.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50, score=0.720, total=   7.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50, score=0.725, total=   8.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50, score=0.718, total=   8.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=50, score=0.720, total=  10.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75, score=0.715, total=  16.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75, score=0.720, total=  13.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75, score=0.722, total=  14.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75, score=0.722, total=  14.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=75, score=0.719, total=  15.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100, score=0.718, total=  22.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100, score=0.726, total=  18.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100, score=0.727, total=  18.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100, score=0.722, total=  22.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=100, score=0.722, total=  21.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200, score=0.720, total=  38.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200, score=0.726, total=  39.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200, score=0.726, total=  36.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200, score=0.723, total=  35.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=2, n_estimators=200, score=0.722, total=  34.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10, score=0.696, total=   1.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10, score=0.692, total=   1.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10, score=0.693, total=   1.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10, score=0.701, total=   1.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=10, score=0.699, total=   1.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20, score=0.707, total=   3.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20, score=0.718, total=   3.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20, score=0.717, total=   3.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20, score=0.713, total=   3.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=20, score=0.706, total=   3.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40, score=0.715, total=   7.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40, score=0.717, total=   6.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40, score=0.723, total=   6.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40, score=0.720, total=   6.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=40, score=0.719, total=   6.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50, score=0.717, total=   8.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50, score=0.718, total=   8.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50, score=0.724, total=   8.8s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50, score=0.718, total=   9.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=50, score=0.718, total=  10.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75, score=0.718, total=  14.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75, score=0.722, total=  14.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75, score=0.724, total=  13.8s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75, score=0.725, total=  14.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=75, score=0.718, total=  14.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100, score=0.720, total=  19.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100, score=0.723, total=  19.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100, score=0.724, total=  19.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100, score=0.725, total=  19.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=100, score=0.721, total=  19.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200, score=0.718, total=  44.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200, score=0.725, total=  44.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200, score=0.726, total=  47.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200, score=0.725, total=  46.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=3, n_estimators=200, score=0.723, total=  36.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10, score=0.697, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10, score=0.707, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10, score=0.700, total=   1.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10, score=0.702, total=   1.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=10, score=0.694, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20, score=0.707, total=   3.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20, score=0.715, total=   3.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20, score=0.718, total=   3.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20, score=0.711, total=   3.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=20, score=0.714, total=   4.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40, score=0.713, total=   7.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40, score=0.725, total=   7.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40, score=0.722, total=   7.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40, score=0.717, total=   7.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=40, score=0.714, total=   7.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50, score=0.717, total=   9.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50, score=0.722, total=   9.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50, score=0.723, total=  10.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50, score=0.718, total=  12.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=50, score=0.717, total=   9.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75, score=0.717, total=  14.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75, score=0.723, total=  14.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75, score=0.723, total=  14.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75, score=0.723, total=  14.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=75, score=0.720, total=  14.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100, score=0.720, total=  19.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100, score=0.725, total=  19.8s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100, score=0.726, total=  19.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100, score=0.724, total=  18.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=100, score=0.720, total=  18.8s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200, score=0.721, total=  38.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200, score=0.725, total=  38.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200, score=0.725, total=  46.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200, score=0.725, total=  41.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=5, n_estimators=200, score=0.723, total=  44.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10, score=0.694, total=   2.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10, score=0.701, total=   2.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10, score=0.699, total=   2.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10, score=0.699, total=   2.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=10, score=0.700, total=   2.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20, score=0.711, total=   4.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20, score=0.716, total=   4.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20, score=0.716, total=   4.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20, score=0.714, total=   4.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=20, score=0.710, total=   4.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40, score=0.716, total=   9.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40, score=0.719, total=   8.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40, score=0.724, total=   8.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40, score=0.719, total=  10.2s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=40, score=0.717, total=   8.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50, score=0.717, total=   9.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50, score=0.721, total=   9.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50, score=0.723, total=   9.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50, score=0.721, total=   9.6s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=50, score=0.716, total=   9.3s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75, score=0.719, total=  13.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75, score=0.721, total=  13.1s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75, score=0.723, total=  14.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75, score=0.723, total=  14.5s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=75, score=0.720, total=  14.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100, score=0.721, total=  22.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100, score=0.725, total=  23.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100, score=0.726, total=  18.9s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100, score=0.722, total=  19.4s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=100, score=0.720, total=  18.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200, score=0.722, total=  38.0s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200, score=0.725, total=  37.7s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200, score=0.727, total=  38.8s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200, score=0.725, total=  37.8s\n",
      "[CV] max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=auto, min_samples_split=6, n_estimators=200, score=0.720, total=  39.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=20, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=75, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=100, score=nan, total=   0.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=1, n_estimators=200, score=nan, total=   0.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.705, total=   0.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.700, total=   0.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.708, total=   0.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.706, total=   0.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=10, score=0.700, total=   0.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.716, total=   1.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.716, total=   1.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.713, total=   1.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.716, total=   1.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=20, score=0.712, total=   1.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.719, total=   3.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.727, total=   3.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.729, total=   2.9s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.721, total=   2.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=40, score=0.721, total=   4.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.719, total=   3.9s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.725, total=   5.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.728, total=   3.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.721, total=   3.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50, score=0.725, total=   3.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.722, total=   7.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.725, total=   9.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.730, total=   9.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.724, total=   7.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=75, score=0.726, total=   7.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.723, total=   8.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.730, total=   9.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.731, total=   8.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.723, total=   8.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100, score=0.727, total=   8.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.726, total=  15.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.730, total=  15.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.734, total=  15.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.728, total=  17.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=200, score=0.728, total=  14.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.700, total=   0.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.704, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.709, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.698, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=10, score=0.697, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.717, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.714, total=   1.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.720, total=   1.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.717, total=   1.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=20, score=0.718, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.721, total=   2.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.725, total=   2.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.729, total=   2.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.720, total=   2.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=40, score=0.723, total=   2.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.724, total=   3.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.728, total=   3.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.728, total=   3.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.722, total=   3.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=50, score=0.724, total=   3.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.723, total=   4.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.727, total=   4.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.731, total=   4.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.724, total=   4.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=75, score=0.726, total=   5.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.727, total=   6.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.731, total=   6.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.732, total=   6.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.727, total=   6.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=100, score=0.726, total=   6.9s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.726, total=  13.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.729, total=  12.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.733, total=  12.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.726, total=  12.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=3, n_estimators=200, score=0.728, total=  12.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.701, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.704, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.706, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.705, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=10, score=0.697, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.713, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.723, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.726, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.716, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=20, score=0.714, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.718, total=   2.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.725, total=   2.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.727, total=   2.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.722, total=   2.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=40, score=0.723, total=   2.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.718, total=   3.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.727, total=   3.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.728, total=   3.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.726, total=   2.9s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50, score=0.725, total=   3.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.722, total=   4.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.731, total=   4.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.732, total=   4.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.725, total=   5.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=75, score=0.727, total=   4.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.725, total=   6.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.727, total=   6.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.733, total=   5.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.727, total=   5.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100, score=0.727, total=   6.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.727, total=  13.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.729, total=  13.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.733, total=  13.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.729, total=  12.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200, score=0.728, total=  13.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.696, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.705, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.709, total=   0.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.703, total=   0.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=10, score=0.695, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.713, total=   1.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.720, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.723, total=   1.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.718, total=   1.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=20, score=0.718, total=   1.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.721, total=   2.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.724, total=   2.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.728, total=   3.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.725, total=   3.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=40, score=0.719, total=   2.9s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.723, total=   2.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.727, total=   2.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.730, total=   3.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.725, total=   3.0s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=50, score=0.724, total=   3.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.725, total=   4.7s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.728, total=   4.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.734, total=   3.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.727, total=   3.3s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=75, score=0.726, total=   3.1s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.724, total=   4.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.726, total=   4.6s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.733, total=   4.8s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.725, total=   4.9s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=100, score=0.727, total=   4.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.725, total=   9.2s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.731, total=   9.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.733, total=   9.4s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.728, total=   9.5s\n",
      "[CV] max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=sqrt, min_samples_split=6, n_estimators=200, score=0.727, total=   9.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=10, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=20, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=40, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=50, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=75, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=100, score=nan, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\hak3cob\\.conda\\envs\\deeplearning\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 231, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=1, n_estimators=200, score=nan, total=   0.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10, score=0.694, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10, score=0.702, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10, score=0.706, total=   0.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10, score=0.696, total=   0.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=10, score=0.694, total=   0.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20, score=0.712, total=   1.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20, score=0.716, total=   1.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20, score=0.724, total=   1.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20, score=0.714, total=   1.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=20, score=0.713, total=   1.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40, score=0.719, total=   2.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40, score=0.724, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40, score=0.729, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40, score=0.724, total=   2.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=40, score=0.723, total=   2.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50, score=0.720, total=   2.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50, score=0.726, total=   3.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50, score=0.729, total=   2.7s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50, score=0.725, total=   2.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50, score=0.723, total=   2.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75, score=0.722, total=   4.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75, score=0.725, total=   4.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75, score=0.729, total=   4.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75, score=0.724, total=   4.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=75, score=0.726, total=   4.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100, score=0.723, total=   5.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100, score=0.726, total=   5.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100, score=0.731, total=   6.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100, score=0.727, total=   5.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100, score=0.727, total=   4.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200, score=0.725, total=   9.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200, score=0.729, total=   9.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200, score=0.733, total=   9.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200, score=0.727, total=   9.7s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=2, n_estimators=200, score=0.728, total=  10.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10, score=0.698, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10, score=0.700, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10, score=0.701, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10, score=0.702, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=10, score=0.704, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20, score=0.715, total=   1.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20, score=0.720, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20, score=0.716, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20, score=0.714, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=20, score=0.712, total=   1.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40, score=0.722, total=   1.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40, score=0.724, total=   1.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40, score=0.728, total=   1.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40, score=0.723, total=   1.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=40, score=0.723, total=   1.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50, score=0.721, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50, score=0.722, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50, score=0.730, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50, score=0.723, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=50, score=0.724, total=   2.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75, score=0.722, total=   3.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75, score=0.728, total=   3.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75, score=0.731, total=   3.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75, score=0.724, total=   3.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=75, score=0.727, total=   3.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100, score=0.724, total=   4.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100, score=0.727, total=   4.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100, score=0.731, total=   4.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100, score=0.725, total=   4.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=100, score=0.727, total=   4.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200, score=0.726, total=   9.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200, score=0.729, total=   9.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200, score=0.732, total=   9.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200, score=0.726, total=   9.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=3, n_estimators=200, score=0.727, total=   9.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10, score=0.699, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10, score=0.705, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10, score=0.711, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10, score=0.703, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=10, score=0.703, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20, score=0.716, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20, score=0.712, total=   0.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20, score=0.720, total=   0.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20, score=0.717, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=20, score=0.715, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40, score=0.717, total=   1.7s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40, score=0.728, total=   1.7s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40, score=0.727, total=   1.7s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40, score=0.718, total=   1.7s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=40, score=0.721, total=   1.7s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50, score=0.722, total=   2.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50, score=0.725, total=   2.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50, score=0.729, total=   2.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50, score=0.724, total=   2.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50, score=0.724, total=   2.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75, score=0.725, total=   3.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75, score=0.728, total=   3.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75, score=0.731, total=   3.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75, score=0.725, total=   3.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=75, score=0.726, total=   3.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100, score=0.724, total=   4.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100, score=0.728, total=   4.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100, score=0.734, total=   4.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100, score=0.728, total=   4.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100, score=0.726, total=   4.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200, score=0.725, total=   8.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200, score=0.730, total=   9.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200, score=0.733, total=  12.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200, score=0.728, total=  13.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200, score=0.727, total=  10.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10, score=0.697, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10, score=0.707, total=   0.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10, score=0.710, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10, score=0.698, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=10, score=0.706, total=   0.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20, score=0.711, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20, score=0.717, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20, score=0.722, total=   1.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20, score=0.718, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=20, score=0.718, total=   0.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40, score=0.718, total=   1.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40, score=0.728, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40, score=0.729, total=   2.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40, score=0.722, total=   2.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=40, score=0.725, total=   1.7s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50, score=0.719, total=   2.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50, score=0.727, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50, score=0.730, total=   2.1s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50, score=0.725, total=   2.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=50, score=0.726, total=   2.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75, score=0.722, total=   3.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75, score=0.727, total=   5.8s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75, score=0.733, total=   5.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75, score=0.723, total=   4.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=75, score=0.726, total=   3.9s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100, score=0.727, total=   5.4s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100, score=0.730, total=   4.5s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100, score=0.733, total=   5.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100, score=0.729, total=   6.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=100, score=0.727, total=   5.3s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200, score=0.727, total=  11.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200, score=0.729, total=  10.2s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200, score=0.732, total=  10.0s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200, score=0.728, total=  10.6s\n",
      "[CV] max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=20, max_features=log2, min_samples_split=6, n_estimators=200, score=0.727, total=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2625 out of 2625 | elapsed: 113.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [3, 5, 6, 10, 20],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_split': [1, 2, 3, 5, 6],\n",
       "                         'n_estimators': [10, 20, 40, 50, 75, 100, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, max_features='log2', min_samples_split=6,\n",
       "                      random_state=101)"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators=100,criterion='mse',min_samples_split=6,max_features='log2',max_depth=20,random_state=101,verbose=0)\n",
    "model_rf.fit(train_x1, train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9309341118603661"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930867086069729"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7303117417629065"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7292618604656331"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with derived RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_Merged_derivedRUL.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=data_rf.drop(labels=['Unnamed: 0','Unit Number','Cycles Time','Operational Setting 1','Operational Setting 2','Operational Setting 3','Sensor 1','Sensor 5','Sensor 10','Sensor 16','Sensor 18','Sensor 19','RUL'], axis=1)\n",
    "y1=data_rf['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1,test_x1,train_y1,test_y1=train_test_split(x_scaled,y1,test_size=0.2,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, max_features='log2', min_samples_split=6,\n",
       "                      random_state=101)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators=100,max_depth=20,criterion='mse',min_samples_split=6,max_features='log2',random_state=101,verbose=0)\n",
    "model_rf.fit(train_x1, train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8328671065266732"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_rf(x,y):\n",
    "    r2 = model_rf.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8328475620201042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.639163900246252"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389950538057633"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(test_x1,test_y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_1=data_rf.drop(labels=['RUL','Sensor14','Sensor4'], axis=1)\n",
    "y1_1=data_rf['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1_1,test_x1_1,train_y1_1,test_y1_1=train_test_split(x1_1,y1_1,test_size=0.2,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "                      max_features='sqrt', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=2, min_samples_split=5,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                      n_jobs=None, oob_score=False, random_state=101, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_1 = RandomForestRegressor(n_estimators=200,criterion='mse',min_samples_split=5,min_samples_leaf=2,max_features='sqrt',bootstrap=False,random_state=101,verbose=0)\n",
    "model_rf_1.fit(train_x1_1, train_y1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9813565932170558"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_1.score(train_x1_1,train_y1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_rf(x,y):\n",
    "    r2 = model_rf_1.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(((1-r2)*(n-1))/(n-p-1))\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9813452893870777"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(train_x1_1,train_y1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6352541003987952"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_1.score(test_x1_1,test_y1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6343679344619604"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_rf(test_x1_1,test_y1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines : SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_svr = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_Merged_derivedRUL.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=data_svr.drop(labels=['Unnamed: 0','Unit Number','Cycles Time','Operational Setting 1','Operational Setting 2','Operational Setting 3','Sensor 1','Sensor 5','Sensor 10','Sensor 16','Sensor 18','Sensor 19','RUL'], axis=1)\n",
    "y2=data_svr['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x2,test_x2,train_y2,test_y2=train_test_split(x2,y2,test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svr = SVR()\n",
    "model_svr.fit(train_x2, train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01157597502117147"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svr.score(train_x2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_svr(x,y):\n",
    "    r2 = model_svr.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.011711170277778793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_svr(train_x2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svr.score(test_x2,test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_r2_svr(test_x2,test_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model  import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV, LinearRegression,MultiTaskLassoCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor2</th>\n",
       "      <th>Sensor3</th>\n",
       "      <th>Sensor4</th>\n",
       "      <th>Sensor7</th>\n",
       "      <th>Sensor9</th>\n",
       "      <th>Sensor11</th>\n",
       "      <th>Sensor12</th>\n",
       "      <th>Sensor14</th>\n",
       "      <th>Sensor15</th>\n",
       "      <th>Sensor17</th>\n",
       "      <th>Sensor20</th>\n",
       "      <th>Sensor21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>554.36</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>392</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>553.75</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>392</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>554.26</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>390</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>554.45</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>392</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>554.00</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>393</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor2  Sensor3  Sensor4  Sensor7  Sensor9  Sensor11  Sensor12  Sensor14  \\\n",
       "0   641.82  1589.70  1400.60   554.36  9046.19     47.47    521.66   8138.62   \n",
       "1   642.15  1591.82  1403.14   553.75  9044.07     47.49    522.28   8131.49   \n",
       "2   642.35  1587.99  1404.20   554.26  9052.94     47.27    522.42   8133.23   \n",
       "3   642.35  1582.79  1401.87   554.45  9049.48     47.13    522.86   8133.83   \n",
       "4   642.37  1582.85  1406.22   554.00  9055.15     47.28    522.19   8133.80   \n",
       "\n",
       "   Sensor15  Sensor17  Sensor20  Sensor21  RUL  \n",
       "0    8.4195       392     39.06   23.4190  191  \n",
       "1    8.4318       392     39.00   23.4236  190  \n",
       "2    8.4178       390     38.95   23.3442  189  \n",
       "3    8.3682       392     38.88   23.3739  188  \n",
       "4    8.4294       393     38.90   23.4044  187  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lr = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Data_for_Model.csv\",header='infer')\n",
    "data_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3=data_lr.drop(labels='RUL', axis=1)\n",
    "y3=data_lr['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x3,test_x3,train_y3,test_y3=train_test_split(x3,y3,test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr.fit(train_x3, train_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5779447161685508"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.score(train_x3,train_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_lr(x,y):\n",
    "    r2 = model_lr.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5775936859907038"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_lr(train_x3,train_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.582302829242975"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.score(test_x3,test_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5814913728646224"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_lr(test_x3,test_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskLassoCV(alphas=None, copy_X=True, cv=10, eps=0.001, fit_intercept=True,\n",
       "                 max_iter=100000, n_alphas=100, n_jobs=None, normalize=True,\n",
       "                 random_state=None, selection='cyclic', tol=0.0001,\n",
       "                 verbose=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LassoCV will return best alpha and coefficients after performing 10 cross validations\n",
    "lasscv = MultiTaskLassoCV(alphas = None,cv =10, max_iter = 100000, normalize = True)\n",
    "lasscv.fit(train_x3, train_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002425867059755066"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best alpha parameter\n",
    "alpha = lasscv.alpha_\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0002425867059755066, copy_X=True, fit_intercept=True,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg = Lasso(alpha)\n",
    "lasso_reg.fit(train_x3,train_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5779446889441093"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(train_x3,train_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_lasso(x,y):\n",
    "    r2 = lasso_reg.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5775936587436192"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_lasso(train_x3,train_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5823025625778454"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(test_x3,test_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5814911056814449"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_lasso(test_x3,test_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussion Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF,DotProduct, WhiteKernel,Kernel,Matern,RationalQuadratic,ConstantKernel,ExpSineSquared\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gpr = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Data_for_Model.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4=data_gpr.drop(labels='RUL', axis=1)\n",
    "y4=data_gpr['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x4,test_x4,train_y4,test_y4=train_test_split(x4,y4,test_size=0.3,random_state=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
       "                         n_restarts_optimizer=0, normalize_y=False,\n",
       "                         optimizer='fmin_l_bfgs_b', random_state=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpr = GaussianProcessRegressor()\n",
    "model_gpr.fit(train_x4, train_y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpr.score(train_x4,train_y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_gpr(x,y):\n",
    "    r2 = model_gpr.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_gpr(train_x4,train_y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7984466433467154"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpr.score(test_x4,test_y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8019404687830374"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_gpr(test_x4,test_y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_xgb = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Data_for_Model.csv\",header='infer')\n",
    "data_xgb = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x5=data_xgb.drop(labels='RUL', axis=1)\n",
    "x5=data_xgb.drop(labels=['UnitNumber','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y5=data_xgb['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5,test_x5,train_y5,test_y5=train_test_split(x5,y5,test_size=0.3,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.09, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBRegressor(learning_rate=0.09,n_estimators=50,num_parallel_tree=1,booster='gbtree',max_depth=6)\n",
    "model_xgb.fit(train_x5,train_y5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884935407057756"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(train_x5,train_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb(x,y):\n",
    "    r2 = model_xgb.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7882589245556988"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb(train_x5,train_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302285123557198"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(test_x5,test_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7295292828397133"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb(test_x5,test_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "'learning_rate':[0.9,0.8,0.6,0.1,0.01],\n",
    "'max_depth': [3,5,6,10,20],\n",
    "'n_estimators':[10,50,100,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid=GridSearchCV(XGBRegressor(objective='reg:squarederror'),param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=10, score=0.694, total=   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=10 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=10, score=0.703, total=   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=10, score=0.714, total=   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=10 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=10, score=0.701, total=   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=10, score=0.692, total=   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=50, score=0.684, total=   0.3s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=50, score=0.693, total=   0.4s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=50, score=0.698, total=   0.3s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=50, score=0.689, total=   0.3s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=50, score=0.687, total=   0.3s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=100, score=0.660, total=   0.6s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=100, score=0.676, total=   0.6s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=100, score=0.675, total=   0.7s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=100, score=0.668, total=   0.6s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=100, score=0.663, total=   0.6s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=200, score=0.634, total=   1.2s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=200, score=0.647, total=   1.3s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=200, score=0.643, total=   1.5s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=200, score=0.643, total=   1.2s\n",
      "[CV] learning_rate=0.9, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=3, n_estimators=200, score=0.637, total=   1.4s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=10, score=0.680, total=   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=10, score=0.698, total=   0.2s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=10, score=0.693, total=   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=10, score=0.685, total=   0.2s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=10, score=0.676, total=   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=50, score=0.621, total=   0.6s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=50, score=0.624, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=50, score=0.633, total=   0.6s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=50, score=0.612, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=50, score=0.606, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=100, score=0.578, total=   1.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=100, score=0.587, total=   1.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=100, score=0.595, total=   1.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=100, score=0.586, total=   1.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=100, score=0.568, total=   0.9s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=200, score=0.557, total=   2.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=200, score=0.558, total=   2.1s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=200, score=0.566, total=   1.9s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=200, score=0.553, total=   1.9s\n",
      "[CV] learning_rate=0.9, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=5, n_estimators=200, score=0.548, total=   4.1s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=10, score=0.664, total=   0.3s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=10, score=0.683, total=   0.2s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=10, score=0.676, total=   0.3s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=10, score=0.667, total=   0.3s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=10, score=0.652, total=   0.2s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=50, score=0.590, total=   1.0s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=50, score=0.611, total=   1.0s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=50, score=0.590, total=   0.7s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=50, score=0.588, total=   0.6s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=50, score=0.568, total=   0.6s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=100, score=0.556, total=   1.2s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=100, score=0.577, total=   1.2s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=100, score=0.564, total=   1.2s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=100, score=0.564, total=   1.2s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=100, score=0.542, total=   1.2s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=200, score=0.543, total=   2.3s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=200, score=0.564, total=   2.3s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=200, score=0.547, total=   2.7s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=200, score=0.553, total=   3.1s\n",
      "[CV] learning_rate=0.9, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.9, max_depth=6, n_estimators=200, score=0.528, total=   3.1s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=10, score=0.581, total=   0.3s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=10, score=0.591, total=   0.4s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=10, score=0.600, total=   0.4s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=10, score=0.592, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=10, score=0.579, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=50, score=0.539, total=   1.5s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=50, score=0.565, total=   1.1s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=50, score=0.553, total=   1.3s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=50, score=0.553, total=   1.6s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=50, score=0.544, total=   1.9s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=100, score=0.538, total=   2.4s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=100, score=0.565, total=   3.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=100, score=0.553, total=   3.1s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=100, score=0.552, total=   3.3s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=100, score=0.543, total=   2.4s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=200, score=0.538, total=   5.8s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=200, score=0.565, total=   6.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=200, score=0.553, total=   4.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=200, score=0.552, total=   5.3s\n",
      "[CV] learning_rate=0.9, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=10, n_estimators=200, score=0.543, total=   4.5s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=10, score=0.533, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=10, score=0.576, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=10, score=0.543, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=10, score=0.559, total=   0.5s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=10, score=0.532, total=   0.7s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=50, score=0.533, total=   1.9s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=50, score=0.576, total=   1.9s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=50, score=0.543, total=   1.8s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=50, score=0.560, total=   2.0s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=50, score=0.532, total=   1.7s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=100, score=0.533, total=   1.7s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=100, score=0.576, total=   1.9s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=100, score=0.543, total=   1.9s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=100, score=0.560, total=   2.1s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=100, score=0.532, total=   2.1s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=200, score=0.533, total=   2.1s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=200, score=0.576, total=   1.7s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=200, score=0.543, total=   1.7s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=200, score=0.560, total=   2.2s\n",
      "[CV] learning_rate=0.9, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.9, max_depth=20, n_estimators=200, score=0.532, total=   2.3s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=10, score=0.696, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=10, score=0.709, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=10, score=0.716, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=10, score=0.704, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=10, score=0.692, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=50, score=0.693, total=   0.4s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=50, score=0.700, total=   0.4s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=50, score=0.710, total=   0.4s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=50, score=0.692, total=   0.4s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=50, score=0.685, total=   0.4s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=100, score=0.674, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=100, score=0.680, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=100, score=0.693, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=100, score=0.674, total=   0.6s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=100, score=0.670, total=   0.5s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=200, score=0.656, total=   0.9s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=200, score=0.654, total=   1.0s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=200, score=0.662, total=   1.3s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=200, score=0.649, total=   1.4s\n",
      "[CV] learning_rate=0.8, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=3, n_estimators=200, score=0.644, total=   1.4s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=10, score=0.683, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=10, score=0.698, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=10, score=0.706, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=10, score=0.694, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=10, score=0.687, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=50, score=0.644, total=   0.6s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=50, score=0.653, total=   0.6s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=50, score=0.659, total=   0.6s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=50, score=0.651, total=   0.6s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=50, score=0.644, total=   0.6s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=100, score=0.603, total=   1.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=100, score=0.631, total=   0.9s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=100, score=0.623, total=   0.8s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=100, score=0.624, total=   0.8s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=100, score=0.617, total=   1.0s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=200, score=0.572, total=   2.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=200, score=0.605, total=   2.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=200, score=0.592, total=   2.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=200, score=0.602, total=   2.2s\n",
      "[CV] learning_rate=0.8, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=5, n_estimators=200, score=0.594, total=   1.6s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=10, score=0.673, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=10, score=0.683, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=10, score=0.692, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=10, score=0.677, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=10, score=0.655, total=   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=50, score=0.620, total=   0.5s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=50, score=0.622, total=   0.6s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=50, score=0.622, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=50, score=0.618, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=50, score=0.583, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=100, score=0.596, total=   1.4s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=100, score=0.602, total=   1.3s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=100, score=0.589, total=   1.3s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=100, score=0.596, total=   1.4s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=100, score=0.562, total=   1.3s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=200, score=0.582, total=   2.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=200, score=0.584, total=   2.5s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=200, score=0.576, total=   2.6s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=200, score=0.586, total=   2.6s\n",
      "[CV] learning_rate=0.8, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.8, max_depth=6, n_estimators=200, score=0.552, total=   2.5s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=10, score=0.594, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=10, score=0.627, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=10, score=0.615, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=10, score=0.603, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=10, score=0.601, total=   0.2s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=50, score=0.566, total=   1.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=50, score=0.598, total=   1.3s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=50, score=0.568, total=   1.3s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=50, score=0.573, total=   1.3s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=50, score=0.570, total=   1.2s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=100, score=0.565, total=   2.5s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=100, score=0.598, total=   2.3s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=100, score=0.569, total=   1.8s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=100, score=0.573, total=   2.4s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=100, score=0.569, total=   2.5s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=200, score=0.565, total=   4.9s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=200, score=0.599, total=   4.8s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=200, score=0.569, total=   5.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=200, score=0.573, total=   4.2s\n",
      "[CV] learning_rate=0.8, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=10, n_estimators=200, score=0.569, total=   4.1s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=10, score=0.560, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=10, score=0.594, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=10, score=0.571, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=10, score=0.563, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=10, score=0.575, total=   0.7s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=50, score=0.560, total=   2.1s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=50, score=0.594, total=   2.1s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=50, score=0.571, total=   1.5s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=50, score=0.563, total=   1.8s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=50, score=0.575, total=   2.4s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=100, score=0.560, total=   2.1s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=100, score=0.594, total=   2.1s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=100, score=0.571, total=   2.2s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=100, score=0.563, total=   2.0s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=100, score=0.575, total=   1.8s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=200, score=0.560, total=   1.9s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=200, score=0.594, total=   1.7s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=200, score=0.571, total=   2.0s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=200, score=0.563, total=   1.9s\n",
      "[CV] learning_rate=0.8, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.8, max_depth=20, n_estimators=200, score=0.575, total=   1.8s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=10, score=0.705, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=10, score=0.711, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=10, score=0.722, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=10, score=0.713, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=10, score=0.700, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=50, score=0.703, total=   0.3s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=50, score=0.706, total=   0.3s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=50, score=0.720, total=   0.3s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=50, score=0.711, total=   0.3s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=50, score=0.696, total=   0.3s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=100, score=0.692, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=100, score=0.696, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=100, score=0.711, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=100, score=0.701, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=100, score=0.683, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=200, score=0.672, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=200, score=0.683, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=200, score=0.699, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=200, score=0.682, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=3, n_estimators=200, score=0.663, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=10, score=0.697, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=10, score=0.713, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=10, score=0.717, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=10, score=0.705, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=10, score=0.695, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=50, score=0.675, total=   0.4s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=50, score=0.687, total=   0.4s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=50, score=0.691, total=   0.4s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=50, score=0.676, total=   0.4s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=50, score=0.662, total=   0.4s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=100, score=0.654, total=   0.8s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=100, score=0.663, total=   0.8s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=100, score=0.669, total=   0.8s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=100, score=0.649, total=   0.8s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=100, score=0.641, total=   0.8s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=200, score=0.632, total=   1.6s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=200, score=0.640, total=   1.6s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=200, score=0.648, total=   1.6s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=200, score=0.632, total=   1.6s\n",
      "[CV] learning_rate=0.6, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=5, n_estimators=200, score=0.618, total=   1.6s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=10, score=0.689, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=10, score=0.705, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=10, score=0.708, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=10, score=0.695, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=10, score=0.692, total=   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=50, score=0.651, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=50, score=0.670, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=50, score=0.677, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=50, score=0.650, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=50, score=0.653, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=100, score=0.622, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=100, score=0.657, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=100, score=0.657, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=100, score=0.631, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=100, score=0.629, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=200, score=0.611, total=   2.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=200, score=0.648, total=   2.1s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=200, score=0.641, total=   2.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=200, score=0.618, total=   2.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.6, max_depth=6, n_estimators=200, score=0.617, total=   1.9s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=10, score=0.655, total=   0.2s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=10, score=0.643, total=   0.2s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=10, score=0.643, total=   0.2s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=10, score=0.652, total=   0.2s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=10, score=0.640, total=   0.2s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=50, score=0.632, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=50, score=0.615, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=50, score=0.620, total=   0.9s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=50, score=0.626, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=50, score=0.623, total=   1.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=100, score=0.631, total=   1.8s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=100, score=0.614, total=   1.8s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=100, score=0.620, total=   1.8s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=100, score=0.624, total=   1.8s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=100, score=0.622, total=   1.9s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=200, score=0.631, total=   3.8s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=200, score=0.614, total=   3.6s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=200, score=0.620, total=   3.6s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=200, score=0.624, total=   3.7s\n",
      "[CV] learning_rate=0.6, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=10, n_estimators=200, score=0.622, total=   3.9s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=10, score=0.617, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=10, score=0.632, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=10, score=0.634, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=10, score=0.613, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=10, score=0.617, total=   0.5s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=50, score=0.617, total=   1.9s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=50, score=0.632, total=   1.9s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=50, score=0.634, total=   1.9s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=50, score=0.613, total=   1.9s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=50, score=0.616, total=   1.9s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=100, score=0.617, total=   2.0s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=100, score=0.632, total=   2.0s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=100, score=0.634, total=   2.1s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=100, score=0.613, total=   2.0s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=100, score=0.616, total=   2.1s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=200, score=0.617, total=   2.5s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=200, score=0.632, total=   3.0s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=200, score=0.634, total=   3.0s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=200, score=0.613, total=   3.2s\n",
      "[CV] learning_rate=0.6, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.6, max_depth=20, n_estimators=200, score=0.616, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10, score=0.301, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10, score=0.313, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10, score=0.318, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10, score=0.320, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10, score=0.283, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.716, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.727, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.731, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.723, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.717, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.719, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.728, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.733, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.724, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.718, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.718, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.728, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.733, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.723, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.717, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10, score=0.320, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10, score=0.332, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10, score=0.340, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10, score=0.341, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10, score=0.304, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.720, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.731, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.736, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.723, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.719, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.720, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.730, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.735, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.720, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.717, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.716, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.727, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.731, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.716, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.713, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=10, score=0.322, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=10, score=0.332, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=10, score=0.345, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=10, score=0.344, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=10, score=0.305, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=50, score=0.722, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=50, score=0.728, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=50, score=0.736, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=50, score=0.722, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=50, score=0.717, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.722, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.727, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.734, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.718, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.714, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.718, total=   2.0s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.724, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.726, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.713, total=   2.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.709, total=   2.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.303, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.320, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.331, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.328, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.291, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.704, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.717, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.725, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.710, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.700, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.703, total=   2.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.715, total=   2.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.722, total=   2.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.706, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.699, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.701, total=   3.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.714, total=   3.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.720, total=   3.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.705, total=   3.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.695, total=   3.7s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10, score=0.267, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10, score=0.276, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10, score=0.286, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10, score=0.302, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10, score=0.254, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.689, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.697, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.702, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.700, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.687, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.690, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.698, total=   5.2s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.702, total=   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.700, total=   5.0s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.688, total=   4.9s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.690, total=   9.5s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.698, total=   9.9s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.702, total=   9.8s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.700, total=   9.7s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.688, total=   9.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10, score=-1.828, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10, score=-1.852, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10, score=-1.877, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10, score=-1.849, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10, score=-1.928, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=-0.456, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=-0.457, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=-0.457, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=-0.447, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=-0.505, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.262, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.273, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.280, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.281, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.243, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.641, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.653, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.660, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.656, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.638, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10, score=-1.822, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10, score=-1.844, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10, score=-1.871, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10, score=-1.842, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10, score=-1.923, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=-0.440, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=-0.437, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=-0.438, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=-0.427, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=-0.486, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.282, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.293, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.301, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.303, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.263, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.656, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.668, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.676, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.670, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.651, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=10, score=-1.822, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=10, score=-1.844, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=10, score=-1.869, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=10, score=-1.842, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=10, score=-1.922, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=50, score=-0.439, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=50, score=-0.438, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=50, score=-0.435, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=50, score=-0.424, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=50, score=-0.484, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.283, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.294, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.305, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.306, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.264, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=200, score=0.658, total=   2.3s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=200, score=0.668, total=   2.2s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=200, score=0.678, total=   2.3s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=200, score=0.671, total=   2.3s\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=200, score=0.652, total=   2.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=-1.824, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=-1.845, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=-1.871, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=-1.845, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=-1.922, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=-0.448, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=-0.451, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=-0.444, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=-0.436, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=-0.494, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.268, total=   2.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.276, total=   2.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.292, total=   2.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.289, total=   2.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.247, total=   2.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.647, total=   4.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.655, total=   4.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.673, total=   4.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.660, total=   4.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.638, total=   4.4s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10, score=-1.825, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10, score=-1.847, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10, score=-1.876, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10, score=-1.848, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10, score=-1.924, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=-0.463, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=-0.466, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=-0.462, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=-0.448, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=-0.511, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.233, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.241, total=   5.1s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.257, total=   5.3s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.263, total=   5.2s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.209, total=   6.2s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.612, total=  13.6s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.613, total=  13.7s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.638, total=  14.0s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.635, total=  13.6s\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.602, total=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             param_grid={'learning_rate': [0.9, 0.8, 0.6, 0.1, 0.01],\n",
       "                         'max_depth': [3, 5, 6, 10, 20],\n",
       "                         'n_estimators': [10, 50, 100, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid.fit(train_x5,train_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=1, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBRegressor(learning_rate=0.1,n_estimators=50,max_depth=5,gamma=1)\n",
    "model_xgb.fit(train_x5,train_y5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7655464209262473"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(train_x5,train_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652863504003751"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb(train_x5,train_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7301629589327086"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(test_x5,test_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7294635595066472"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb(test_x5,test_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.35435122311844"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_xgb.predict(train_x5)\n",
    "mean_squared_error(train_y5,predictions,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.77315210244013"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_xgb.predict(test_x5)\n",
    "mean_squared_error(test_y5,predictions,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x5=data_xgb.drop(labels='RUL', axis=1)\n",
    "x5_1=data_xgb.drop(labels=['UnitNumber','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y5_1=data_xgb['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5_1,test_x5_1,train_y5_1,test_y5_1=train_test_split(x5_1,y5_1,test_size=0.3,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.1, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_1 = XGBRegressor(learning_rate=0.1,n_estimators=50,max_depth=5,gamma=0.1)\n",
    "model_xgb_1.fit(train_x5_1,train_y5_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7655464209262473"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_1.score(train_x5_1,train_y5_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb_1(x,y):\n",
    "    r2 = model_xgb_1.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652863504003751"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_1(train_x5_1,train_y5_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7301629589327086"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_1.score(test_x5_1,test_y5_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7294635595066472"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_1(test_x5_1,test_y5_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_2 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Data_for_Model.csv\",header='infer')\n",
    "#data_xgb = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5_2=data_xgb_2.drop(labels='RUL', axis=1)\n",
    "#x5=data_xgb.drop(labels=['UnitNumber','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y5_2=data_xgb['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5_2,test_x5_2,train_y5_2,test_y5_2=train_test_split(x5_2,y5_2,test_size=0.3,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_2 = XGBRegressor(learning_rate=0.1,n_estimators=50,max_depth=5)\n",
    "model_xgb_2.fit(train_x5_2,train_y5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6857634748784835"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_2.score(train_x5_2,train_y5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb_2(x,y):\n",
    "    r2 = model_xgb_2.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6855021192989537"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_2(train_x5_2,train_y5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6364691440519636"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_2.score(test_x5_2,test_y5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6357629160656634"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_2(test_x5_2,test_y5_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x5=data_xgb.drop(labels='RUL', axis=1)\n",
    "x5_3=data_xgb.drop(labels=['UnitNumber','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y5_3=data_xgb['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5_3,test_x5_3,train_y5_3,test_y5_3=train_test_split(x5_3,y5_3,test_size=0.3,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_3 = XGBRegressor(learning_rate=0.1,n_estimators=50,max_depth=5)\n",
    "model_xgb_3.fit(train_x5_3,train_y5_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7677830564344443"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_3.score(train_x5_3,train_y5_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb_3(x,y):\n",
    "    r2 = model_xgb_3.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7674771052571511"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_3(train_x5_3,train_y5_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7292311289253033"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_3.score(test_x5_3,test_y5_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7283973187874719"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_3(test_x5_3,test_y5_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XGB with  1 Averaged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_5_4 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD001_avg.csv\",header='infer')\n",
    "#data_xgb = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5_4=data_xgb_5_4.drop(labels=['RUL'], axis=1)\n",
    "#x5_4=data_xgb.drop(labels=['UnitNumber','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y5_4=data_xgb_5_4['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1_Avg</th>\n",
       "      <th>Sensor2_Avg</th>\n",
       "      <th>Sensor3_Avg</th>\n",
       "      <th>Sensor4_Avg</th>\n",
       "      <th>Sensor5_Avg</th>\n",
       "      <th>Sensor6_Avg</th>\n",
       "      <th>Sensor7_Avg</th>\n",
       "      <th>Sensor8_Avg</th>\n",
       "      <th>Sensor9_Avg</th>\n",
       "      <th>Sensor10_Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor12_Avg</th>\n",
       "      <th>Sensor13_Avg</th>\n",
       "      <th>Sensor14_Avg</th>\n",
       "      <th>Sensor15_Avg</th>\n",
       "      <th>Sensor16_Avg</th>\n",
       "      <th>Sensor17_Avg</th>\n",
       "      <th>Sensor18_Avg</th>\n",
       "      <th>Sensor19_Avg</th>\n",
       "      <th>Sensor20_Avg</th>\n",
       "      <th>Sensor21_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>642.621042</td>\n",
       "      <td>642.621042</td>\n",
       "      <td>1589.485521</td>\n",
       "      <td>1407.262135</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>553.439427</td>\n",
       "      <td>2388.110260</td>\n",
       "      <td>9048.265833</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.459427</td>\n",
       "      <td>2388.110833</td>\n",
       "      <td>8128.913542</td>\n",
       "      <td>8.436555</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.854167</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.840052</td>\n",
       "      <td>23.306310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642.423031</td>\n",
       "      <td>642.423031</td>\n",
       "      <td>1587.581533</td>\n",
       "      <td>1403.757247</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609547</td>\n",
       "      <td>553.795993</td>\n",
       "      <td>2388.078223</td>\n",
       "      <td>9049.902927</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.780592</td>\n",
       "      <td>2388.075854</td>\n",
       "      <td>8131.658467</td>\n",
       "      <td>8.422551</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.351916</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.906376</td>\n",
       "      <td>23.343887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642.545363</td>\n",
       "      <td>642.545363</td>\n",
       "      <td>1588.757709</td>\n",
       "      <td>1405.981564</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>553.575196</td>\n",
       "      <td>2388.099218</td>\n",
       "      <td>9048.757151</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.570782</td>\n",
       "      <td>2388.098771</td>\n",
       "      <td>8129.803520</td>\n",
       "      <td>8.431322</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.631285</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.865140</td>\n",
       "      <td>23.323317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>642.606984</td>\n",
       "      <td>642.606984</td>\n",
       "      <td>1589.302804</td>\n",
       "      <td>1406.959841</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>553.475714</td>\n",
       "      <td>2388.107302</td>\n",
       "      <td>9048.415238</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.484233</td>\n",
       "      <td>2388.107460</td>\n",
       "      <td>8129.170794</td>\n",
       "      <td>8.435278</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.804233</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.845873</td>\n",
       "      <td>23.310315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>642.448922</td>\n",
       "      <td>642.448922</td>\n",
       "      <td>1587.766022</td>\n",
       "      <td>1404.140409</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.609628</td>\n",
       "      <td>553.753717</td>\n",
       "      <td>2388.082565</td>\n",
       "      <td>9049.710446</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>521.728699</td>\n",
       "      <td>2388.080186</td>\n",
       "      <td>8131.302937</td>\n",
       "      <td>8.424452</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.423792</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.898327</td>\n",
       "      <td>23.339687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor1_Avg  Sensor2_Avg  Sensor3_Avg  Sensor4_Avg  Sensor5_Avg  \\\n",
       "0   642.621042   642.621042  1589.485521  1407.262135        14.62   \n",
       "1   642.423031   642.423031  1587.581533  1403.757247        14.62   \n",
       "2   642.545363   642.545363  1588.757709  1405.981564        14.62   \n",
       "3   642.606984   642.606984  1589.302804  1406.959841        14.62   \n",
       "4   642.448922   642.448922  1587.766022  1404.140409        14.62   \n",
       "\n",
       "   Sensor6_Avg  Sensor7_Avg  Sensor8_Avg  Sensor9_Avg  Sensor10_Avg  ...  \\\n",
       "0    21.610000   553.439427  2388.110260  9048.265833           1.3  ...   \n",
       "1    21.609547   553.795993  2388.078223  9049.902927           1.3  ...   \n",
       "2    21.610000   553.575196  2388.099218  9048.757151           1.3  ...   \n",
       "3    21.610000   553.475714  2388.107302  9048.415238           1.3  ...   \n",
       "4    21.609628   553.753717  2388.082565  9049.710446           1.3  ...   \n",
       "\n",
       "   Sensor12_Avg  Sensor13_Avg  Sensor14_Avg  Sensor15_Avg  Sensor16_Avg  \\\n",
       "0    521.459427   2388.110833   8128.913542      8.436555          0.03   \n",
       "1    521.780592   2388.075854   8131.658467      8.422551          0.03   \n",
       "2    521.570782   2388.098771   8129.803520      8.431322          0.03   \n",
       "3    521.484233   2388.107460   8129.170794      8.435278          0.03   \n",
       "4    521.728699   2388.080186   8131.302937      8.424452          0.03   \n",
       "\n",
       "   Sensor17_Avg  Sensor18_Avg  Sensor19_Avg  Sensor20_Avg  Sensor21_Avg  \n",
       "0    392.854167          2388           100     38.840052     23.306310  \n",
       "1    392.351916          2388           100     38.906376     23.343887  \n",
       "2    392.631285          2388           100     38.865140     23.323317  \n",
       "3    392.804233          2388           100     38.845873     23.310315  \n",
       "4    392.423792          2388           100     38.898327     23.339687  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x5_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5_4,test_x5_4,train_y5_4,test_y5_4=train_test_split(x5_4,y5_4,test_size=0.2,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_4 = XGBRegressor(learning_rate=0.1,n_estimators=50,max_depth=5)\n",
    "model_xgb_4.fit(train_x5_4,train_y5_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6386973305382169"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_4.score(train_x5_4,train_y5_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb_4(x,y):\n",
    "    r2 = model_xgb_4.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5078808467675713"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_4(train_x5_4,train_y5_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9055107041774157"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_4.score(test_x5_4,test_y5_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.10235168968545"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_4(test_x5_4,test_y5_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB with all 4 Mearged Average Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_5_5 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_Merged_data_avg_RUL_Null_Delete.csv\",header='infer')\n",
    "#data_xgb = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5_5=data_xgb_5_5.drop(labels='RUL', axis=1)\n",
    "#x5_4=data_xgb.drop(labels=['UnitNumber','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y5_5=data_xgb_5_5['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5_5,test_x5_5,train_y5_5,test_y5_5=train_test_split(x5_5,y5_5,test_size=0.2,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_5 = XGBRegressor(learning_rate=0.1,n_estimators=50,max_depth=5)\n",
    "model_xgb_5.fit(train_x5_5,train_y5_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4248853603138055"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_5.score(train_x5_5,train_y5_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb_5(x,y):\n",
    "    r2 = model_xgb_5.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40264335767400794"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_5(train_x5_5,train_y5_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10912777391932749"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_5.score(test_x5_5,test_y5_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3032251343552097"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_5(test_x5_5,test_y5_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB with derived RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_5_6 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_Merged_derivedRUL.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x5_6=data_xgb_5_6.drop(labels='RUL', axis=1)\n",
    "x5_6=data_xgb_5_6.drop(labels=['Unnamed: 0','Unit Number','Cycles Time','Operational Setting 1','Operational Setting 2','Operational Setting 3','Sensor 1','Sensor 5','Sensor 10','Sensor 16','Sensor 18','Sensor 19','RUL'], axis=1)\n",
    "y5_6=data_xgb_5_6['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5_6,test_x5_6,train_y5_6,test_y5_6=train_test_split(x_scaled,y5_6,test_size=0.2,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=125, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_6 = XGBRegressor(learning_rate=0.1,n_estimators=125,max_depth=8)\n",
    "model_xgb_6.fit(train_x5_6,train_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7059591541551337"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_6.score(train_x5_6,train_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb_6(x,y):\n",
    "    r2 = model_xgb_6.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7059247690432403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_6(train_x5_6,train_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417066457874431"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_6.score(test_x5_6,test_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6415389891767247"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_6(test_x5_6,test_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "'learning_rate':[0.5,0.4,0.2,0.15,0.1],\n",
    "'max_depth': [5,6,8,10,12,20],\n",
    "'n_estimators':[75,100,125,150,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid=GridSearchCV(XGBRegressor(objective='reg:squarederror'),param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=75 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=75, score=0.626, total=   6.6s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=75 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=75, score=0.619, total=   6.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=75 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   12.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=75, score=0.628, total=   6.7s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=75, score=0.618, total=   7.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=75, score=0.624, total=   6.5s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.623, total=   8.5s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.617, total=   8.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.626, total=   8.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.616, total=   8.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.622, total=   8.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=125, score=0.620, total=  10.3s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=125, score=0.613, total=  20.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=125, score=0.623, total=  10.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=125, score=0.614, total=   9.5s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=125, score=0.621, total=   9.7s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=150, score=0.618, total=  12.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=150, score=0.611, total=  10.9s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=150, score=0.621, total=  10.9s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=150, score=0.612, total=  11.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=150, score=0.619, total=  11.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.615, total=  14.8s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.608, total=  14.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.615, total=  14.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.608, total=  14.5s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.616, total=  15.4s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=75, score=0.618, total=   6.8s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=75, score=0.613, total=   6.8s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=75, score=0.620, total=   6.9s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=75, score=0.611, total=   6.9s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=75, score=0.617, total=   6.8s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=100, score=0.615, total=   9.0s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=100, score=0.611, total=   9.0s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=100, score=0.616, total=   9.3s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=100, score=0.606, total=   9.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=100, score=0.613, total=   9.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=125, score=0.613, total=  11.0s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=125, score=0.607, total=  11.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=125, score=0.612, total=  11.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=125, score=0.602, total=  12.3s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=125, score=0.611, total=  11.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=150, score=0.610, total=  13.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=150, score=0.603, total=  13.4s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=150, score=0.608, total=  13.3s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=150, score=0.599, total=  17.0s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=150, score=0.606, total=  18.2s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=200, score=0.602, total=  23.8s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=200, score=0.595, total=  18.7s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=200, score=0.600, total=  17.4s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=200, score=0.592, total=  19.5s\n",
      "[CV] learning_rate=0.5, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=6, n_estimators=200, score=0.599, total=  23.7s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=75, score=0.602, total=  11.9s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=75, score=0.592, total=  11.9s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=75, score=0.601, total=  11.9s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=75, score=0.593, total=  13.0s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=75, score=0.600, total=  12.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=100, score=0.596, total=  15.6s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=100 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=100, score=0.586, total=  15.8s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=100, score=0.592, total=  16.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=100, score=0.585, total=  16.0s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=100, score=0.594, total=  15.2s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=125, score=0.587, total=  19.7s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=125, score=0.579, total=  21.0s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=125, score=0.585, total=  15.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=125, score=0.577, total=  15.4s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=125, score=0.588, total=  15.0s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=150, score=0.583, total=  18.2s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=150, score=0.574, total=  18.0s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=150, score=0.580, total=  17.9s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=150, score=0.573, total=  19.0s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=150, score=0.584, total=  17.9s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=200, score=0.574, total=  23.8s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=200, score=0.564, total=  24.3s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=200, score=0.570, total=  23.6s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=200, score=0.563, total=  24.9s\n",
      "[CV] learning_rate=0.5, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=8, n_estimators=200, score=0.573, total=  23.6s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=75, score=0.579, total=  11.8s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=75, score=0.575, total=  11.8s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=75, score=0.580, total=  11.9s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=75, score=0.576, total=  11.7s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=75, score=0.579, total=  11.7s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.572, total=  15.5s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.566, total=  16.4s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.570, total=  16.4s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.565, total=  15.5s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.572, total=  18.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=125, score=0.566, total=  26.6s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=125, score=0.559, total=  20.4s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=125, score=0.563, total=  23.4s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=125, score=0.559, total=  28.9s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=125, score=0.565, total=  24.8s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=150, score=0.562, total=  30.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=150, score=0.553, total=  31.9s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=150, score=0.558, total=  28.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=150, score=0.553, total=  21.5s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=150, score=0.559, total=  19.7s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.555, total=  26.5s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.546, total=  27.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.549, total=  26.7s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.545, total=  26.5s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.551, total=  27.0s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=75, score=0.561, total=  12.7s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=75, score=0.556, total=  12.9s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=75, score=0.557, total=  13.5s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=75, score=0.559, total=  13.1s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=75, score=0.565, total=  12.9s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=100, score=0.554, total=  16.7s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=100, score=0.550, total=  16.8s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=100, score=0.549, total=  19.0s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=100, score=0.552, total=  18.0s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=100, score=0.558, total=  16.7s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=125 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=125, score=0.547, total=  21.5s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=125, score=0.545, total=  20.7s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=125, score=0.544, total=  25.8s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=125, score=0.547, total=  27.6s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=125, score=0.553, total=  27.6s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=150, score=0.543, total=  33.6s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=150, score=0.542, total=  32.3s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=150, score=0.542, total=  32.9s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=150, score=0.544, total=  31.0s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=150, score=0.551, total=  25.2s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=200, score=0.539, total=  32.9s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=200, score=0.537, total=  33.0s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=200, score=0.539, total=  33.9s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=200, score=0.539, total=  33.1s\n",
      "[CV] learning_rate=0.5, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=12, n_estimators=200, score=0.547, total=  33.6s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=75, score=0.523, total=  24.1s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=75, score=0.521, total=  24.8s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=75, score=0.535, total=  23.9s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=75, score=0.526, total=  23.7s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=75, score=0.530, total=  24.2s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.523, total=  31.0s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.521, total=  32.2s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.535, total=  34.7s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.526, total=  39.4s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.529, total=  42.3s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=125, score=0.523, total=  49.6s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=125, score=0.521, total=  50.3s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=125, score=0.535, total=  38.7s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=125, score=0.526, total=  38.7s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=125, score=0.529, total=  38.8s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=150, score=0.523, total=  47.0s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=150, score=0.521, total=  46.8s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=150, score=0.535, total=  46.6s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=150, score=0.526, total=  46.6s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=150, score=0.529, total=  46.5s\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.523, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.521, total= 1.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.535, total= 1.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.526, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.529, total= 1.0min\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=75, score=0.628, total=   5.1s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=75, score=0.625, total=   6.4s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=75, score=0.631, total=   7.3s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=75, score=0.622, total=   5.5s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=75, score=0.628, total=   5.6s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=100, score=0.628, total=   9.4s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=100, score=0.625, total=  10.6s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=100, score=0.631, total=   9.7s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=100, score=0.621, total=   6.8s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=100, score=0.627, total=   6.7s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=125, score=0.627, total=   8.3s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=125, score=0.624, total=   8.4s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=125, score=0.630, total=   8.2s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=125, score=0.621, total=   8.4s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=125 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=125, score=0.625, total=   8.2s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=150, score=0.626, total=  10.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=150, score=0.623, total=   9.8s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=150, score=0.629, total=  10.6s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=150, score=0.620, total=   9.9s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=150, score=0.624, total=   9.8s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=200, score=0.624, total=  13.5s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=200, score=0.621, total=  13.2s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=200, score=0.627, total=  13.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=200, score=0.617, total=  12.9s\n",
      "[CV] learning_rate=0.4, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=5, n_estimators=200, score=0.622, total=  12.8s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=75, score=0.626, total=   6.1s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=75, score=0.625, total=   6.3s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=75, score=0.629, total=   6.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=75, score=0.620, total=   6.1s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=75, score=0.624, total=   6.9s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=100, score=0.624, total=   8.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=100, score=0.622, total=   7.9s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=100, score=0.627, total=   8.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=100, score=0.618, total=   8.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=100, score=0.622, total=   8.2s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=125, score=0.622, total=  13.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=125, score=0.621, total=  13.7s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=125, score=0.625, total=  12.6s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=125, score=0.615, total=  12.9s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=125, score=0.620, total=  13.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=150, score=0.619, total=  16.4s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=150, score=0.618, total=  15.3s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=150, score=0.623, total=  15.2s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=150, score=0.613, total=  15.6s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=150, score=0.617, total=  15.3s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=200, score=0.614, total=  20.1s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=200, score=0.613, total=  22.4s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=200, score=0.619, total=  18.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=200, score=0.609, total=  15.6s\n",
      "[CV] learning_rate=0.4, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=6, n_estimators=200, score=0.613, total=  15.5s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=75, score=0.615, total=   8.6s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=75, score=0.610, total=   8.2s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=75, score=0.616, total=   8.3s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=75, score=0.611, total=   8.2s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=75, score=0.614, total=   8.2s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=100, score=0.610, total=  11.0s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=100, score=0.607, total=  10.8s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=100, score=0.611, total=  11.0s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=100, score=0.607, total=  11.7s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=100, score=0.610, total=  10.8s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=125, score=0.605, total=  13.4s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=125, score=0.602, total=  13.4s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=125, score=0.606, total=  13.7s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=125, score=0.603, total=  13.5s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=125, score=0.606, total=  13.5s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=150, score=0.600, total=  16.3s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=150, score=0.597, total=  16.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=150, score=0.601, total=  16.8s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=150 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=150, score=0.598, total=  16.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=150, score=0.603, total=  15.9s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=200, score=0.593, total=  22.8s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=200, score=0.590, total=  28.9s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=200, score=0.594, total=  25.9s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=200, score=0.593, total=  21.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.4, max_depth=8, n_estimators=200, score=0.594, total=  21.0s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=75, score=0.599, total=  14.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=75, score=0.598, total=  13.8s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=75, score=0.603, total=  13.7s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=75, score=0.595, total=  13.5s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=75, score=0.603, total=  13.7s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=100, score=0.593, total=  18.7s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=100, score=0.592, total=  18.3s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=100, score=0.596, total=  14.5s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=100, score=0.588, total=  14.6s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=100, score=0.596, total=  18.2s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=125, score=0.589, total=  22.2s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=125, score=0.586, total=  22.9s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=125, score=0.590, total=  21.3s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=125, score=0.582, total=  17.2s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=125, score=0.591, total=  17.2s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=150, score=0.585, total=  20.5s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=150, score=0.583, total=  21.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=150, score=0.587, total=  21.4s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=150, score=0.577, total=  20.2s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=150, score=0.586, total=  20.2s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=200, score=0.579, total=  27.2s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=200, score=0.575, total=  27.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=200, score=0.582, total=  29.5s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=200, score=0.570, total=  35.4s\n",
      "[CV] learning_rate=0.4, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=10, n_estimators=200, score=0.579, total=  31.3s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=75, score=0.582, total=  12.9s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=75, score=0.577, total=  13.2s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=75, score=0.593, total=  13.0s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=75, score=0.583, total=  13.8s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=75, score=0.584, total=  12.9s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=100, score=0.576, total=  17.0s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=100, score=0.571, total=  19.9s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=100, score=0.585, total=  24.6s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=100, score=0.578, total=  24.6s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=100, score=0.579, total=  25.5s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=125, score=0.571, total=  24.9s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=125, score=0.566, total=  24.2s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=125, score=0.581, total=  36.0s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=125, score=0.574, total=  32.5s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=125, score=0.575, total=  32.7s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=150, score=0.568, total=  29.1s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=150, score=0.563, total=  28.9s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=150, score=0.577, total=  30.2s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=150, score=0.570, total=  28.6s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=150, score=0.572, total=  32.4s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=200, score=0.565, total=  42.6s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=200 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=200, score=0.560, total=  47.6s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=200, score=0.574, total=  53.5s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=200, score=0.566, total=  40.2s\n",
      "[CV] learning_rate=0.4, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=12, n_estimators=200, score=0.569, total=  40.2s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=75, score=0.549, total=  36.1s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=75, score=0.552, total=  36.9s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=75, score=0.560, total=  35.4s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=75, score=0.551, total=  35.1s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=75, score=0.553, total=  35.7s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=100, score=0.549, total=  45.4s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=100, score=0.551, total=  36.6s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=100, score=0.560, total=  36.5s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=100, score=0.550, total=  37.4s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=100, score=0.552, total=  36.3s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=125, score=0.549, total=  51.1s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=125, score=0.551, total=  46.1s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=125, score=0.560, total=  44.9s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=125, score=0.550, total=  45.8s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=125, score=0.552, total=  48.9s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=150, score=0.549, total= 1.2min\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=150, score=0.551, total= 1.1min\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=150, score=0.560, total= 1.1min\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=150, score=0.550, total=  53.6s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=150, score=0.552, total=  54.3s\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=200, score=0.549, total= 1.2min\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=200, score=0.551, total= 1.2min\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=200, score=0.560, total= 1.2min\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=200, score=0.550, total= 1.3min\n",
      "[CV] learning_rate=0.4, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.4, max_depth=20, n_estimators=200, score=0.552, total= 1.9min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=75, score=0.630, total=   9.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=75, score=0.629, total=   8.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=75, score=0.634, total=   7.9s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=75, score=0.626, total=   8.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=75, score=0.630, total=   7.7s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.632, total=  10.4s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.631, total=  10.6s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.636, total=  10.7s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.628, total=  11.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.632, total=   9.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=125, score=0.634, total=  10.8s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=125, score=0.632, total=   9.9s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=125, score=0.637, total=   9.8s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=125, score=0.629, total=  10.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=125, score=0.632, total=   9.8s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=150, score=0.634, total=  12.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=150, score=0.633, total=  12.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=150, score=0.638, total=  12.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=150, score=0.630, total=  12.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=150, score=0.633, total=  12.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.635, total=  15.7s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.633, total=  15.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.639, total=  15.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.630, total=  16.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.634, total=  16.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=75 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=75, score=0.633, total=   7.5s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=75, score=0.631, total=   7.9s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=75, score=0.637, total=   7.9s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=75, score=0.630, total=   7.3s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=75, score=0.633, total=   7.5s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=100, score=0.634, total=  10.0s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=100, score=0.633, total=   7.9s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=100, score=0.638, total=   8.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=100, score=0.631, total=   7.9s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=100, score=0.633, total=   8.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=125, score=0.634, total=  10.7s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=125, score=0.632, total=   9.9s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=125, score=0.638, total=  10.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=125, score=0.630, total=   9.9s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=125, score=0.634, total=   9.9s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=150, score=0.634, total=  12.6s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=150, score=0.632, total=  11.8s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=150, score=0.638, total=  12.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=150, score=0.631, total=  11.8s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=150, score=0.634, total=  14.7s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=200, score=0.633, total=  21.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=200, score=0.631, total=  20.4s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=200, score=0.637, total=  21.5s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=200, score=0.631, total=  21.5s\n",
      "[CV] learning_rate=0.2, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=6, n_estimators=200, score=0.633, total=  21.4s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=75, score=0.633, total=  12.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=75, score=0.631, total=  12.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=75, score=0.637, total=  12.4s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=75, score=0.630, total=  13.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=75, score=0.634, total=  13.6s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=100, score=0.632, total=  17.3s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=100, score=0.631, total=  13.4s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=100, score=0.636, total=  13.9s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=100, score=0.628, total=  13.0s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=100, score=0.633, total=  12.0s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=125, score=0.630, total=  14.7s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=125, score=0.629, total=  14.5s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=125, score=0.635, total=  14.0s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=125, score=0.627, total=  14.0s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=125, score=0.633, total=  14.5s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=150, score=0.629, total=  16.4s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=150, score=0.629, total=  16.5s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=150, score=0.634, total=  16.5s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=150, score=0.626, total=  16.4s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=150, score=0.632, total=  16.6s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=200, score=0.626, total=  21.8s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=200, score=0.625, total=  22.4s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=200, score=0.632, total=  21.7s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=200, score=0.623, total=  21.6s\n",
      "[CV] learning_rate=0.2, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=8, n_estimators=200, score=0.629, total=  27.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=75, score=0.630, total=  15.0s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=75, score=0.628, total=  14.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=75, score=0.635, total=  11.7s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=75, score=0.625, total=  11.2s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=75 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=75, score=0.627, total=  11.0s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.627, total=  14.4s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.626, total=  18.5s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.631, total=  18.4s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.623, total=  18.5s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.626, total=  18.9s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=125, score=0.627, total=  23.6s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=125, score=0.623, total=  23.3s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=125, score=0.629, total=  23.0s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=125, score=0.621, total=  27.6s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=125, score=0.624, total=  30.7s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=150, score=0.625, total=  21.0s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=150, score=0.620, total=  21.2s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=150, score=0.626, total=  21.3s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=150, score=0.619, total=  21.0s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=150, score=0.622, total=  21.2s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.621, total=  28.5s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.617, total=  27.8s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.624, total=  27.7s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.616, total=  27.9s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.618, total=  28.3s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=75, score=0.623, total=  13.6s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=75, score=0.619, total=  13.9s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=75, score=0.628, total=  13.6s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=75, score=0.618, total=  13.6s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=75, score=0.624, total=  13.6s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=100, score=0.621, total=  17.7s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=100, score=0.617, total=  18.0s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=100, score=0.625, total=  18.4s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=100, score=0.616, total=  17.6s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=100, score=0.620, total=  18.7s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=125, score=0.620, total=  29.2s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=125, score=0.614, total=  28.5s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=125, score=0.623, total=  28.8s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=125, score=0.614, total=  28.7s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=125, score=0.617, total=  27.8s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=150, score=0.616, total=  34.0s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=150, score=0.612, total=  30.3s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=150, score=0.621, total=  26.1s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=150, score=0.612, total=  26.1s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=150, score=0.615, total=  25.7s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=200, score=0.614, total=  35.2s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=200, score=0.609, total=  34.6s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=200, score=0.617, total=  35.7s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=200, score=0.610, total=  34.3s\n",
      "[CV] learning_rate=0.2, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=12, n_estimators=200, score=0.612, total=  34.7s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=75, score=0.592, total=  27.4s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=75, score=0.593, total=  32.9s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=75, score=0.603, total=  38.1s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=75, score=0.591, total=  27.6s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=75, score=0.597, total=  33.4s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.592, total=  44.6s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.593, total=  45.5s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.602, total=  44.7s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.591, total=  44.7s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.597, total=  35.0s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=125, score=0.592, total=  42.7s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=125, score=0.593, total=  45.4s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=125, score=0.602, total=  44.1s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=125, score=0.591, total=  42.4s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=125, score=0.597, total=  43.5s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=150, score=0.592, total=  50.1s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=150, score=0.593, total=  56.0s\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=150, score=0.602, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=150, score=0.591, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=150, score=0.596, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.591, total= 1.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.593, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.602, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.590, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.596, total= 1.1min\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=75, score=0.627, total=   5.2s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=75, score=0.627, total=   5.3s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=75, score=0.632, total=   5.3s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=75, score=0.624, total=   5.2s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=75, score=0.625, total=   5.2s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=100, score=0.631, total=   6.9s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=100, score=0.630, total=   6.9s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=100, score=0.636, total=   6.9s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=100, score=0.627, total=   7.0s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=100, score=0.629, total=   7.6s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=125, score=0.633, total=   8.5s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=125, score=0.632, total=   8.5s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=125, score=0.637, total=   8.7s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=125, score=0.629, total=   8.4s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=125, score=0.631, total=   9.3s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=150, score=0.634, total=  13.7s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=150, score=0.633, total=  13.3s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=150, score=0.639, total=  13.2s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=150, score=0.630, total=  13.1s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=150, score=0.632, total=  12.8s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=200, score=0.636, total=  18.1s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=200, score=0.634, total=  17.5s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=200, score=0.640, total=  17.3s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=200, score=0.631, total=  17.3s\n",
      "[CV] learning_rate=0.15, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=5, n_estimators=200, score=0.633, total=  17.4s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=75, score=0.631, total=   8.1s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=75, score=0.631, total=   7.9s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=75, score=0.637, total=   8.4s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=75, score=0.629, total=   8.9s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=75, score=0.634, total=   8.1s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=100, score=0.634, total=   8.5s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=100, score=0.632, total=   8.3s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=100, score=0.639, total=   8.3s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=100, score=0.631, total=   8.2s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=100, score=0.636, total=   8.4s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=125 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=125, score=0.635, total=  10.2s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=125, score=0.633, total=  10.4s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=125, score=0.639, total=  10.2s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=125, score=0.631, total=  10.3s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=125, score=0.636, total=  10.3s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=150, score=0.635, total=  12.2s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=150, score=0.633, total=  13.0s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=150, score=0.639, total=  12.2s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=150, score=0.631, total=  12.2s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=150, score=0.636, total=  12.2s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=200, score=0.636, total=  17.5s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=200, score=0.634, total=  17.0s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=200, score=0.639, total=  16.8s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=200, score=0.631, total=  16.4s\n",
      "[CV] learning_rate=0.15, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=6, n_estimators=200, score=0.636, total=  17.2s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=75, score=0.636, total=   8.9s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=75, score=0.635, total=   9.0s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=75, score=0.641, total=   8.9s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=75, score=0.632, total=   8.9s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=75, score=0.637, total=   8.8s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=100, score=0.636, total=  11.7s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=100, score=0.634, total=  11.6s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=100, score=0.640, total=  11.6s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=100, score=0.631, total=  11.6s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=100, score=0.637, total=  11.6s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=125, score=0.637, total=  15.1s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=125, score=0.633, total=  14.2s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=125, score=0.640, total=  14.2s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=125, score=0.630, total=  14.2s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=125, score=0.636, total=  19.2s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=150, score=0.636, total=  22.1s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=150, score=0.633, total=  21.7s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=150, score=0.639, total=  23.0s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=150, score=0.630, total=  22.4s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=150, score=0.636, total=  21.9s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=200, score=0.635, total=  28.7s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=200, score=0.632, total=  29.6s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=200, score=0.638, total=  24.1s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=200, score=0.628, total=  22.3s\n",
      "[CV] learning_rate=0.15, max_depth=8, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=8, n_estimators=200, score=0.634, total=  22.3s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=75, score=0.632, total=  11.9s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=75, score=0.632, total=  11.4s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=75, score=0.639, total=  11.3s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=75, score=0.631, total=  11.3s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=75, score=0.635, total=  11.6s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=100, score=0.631, total=  15.5s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=100, score=0.631, total=  14.7s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=100, score=0.637, total=  14.7s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=100, score=0.630, total=  14.7s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=100, score=0.634, total=  15.0s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=125, score=0.630, total=  18.5s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=125, score=0.630, total=  18.3s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=125, score=0.635, total=  19.1s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=125 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=125, score=0.628, total=  18.1s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=125, score=0.632, total=  18.6s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=150, score=0.628, total=  23.9s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=150, score=0.629, total=  29.1s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=150, score=0.633, total=  25.6s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=150, score=0.627, total=  21.8s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=150, score=0.630, total=  22.4s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=200, score=0.627, total=  38.0s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=200, score=0.627, total=  37.4s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=200, score=0.630, total=  37.1s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=200, score=0.625, total=  36.8s\n",
      "[CV] learning_rate=0.15, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=10, n_estimators=200, score=0.628, total=  37.2s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=75, score=0.628, total=  15.2s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=75, score=0.627, total=  14.2s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=75, score=0.634, total=  14.1s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=75, score=0.623, total=  14.2s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=75, score=0.628, total=  14.1s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=100, score=0.626, total=  18.6s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=100, score=0.626, total=  18.3s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=100, score=0.632, total=  19.0s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=100, score=0.621, total=  18.5s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=100, score=0.627, total=  18.2s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=125, score=0.625, total=  22.4s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=125, score=0.625, total=  22.8s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=125, score=0.631, total=  22.7s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=125, score=0.619, total=  23.3s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=125, score=0.625, total=  22.4s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=150, score=0.623, total=  26.6s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=150, score=0.623, total=  27.0s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=150, score=0.629, total=  26.7s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=150, score=0.618, total=  27.8s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=150, score=0.623, total=  28.5s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=200, score=0.620, total=  45.6s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=200, score=0.620, total=  45.7s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=200, score=0.626, total=  44.8s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=200, score=0.616, total=  44.7s\n",
      "[CV] learning_rate=0.15, max_depth=12, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=12, n_estimators=200, score=0.620, total=  36.7s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=75, score=0.604, total=  29.0s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=75, score=0.606, total=  29.6s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=75, score=0.608, total=  29.2s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=75, score=0.601, total=  29.9s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=75 ...............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=75, score=0.604, total=  29.1s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=100, score=0.603, total=  37.1s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=100, score=0.605, total=  37.3s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=100, score=0.608, total=  37.1s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=100, score=0.601, total=  38.0s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=100, score=0.604, total=  39.5s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=125, score=0.603, total=  45.1s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=125, score=0.605, total=  57.9s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=125, score=0.607, total=  57.6s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=125, score=0.601, total=  56.3s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=125 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=125, score=0.604, total=  49.8s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=150, score=0.603, total=  52.5s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=150 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=150, score=0.605, total=  54.0s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=150, score=0.607, total=  52.0s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=150, score=0.600, total=  55.5s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=150 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=150, score=0.604, total=  51.7s\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=200, score=0.603, total= 1.1min\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=200, score=0.604, total= 1.3min\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=200, score=0.607, total= 1.5min\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=200, score=0.600, total= 1.4min\n",
      "[CV] learning_rate=0.15, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.15, max_depth=20, n_estimators=200, score=0.604, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=75, score=0.621, total=   5.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=75, score=0.619, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=75, score=0.627, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=75, score=0.617, total=   5.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=75, score=0.622, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.626, total=   7.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.625, total=   7.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.632, total=   7.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.624, total=   6.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.627, total=   6.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=125, score=0.630, total=   8.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=125, score=0.629, total=   8.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=125, score=0.635, total=   8.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=125, score=0.627, total=   8.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=125, score=0.630, total=   8.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=150, score=0.632, total=  10.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=150, score=0.630, total=  10.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=150, score=0.637, total=  10.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=150, score=0.629, total=  10.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=150, score=0.633, total=  10.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.635, total=  14.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.633, total=  13.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.639, total=  13.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.631, total=  13.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.634, total=  13.3s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=75, score=0.630, total=   6.4s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=75, score=0.629, total=   6.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=75, score=0.636, total=   6.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=75, score=0.627, total=   6.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=75, score=0.630, total=   6.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.633, total=   8.4s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.631, total=   8.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.638, total=   9.2s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.630, total=   8.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.633, total=   8.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=125, score=0.634, total=  10.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=125, score=0.633, total=  10.4s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=125, score=0.640, total=  12.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=125, score=0.632, total=  14.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=125, score=0.635, total=  13.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=150, score=0.635, total=  15.8s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=150, score=0.634, total=  16.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=150, score=0.641, total=  16.8s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=150, score=0.633, total=  16.4s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=150, score=0.635, total=  16.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.636, total=  21.2s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.636, total=  21.3s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.642, total=  21.0s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.634, total=  19.8s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.637, total=  16.3s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=75, score=0.637, total=   9.3s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=75, score=0.635, total=   9.2s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=75, score=0.641, total=   9.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=75, score=0.634, total=   9.2s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=75 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=75, score=0.637, total=   9.4s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=100, score=0.637, total=  12.5s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=100, score=0.636, total=  13.0s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=100, score=0.641, total=  11.7s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=100, score=0.634, total=  11.7s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=100, score=0.637, total=  12.5s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=125, score=0.638, total=  14.5s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=125, score=0.636, total=  14.6s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=125, score=0.641, total=  14.6s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=125, score=0.634, total=  14.4s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=125 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=125, score=0.637, total=  14.3s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=150, score=0.638, total=  17.9s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=150, score=0.636, total=  17.6s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=150, score=0.641, total=  19.3s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=150, score=0.634, total=  20.6s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=150 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=150, score=0.637, total=  17.7s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=200, score=0.637, total=  22.3s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=200, score=0.636, total=  22.6s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=200, score=0.640, total=  22.9s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=200, score=0.634, total=  22.3s\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=200, score=0.637, total=  23.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=75, score=0.637, total=  16.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=75, score=0.635, total=  15.5s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=75, score=0.640, total=  15.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=75, score=0.634, total=  15.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=75, score=0.637, total=  16.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.637, total=  19.5s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.634, total=  19.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.639, total=  20.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.633, total=  19.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.637, total=  19.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=125, score=0.636, total=  22.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=125, score=0.634, total=  18.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=125, score=0.638, total=  18.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=125, score=0.632, total=  18.5s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=125, score=0.636, total=  18.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=150, score=0.636, total=  21.9s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=150, score=0.633, total=  22.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=150, score=0.637, total=  21.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=150, score=0.632, total=  22.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=150, score=0.635, total=  21.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.636, total=  28.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.632, total=  29.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.635, total=  28.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.631, total=  31.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.634, total=  39.0s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=75, score=0.633, total=  15.7s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=75, score=0.633, total=  14.9s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=75, score=0.638, total=  15.0s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=75, score=0.632, total=  17.5s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=75, score=0.635, total=  19.7s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=100, score=0.632, total=  24.9s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=100, score=0.632, total=  25.5s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=100, score=0.637, total=  24.9s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=100, score=0.631, total=  25.2s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=100, score=0.634, total=  25.2s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=125, score=0.632, total=  30.5s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=125, score=0.632, total=  25.5s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=125, score=0.636, total=  23.0s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=125, score=0.630, total=  23.3s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=125, score=0.633, total=  22.8s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=150, score=0.631, total=  40.3s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=150, score=0.631, total=  30.3s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=150, score=0.635, total=  32.5s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=150, score=0.629, total=  30.5s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=150, score=0.632, total=  32.0s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=200, score=0.630, total=  40.2s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=200, score=0.629, total=  39.5s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=200, score=0.633, total=  42.1s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=200, score=0.628, total=  42.7s\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=200, score=0.630, total=  52.1s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=75, score=0.611, total=  48.3s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=75, score=0.611, total=  47.9s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=75, score=0.618, total=  45.7s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=75, score=0.606, total=  52.5s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=75 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=75, score=0.610, total=  40.6s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.611, total=  48.0s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.610, total=  46.8s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.618, total=  46.6s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.606, total=  45.1s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.610, total=  46.6s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=125, score=0.611, total=  57.5s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=125, score=0.610, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=125, score=0.617, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=125, score=0.606, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=125 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=125, score=0.610, total=  59.1s\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=150, score=0.611, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=150, score=0.610, total= 1.0min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=150, score=0.617, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=150, score=0.606, total= 1.0min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=150 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=150, score=0.610, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.610, total= 1.5min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.610, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.617, total= 1.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.605, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.610, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 750 out of 750 | elapsed: 286.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             param_grid={'learning_rate': [0.5, 0.4, 0.2, 0.15, 0.1],\n",
       "                         'max_depth': [5, 6, 8, 10, 12, 20],\n",
       "                         'n_estimators': [75, 100, 125, 150, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid.fit(train_x5_6,train_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 125}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5_6,test_x5_6,train_y5_6,test_y5_6=train_test_split(x5_6,y5_6,test_size=0.2,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=125, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_6 = XGBRegressor(learning_rate=0.1,n_estimators=125,max_depth=8)\n",
    "model_xgb_6.fit(train_x5_6,train_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7059591541551337"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_6.score(train_x5_6,train_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7059247690432403"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_6(train_x5_6,train_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417037827248054"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_6.score(test_x5_6,test_y5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6415361247743709"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_6(test_x5_6,test_y5_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_5_7 = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_Merged_derivedRUL.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data_xgb_5_7.drop(labels=['Unnamed: 0','Unit Number','Cycles Time','Operational Setting 1','Operational Setting 2','Operational Setting 3','Sensor 1','Sensor 5','Sensor 10','Sensor 16','Sensor 18','Sensor 19','RUL'], axis=1)\n",
    "y=data_xgb_5_7['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=x_scaled, columns= x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(df)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=7)\n",
    "new_data = pca.fit_transform(df)\n",
    "# This will be the new data fed to the algorithm.\n",
    "\n",
    "principal_Df = pd.DataFrame(data = new_data\n",
    "             , columns = ['principal component 1', 'principal component 2','principal component 3','principal component 4','principal component 5'\n",
    "               ,'principal component 6','principal component 7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5_7,test_x5_7,train_y5_7,test_y5_7=train_test_split(principal_Df,y,test_size=0.3,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=125, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_7 = XGBRegressor(learning_rate=0.1,n_estimators=125,max_depth=8)\n",
    "model_xgb_7.fit(train_x5_7,train_y5_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6654914895274426"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_7.score(train_x5_7,train_y5_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb_7(x,y):\n",
    "    r2 = model_xgb_7.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6654706280075857"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_7(train_x5_7,train_y5_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6073982947593156"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_7.score(test_x5_7,test_y5_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6073411593760165"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb_7(test_x5_7,test_y5_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB with train_FD002_derivedRUL.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/train_FD002_derivedRUL.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5=data_xgb.drop(labels=['Unnamed: 0','Unit Number','Cycles Time','Operational Setting 1','Operational Setting 2','Operational Setting 3','Sensor 1','Sensor 5','Sensor 10','Sensor 16','Sensor 18','Sensor 19','RUL'], axis=1)\n",
    "y5=data_xgb['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x5,test_x5,train_y5,test_y5=train_test_split(x5,y5,test_size=0.2,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.09, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=125, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBRegressor(learning_rate=0.09,n_estimators=125,max_depth=8)\n",
    "model_xgb.fit(train_x5,train_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7348523954127925"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(train_x5,train_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_xgb(x,y):\n",
    "    r2 = model_xgb.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734759882699229"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb(train_x5,train_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6118258053096373"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(test_x5,test_y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6112834605890378"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_xgb(test_x5,test_y5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_knn = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data_knn.drop(labels=['UnitNumber','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y=data_knn['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.1,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(leaf_size=40, n_neighbors=10)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsRegressor(n_neighbors=10,leaf_size=40)\n",
    "model_knn.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7433114293918702"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn.score(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_knn(x,y):\n",
    "    r2 = model_knn.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.743090026851184"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_knn(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6879311902127987"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6854919616067434"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_knn(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.88833194381981"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_knn.predict(train_x)\n",
    "mean_squared_error(train_y,predictions,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.55848893302809"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_knn.predict(test_x)\n",
    "mean_squared_error(test_y,predictions,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dcr = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data_dcr.drop(labels=['UnitNumber','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y=data_dcr['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.2,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=15, min_samples_split=50)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dcr = DecisionTreeRegressor(max_depth=15,min_samples_split=50)\n",
    "model_dcr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8110905262597488"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dcr.score(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to create adjusted R-Squared\n",
    "def adj_r2_dcr(x,y):\n",
    "    r2 = model_dcr.score(x,y)\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109071968741817"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_dcr(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6322521238655361"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dcr.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6308205019633095"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_dcr(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.96462553025713"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_dcr.predict(train_x)\n",
    "mean_squared_error(train_y,predictions,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.61791544923815"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_dcr.predict(test_x)\n",
    "mean_squared_error(test_y,predictions,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Sensor2</th>\n",
       "      <th>Sensor3</th>\n",
       "      <th>Sensor4</th>\n",
       "      <th>Sensor6</th>\n",
       "      <th>Sensor7</th>\n",
       "      <th>Sensor8</th>\n",
       "      <th>Sensor9</th>\n",
       "      <th>Sensor11</th>\n",
       "      <th>Sensor12</th>\n",
       "      <th>Sensor13</th>\n",
       "      <th>Sensor14</th>\n",
       "      <th>Sensor15</th>\n",
       "      <th>Sensor17</th>\n",
       "      <th>Sensor20</th>\n",
       "      <th>Sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>392</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>392</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>390</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>392</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>393</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time  Sensor2  Sensor3  Sensor4  Sensor6  Sensor7  Sensor8  Sensor9  \\\n",
       "0     1   641.82  1589.70  1400.60    21.61   554.36  2388.06  9046.19   \n",
       "1     2   642.15  1591.82  1403.14    21.61   553.75  2388.04  9044.07   \n",
       "2     3   642.35  1587.99  1404.20    21.61   554.26  2388.08  9052.94   \n",
       "3     4   642.35  1582.79  1401.87    21.61   554.45  2388.11  9049.48   \n",
       "4     5   642.37  1582.85  1406.22    21.61   554.00  2388.06  9055.15   \n",
       "\n",
       "   Sensor11  Sensor12  Sensor13  Sensor14  Sensor15  Sensor17  Sensor20  \\\n",
       "0     47.47    521.66   2388.02   8138.62    8.4195       392     39.06   \n",
       "1     47.49    522.28   2388.07   8131.49    8.4318       392     39.00   \n",
       "2     47.27    522.42   2388.03   8133.23    8.4178       390     38.95   \n",
       "3     47.13    522.86   2388.08   8133.83    8.3682       392     38.88   \n",
       "4     47.28    522.19   2388.04   8133.80    8.4294       393     38.90   \n",
       "\n",
       "   Sensor21  \n",
       "0   23.4190  \n",
       "1   23.4236  \n",
       "2   23.3442  \n",
       "3   23.3739  \n",
       "4   23.4044  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data.drop(labels=['UnitNumber','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y=data['RUL']\n",
    "x.head()\n",
    "#X, labels_true = make_blobs(n_samples=20631,n_features=15,centers=5,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxddZ3/8dcnN1vbpFs2oKGkTQq0IltLgaYoCCrggmNlBFQclGFwFMWRhzo+xnGZmd+4j7tMZRBxAZEyAiOyKaC0UGhLWdoKXaHplnRN0zb75/fHOUlvQ5Kbtrk5997zfj4eeeTec88953MuNO97tu/H3B0REYmvvKgLEBGRaCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEklHM7Mtm9ssRWE+NmbmZ5YfPHzeza9O93pEwnNtiZreZ2b8Px7IkcykIZESZWUvST7eZHUh6/oFhXtdtZtbeZ53PD+c6jlRSEC3rM708rHnDEJczIsEpuU1BICPK3Ut6foDXgHclTftVGlb5jeR1uvtpaVjH0RhjZqckPb8KWB9VMRJPCgLJRIVmdruZ7TWzFWY2q+cFMzvOzBaYWZOZrTezTw7jemvN7Bkz22Nm95rZxKT1vjusZXd46GV6OP0aM7s/ab41ZnZX0vONZnb6IOv8BfDhpOdXA7cnzzDQNpvZxcAXgPf3s7dzgpktDD/Dh82sPNW2hK+dYWbLwvf9Bige2kcn2UxBIJno3cCdwHjgPuCHAGaWB9wPPA9MAi4EbjSztw/Teq8GPgIcB3QC3w/XeyJwB3AjUAE8ANxvZoXAE8B5ZpZnZscCBUB9+L6pQAnwwiDr/CVwhZklwj/IpcDinhcH22Z3fxD4f8Bv+tnbuQq4BqgECoGbUm1LuD2/IwinicBvgXmH9QlKVsrKIDCzW82s0cxeGsK8k83sMTN7zsxeMLNLR6JGOSpPuvsD7t5F8Eep5w/cWUCFu3/V3dvdfR3wU+CKQZZ1U/jNt+fn54PM+wt3f8nd9wFfBP7WzBLA+4Hfu/sj7t4BfAsYBcwJa9gLnA68GXgI2GRmJ4fP/+Lu3YOsswF4GbiIYM/g9j6vH8k2A/zM3V9x9wPAXWF9DLYtwDkEQfZdd+9w97uBZ1OsR3JAftQFHKHbCL4l9v1H059/Ae5y95+Y2QyCb0A16StNhsHWpMf7geLw6p4TgOPMbHfS6wngL4Ms61vu/i9DXO/GpMevEvxRLCfYQ3i15wV37zazjQTf0CHYKzgfqAsf7yYIgXPD56ncDvwdwR/jNwHTkl47km2G13+GJeHjwbalC9jkh45E+SqS87Jyj8Dd/wzsTJ5mZrVm9qCZLTWzv4TfyAAcGBs+HgdsHsFSZXhtBNa7+/ikn1J3H669vOOTHk8GOoDtBP/PnNDzgplZOO+mcFJPEJwXPn6CIAjezNCCYAHwDmCdu/f9w5tqmw93+ODBtmULMCmc1mPyYS5fslBWBsEA5gM3uPtMguOhPw6nfxn4oJk1EOwN3BBNeTIMngGazexzZjYqPK5+ipmdNUzL/6CZzTCz0cBXgbvDw1N3Ae8wswvNrAD4DNAGLArf9wRwATDK3RsIvq1fDJQBz6VaaXgo6i1Af9f+p9rmbUBNeC5hKAbblqcIzo180szyzey9wOwhLleyWE4EgZmVEOxW/9bMlgP/DRwbvnwlcJu7VwOXAr84jH80kkHCP8rvIjjevZ7g2/otBHt6A/lsn/sItg8y7y8IDjtuJbha5pPhel8GPgj8IFznuwgue20PX38FaCE8XOPuzcA6YGFY81C2bYm7rz2Cbf5t+HtH33sSBljPgNsSbs97CQ5T7SI4n3DPUOqX7GbZ2pjGzGqA/3P3U8xsLPCyux/bz3wrgIvdfWP4fB1wjrs3jmS9IiKZKie+GYffwNab2eUQHPc0s54rTV4juOSO8PK8YqApkkJFRDJQVu4RmNkdBCfnygmOkX4J+BPwE4JDQgXAne7+1fBKoZ8SXDXhwGfd/eEo6hYRyURZGQQiIjJ8cuLQkIiIHLmsu6GsvLzca2pqoi5DRCSrLF26dLu7V/T3WtYFQU1NDUuWLIm6DBGRrGJmA94lrkNDIiIxl7YgSDUwnJl9IBwE7gUzW5R0uaeIiIygdO4R3EZwm/1A1gNvdvdTgX8jGCJCRERGWNrOEbj7n8O7fwd6fVHS06eB6nTVIiIiA8uUcwQfBf4QdREiInEU+VVDZnYBQRDMHWSe64DrACZP1qi4IiLDKdI9AjM7lWAkxcvcfcdA87n7fHef5e6zKir6vQxWRESOUGRBYGaTCYa4/VA4jG9avbJtL//+fytp7RjSqMAiIrGRzstH7yBodHGSmTWY2UfN7Hozuz6c5V8JGnf82MyWm1la7xJr2LWfW55cz9JXd6VzNSIiWSedVw1dmeL1a+m/I1NazJ5SRn6esXDNdurrykdqtSIiGS9TrhpKu5KifE4/fjwL1w54KkJEJJZiEwQAc+rKebFhN3sOdERdiohIxohVEMytK6fb4el12isQEekRqyA4/fjxjCpIsHDNYP3LRUTiJVZBUJifx+wpExUEIiJJYhUEEBweWtu0j617WqMuRUQkI8QuCObUlQFor0BEJBS7IJh+zFgmjilk4VoFgYgIxDAI8vKMc2vLWLRmB+4edTkiIpGLXRAA1NeWs7W5lbVN+6IuRUQkcrEMgrnhEBOLdHhIRCSeQTC5bDTVE0bphLGICDENAggODz21dgdd3TpPICLxFt8gmFZOc2snL23aE3UpIiKRim0QzKkN7yfQeQIRibnYBkF5SREnH1Oq8wQiEnuxDQKA+rpylmzYpfaVIhJrMQ+CMto6u1mm9pUiEmOxDoKe9pVP6vCQiMRYrINA7StFRGIeBKD2lSIisQ+C+toyta8UkViLfRCcMXkCowoSLNJ5AhGJqdgHQU/7Sp0wFpG4in0QQHAZqdpXikhcKQgIbiwDDUstIvGkIOBg+0odHhKROFIQELavnKr2lSIST2kLAjO71cwazeylAV43M/u+ma0xsxfM7Mx01TIU9XVB+8p129W+UkTiJZ17BLcBFw/y+iXAtPDnOuAnaawlpfq6cFhqHR4SkZhJWxC4+5+BnYPMchlwuweeBsab2bHpqieVyRPVvlJE4inKcwSTgI1JzxvCaa9jZteZ2RIzW9LU1JSWYsxM7StFJJaiDALrZ1q/f4Hdfb67z3L3WRUVFWkraE5dmdpXikjsRBkEDcDxSc+rgc0R1QLAnNrgfgK1rxSROIkyCO4Drg6vHjoH2OPuWyKsh4rSoH3lojUagE5E4iM/XQs2szuA84FyM2sAvgQUALj7zcADwKXAGmA/cE26ajkcc2rL+dXiV2nt6KK4IBF1OSIiaZe2IHD3K1O87sDH07X+IzV3Whm3LlzPsld3MSccekJEJJfpzuI+etpX6jyBiMSFgqCPkqJ8Tjt+PE/qPIGIxISCoB/1al8pIjGiIOiH2leKSJwoCPqh9pUiEicKgn70tK9cuFZ7BCKS+xQEA6ivK2NNY4vaV4pIzlMQDKBnuAm1rxSRXKcgGMCMY8cyYXQBC3UZqYjkOAXBAPLyjDm15Sxcs13tK0UkpykIBjGnrkztK0Uk5ykIBjE3HGtIl5GKSC5TEAxi8sTRTBo/iicVBCKSwxQEgzAz5tapfaWI5DYFQQo97StXbFb7ShHJTQqCFHruJ9DhIRHJVQqCFNS+UkRynYJgCObUlvPshp20dnRFXYqIyLBTEAxBfV0ZbZ3dLHt1V9SliIgMOwXBEJw9tYyE2leKSI5SEAxBSVE+px8/XuMOiUhOUhAMUX1tGS+ofaWI5CAFwRDV15XT7bBY7StFJMcoCIaop33lQt1PICI5RkEwRIX5eZyl9pUikoMUBIdhbti+cluz2leKSO5QEByGnuEmdHhIRHKJguAwqH2liOSitAaBmV1sZi+b2Roz+3w/r48zs/vN7HkzW2Fm16SznqPV075y0Vq1rxSR3JG2IDCzBPAj4BJgBnClmc3oM9vHgZXufhpwPvBtMytMV03DYU5dGVv2qH2liOSOdO4RzAbWuPs6d28H7gQu6zOPA6VmZkAJsBPoTGNNR62+Vu0rRSS3pDMIJgEbk543hNOS/RCYDmwGXgQ+5e7dfRdkZteZ2RIzW9LU1JSueofkhLKgfaXOE4hIrkhnEFg/0/oeWH87sBw4Djgd+KGZjX3dm9znu/ssd59VUVEx/JUeBjOjvq6MRWu3q32liOSEdAZBA3B80vNqgm/+ya4B7vHAGmA9cHIaaxoW9XXlal8pIjkjnUHwLDDNzKaEJ4CvAO7rM89rwIUAZlYFnASsS2NNw+Lg/QQ6PCQi2S9tQeDuncAngIeAVcBd7r7CzK43s+vD2f4NmGNmLwJ/BD7n7hl/FraitIiTqkp1Y5mI5IT8dC7c3R8AHugz7eakx5uBt6WzhnSpryvnV4tfpbWji+KCRNTliIgcMd1ZfIR621e+pvaVIpLdFARHaPaUiUH7Sh0eEpEspyA4QqXFBWpfKSI5QUFwFNS+UkRygYLgKMxR+0oRyQEKgqNwxuTxjCpIsEhdy0QkiykIjkJRfoKzpkzkSZ0wFpEspiA4SvW1al8pItlNQXCU6uvCYanXaq9ARLKTguAo9bSvfHK1zhOISHZSEBylvDzj3Noyta8UkaylIBgG9XXlbNnTynq1rxSRLDRoEJjZWWZ2TNLzq83sXjP7vplNTH952aG+d1hqnScQkeyTao/gv4F2ADN7E/A14HZgDzA/vaVlD7WvFJFslioIEu6+M3z8fmC+uy9w9y8CdektLXv0tK98at0Ota8UkayTMgjMrKdnwYXAn5JeS2svg2xTX1fOngMdal8pIlknVRDcATxhZvcCB4C/AJhZHcHhIQmdW1sGqH2liGSfQYPA3f8D+AxwGzDXD14fmQfckN7SsktlaTEnVZXqxjIRyTqDHt4xs9HAUnfvCJ+fBFwKvOru94xAfVllTl0Zv178mtpXikhWSXVo6EGgBnoPBz0FTAU+bmb/md7Sss/cunK1rxSRrJMqCCa4++rw8YeBO9z9BuAS4J1prSwL9bSvXKTzBCKSRVIFQfK1kG8BHgFw93agO11FZavS4gJOqx6nYalFJKukCoIXzOxbZvZpgvsGHgYws/FpryxLza0r54WG3TS3qn2liGSHVEHw98B2gvMEb3P3/eH0GcC30lhX1uppX/m0upaJSJZIFQQlwP3u/il3fz5pejPBiWTp44zJ4ykuyFP7ShHJGqmC4AdAeT/TJwHfG/5ysl9RfoLZU8o0AJ2IZI1UQfBGd3+i70R3fwg4NT0lZb/62jJWq32liGSJVEFQcISvAWBmF5vZy2a2xsw+P8A855vZcjNbYWavC51spPaVIpJNUgXBajO7tO9EM7sEWDfYG80sAfyI4J6DGcCVZjajzzzjgR8D73b3NwCXH0btGWvGsWMZP7pA4w6JSFZINYLojcDvzexvgaXhtFnAuaS+oWw2sMbd1wGY2Z3AZcDKpHmuAu5x99cA3L3x8MrPTHl5xpza4DyBu2NmUZckIjKgVHsE7wA+CiwETgh/ngBOdfdXUrx3ErAx6XlDOC3ZicAEM3vczJaa2dX9LcjMrjOzJWa2pKmpKcVqM8OcWrWvFJHskCoIqoGvA98g2BNoB7YBo4ew7P6+Bvft2pIPzCQInLcDXzSzE1/3Jvf57j7L3WdVVFQMYdXRmxueJ1ioy0hFJMOlGob6JnefA1QBXwB2Ah8BXjKzlYO9l2AP4Pik59XA5n7medDd97n7duDPwGmHUX/G6m1fuVonjEUks6XaI+gxChgLjAt/NgOLU7znWWCamU0xs0LgCuC+PvPcC5xnZvnhkNdnA6uGWnwmMwvOE6h9pYhkulT9COYDbwD2EvzhXwR8x91TjrPs7p1m9gngISAB3OruK8zs+vD1m919lZk9CLxAMIjdLe7+0lFtUQaZO62c3y5tYOXmZt5YPS7qckRE+pXqqqHJQBGwGthEcChn91AX7u4PAA/0mXZzn+ffBL451GVmk572lU+u2a4gEJGMleocwcXAWRwcYO4zwLNm9rCZfSXdxWW7ytJiTqwq0Y1lIpLRUp4j8MBLBN/s/0BwKWkt8Kk015YT6uvKeXbDTlo7uqIuRUSkX4MGgZl90szuNLONBFf0vBN4GXgvMHEE6st69bXltHaofaWIZK5U5whqgLuBT7v7lvSXk3vOnnqwfeWc2v4GchURiVaqcwT/5O53KwSOnNpXikimG+p9BHIU6tW+UkQymIJgBNSH7SsXr9sZdSkiIq+jIBgBPe0r1bVMRDKRgmAEFOUnOKtmooJARDKSgmCEzK0rZ3VjC41qXykiGUZBMELqe4el1l6BiGQWBcEIUftKEclUCoIR0tO+clHYvlJEJFMoCEbQnNpyNqt9pYhkGAXBCKpX+0oRyUAKghFUE7avXKTLSEUkgygIRlBP+8onV29nbVNL1OWIiAAKghF33ZumUlSQx+U3P8VLm/ZEXY6IiIJgpE2rKuWufziXUQUJrpj/NE+v0/kCEYmWgiACUytKuPtj51I1togP3/oMf1y1LeqSRCTGFAQROXbcKH57/RxOOqaU636xlN89tynqkkQkphQEEZo4ppBf//05zK6ZyI2/Wc5tC9dHXZKIxJCCIGIlRfn87JqzeOuMKr58/0q+9+hq3XksIiNKQZABigsS/OQDZzLvzGr+69FX+Mr9K+nuVhiIyMhI1bxeRkh+Io9vvu9Uxo0q4NaF62lu7eAb804lP6GsFpH0UhBkkLw844vvnM6E0QV8+5FXaD7QyQ+vOoPigkTUpYlIDtPXzQxjZtxw4TS+etkbeHTVNv7uZ8+wV03vRSSNFAQZ6upza/jeFaezZMMurvrpYna0tEVdkojkqLQGgZldbGYvm9kaM/v8IPOdZWZdZva+dNaTbS47fRLzr57JK9v28rf//RSbdx+IuiQRyUFpCwIzSwA/Ai4BZgBXmtmMAeb7OvBQumrJZm85uYrbPzKbxuY23veTRazTYHUiMszSuUcwG1jj7uvcvR24E7isn/luABYAjWmsJaudPbWMO647h7bObg1WJyLDLp1BMAnYmPS8IZzWy8wmAX8D3DzYgszsOjNbYmZLmpqahr3QbHDKpHH89vpzKS5IcOX8p1mswepEZJikMwisn2l975L6LvA5d+8abEHuPt/dZ7n7rIqKimErMNtMrSjht9efS+XYIq6+9Rn+9FcNViciRy+dQdAAHJ/0vBrY3GeeWcCdZrYBeB/wYzN7TxprynrHjQ8GqzuxqpTrbtdgdSJy9NIZBM8C08xsipkVAlcA9yXP4O5T3L3G3WuAu4F/dPffpbGmnBAMVnc2s2omcONvlvPzRRuiLklEsljagsDdO4FPEFwNtAq4y91XmNn1ZnZ9utYbF6XFBdx2zWwuml7Fl+5bwff/qMHqROTIWLb98Zg1a5YvWbIk6jIyRmdXN59d8AL3LNvENfU1fPEdM8jL6+/0jIjEmZktdfdZ/b2msYayXH4ij2+97zTGjSrgZws30Hygk6/Pe6MGqxORIVMQ5IC8PONf3zmDCaML+c4jr9Dc2sEPrtRgdSIyNPramCPMjE9eOI2vvPsNPLJyG9f87FkNViciQ6IgyDEfnlPDd99/Os9s2MkHblnMzn3tUZckIhlOQZCD3nPGJOZ/aCYvb93L5Tcv0mB1IjIoBUGOunD6wcHqLr/5KQ1WJyIDUhDksJ7B6lo7ujRYnYgMSEGQ406ZNI67rj+Xovw8rpz/NM+s3xl1SSKSYRQEMVBbUcLdH5tD5dgiPvQ/izVYnYgcQkEQE8eNH8Vd/3Bu72B19y7XYHUiElAQxEhZSRG//vuzmXlCMFjdfz3yCtvVC1kk9jTWUAy1dnTxT3ct54EXt5LIM84/sYJ5M6u5cHolRfm6G1kkF2msITlEcUGCH39gJqu37WXBsk3873MN/PGvjYwbVcC7TjuWeWdWc/rx4zHT4HUicaA9AqGr21m4ZjsLljXw0IqttHZ0M7ViDPPOrOa9Z07i2HGjoi5RRI7SYHsECgI5xN7WDh54cQsLlm7imQ07MYP62nLmzZzE299wDKMLtRMpko0UBHJEXtuxnwXLGrjnuQY27jzAmMIEl77xWObNrGZ2zUT1PRDJIgoCOSrd3c6zG3ayYFkDD7y4lZa2TqonjOK9Z1Yz78xJnFA2JuoSRSQFBYEMmwPtXTy0YisLljXw5JrtuMNZNROYd2Y1l556LGOLC6IuUUT6oSCQtNiy5wD/+9wmFixtYG3TPory83j7G45h3sxq5taVk9ChI5GMoSCQtHJ3nm/Yw4KlDdz3/Gb2HOigsrSIvzljEvNmVnNiVWnUJYrEnoJARkxbZxd/WtXIgmUNPP5yE53dzhsnjWPemZN49+mTmDimMOoSRWJJQSCR2N7Sxr3LN7NgaQMrtzRTkDAuOKmSeTOrueCkSgrzNcKJyEhREEjkVm1pZsHSBn63fDPbW9qYOKaQd592HPPOrOaUSWN1F7NImikIJGN0dnXz59VNLFi6iUdWbqO9q5sp5WO4aHolF02vYuYJE8hPaE9BZLgpCCQj7dnfwe9f3MKDK7by1NrtdHQ5E0YXcMHJlbx1ehXnnVhBSZHuZBYZDgoCyXh7Wzv4y+rtPLpyG396uZHd+zsoTOQxp66Mi6ZXcdH0Ko4ZVxx1mSJZS0EgWaWzq5slr+7i0ZXbeGTVNl7dsR+AU6vH9YbC9GNLdV5B5DBEFgRmdjHwPSAB3OLuX+vz+geAz4VPW4CPufvzgy1TQRAv7s6axhYeWbWNR1du47mNu3GHSeNH8dYZQSjMnjJRVyCJpBBJEJhZAngFeCvQADwLXOnuK5PmmQOscvddZnYJ8GV3P3uw5SoI4q1xbyuP/bWRR1Y28uSaJlo7uiktzuf8kyq5aHol559UybhRGuZCpK+oGtPMBta4+7qwiDuBy4DeIHD3RUnzPw1Up7EeyQGVpcW8/6zJvP+syRxo7+LJNcF5hT/+dRv3P7+Z/Dzj7KkTew8hHT9xdNQli2S8dAbBJGBj0vMGYLBv+x8F/tDfC2Z2HXAdwOTJk4erPslyowoTvHVGFW+dUUVXt7N8424eDQ8hfeX+lXzl/pWcfEwpF00P5nnjpHEaOlukH+k8NHQ58HZ3vzZ8/iFgtrvf0M+8FwA/Bua6+47BlqtDQzIUG7bv49FV23hk5Tae3bCTbofK0iIunF7F22ZUcW5tGcUF6s8s8RHVoaEG4Pik59XA5r4zmdmpwC3AJalCQGSoasrHcO15U7n2vKns2tfOYy838uiqbdy3fBN3PPMaowsTnDetnLfOOIa3nFypMZAk1tK5R5BPcLL4QmATwcniq9x9RdI8k4E/AVf3OV8wIO0RyNFo6+ziqbU7wkNIjWxtbiXP4MzJEzhj8nimVZZSV1VCXWWJeitITony8tFLge8SXD56q7v/h5ldD+DuN5vZLcA84NXwLZ0DFdpDQSDDxd1ZsbmZh1du4/GXG/nr1r20d3b3vl41tigIhsoSplWV9D7W3oNkI91QJjIEXd1Ow679rN7WwurGFlY37mVNYwtrGlvY397VO1/ZmMJDwmFaZbAHUVFapJvcJGNFdY5AJKsk8owTysZwQtkYLppR1Tu9u9vZ0tzK6m1BMKze1sKaphbuXb6Zva2dvfONLc5nWtXBYJhWFexBHDeuWAEhGU17BCJHyN1p2tsW7D1s28vqcO9hTWMLO/a19843pjBBXWUJdZWlTKsqoa4i2JuonjBa7TxlxGiPQCQNzIzKscVUji2mvq78kNd2tLQFew9J4fDkmiYWLGvonacoP4/aMBR6wqG2ooRjx4/SqKsyovR/m0galJUUUVZSxNlTyw6ZvudARxgMe3uDYsmGXdy7/NArq0cXJqgsLaKytJiKsUW9jytLi6gce/Dx+NEFOuwkR01BIDKCxo0qYOYJE5h5woRDpu9r62RtUwvrmvaxrbmVxr1twU9zKys3N/N4cyv7kk5Y9yhM5FFRWkRFaRAWVWMPDYuK8HHZmCIdhpIBKQhEMsCYonxOrR7PqdXjB5xnX1tnbzj0BsXeVpqag8cbduzjmQ072b2/43XvTeQZZWMKD9mbqCwtomLswcdVY4spLynSSK4xpCAQyRJjivKZUpTPlPIxg87X1tlFU+8eRRtNe1t7H2/b28rWPa280LCHHfva6O9akYljCqkoKWLimMLenwljCilL/j26kLKS4LeCI/spCERyTFF+guoJo6meMPjIq51d3ezY105jc7Bn0RMWjXtbadrbxq797aza2syufe3sPtDRb2gAlBblMyEpNA75GV34utfGFufrvEaGURCIxFR+Io+qscVUjS0Gxg06b2dXN3sOdLBzX/vBn/3t7GwJf4fTtjW38tctzezY105b0l3ah6w3z4JwGF2Ycq9jwpgCSoryGVOYr5Fj00hBICIp5Sfyeq+EGgp350BHFzta2tm1v50d+9rZlRwi+w5OW7WlmZ372/s9t9HDDEoK8ykpzqekKPhdWlxAaVHy8+Bx8Lsg+F2cH8wTzj+6IKFA6YeCQESGnZkxujCf0RPzh9wcqLOrm9199jp27++gpa2DltZO9rZ1Br9bO2lp62TPgQ427dpPS1swbX8/V1W9vq6DgVLaGypBoJQmhUxJUT5jiwt6H48pymdUQYLRhcFPcWGC0QUJ8hO5cX5EQSAiGSE/kUd5SRHlQ9zr6Kur22lpC0IiCIyO3vAIwuLQQOkJkCMJlB6FiTyKC/KC0CtMUByGxajCRG9wjCrMT3qc6Odx/iHTowgaBYGI5IREnjFuVMFR96zuL1D2tXdxoL2TAx1d7G/v4kD4s7+j7+Ngnpa2Tpr2th0y//72TroPc0SfvkFz1dmTufa8qUe1ff1REIiIJBmuQOnL3Wnv6g6CIzlQeh+nDpqK0iPbW0pFQSAiMgLMjKL8BEX5CQa+bTAauXGmQ0REjpiCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYMx9okPEMZWZNwKtR13GUyoHtUReRQfR5HEqfx0H6LA51NJ/HCe5e0d8LWRcEufHNQIsAAAZBSURBVMDMlrj7rKjryBT6PA6lz+MgfRaHStfnoUNDIiIxpyAQEYk5BUE05kddQIbR53EofR4H6bM4VFo+D50jEBGJOe0RiIjEnIJARCTmFAQjyMyON7PHzGyVma0ws09FXVPUzCxhZs+Z2f9FXUvUzGy8md1tZn8N/x85N+qaomRmnw7/nbxkZneYWXHUNY0kM7vVzBrN7KWkaRPN7BEzWx3+njAc61IQjKxO4DPuPh04B/i4mc2IuKaofQpYFXURGeJ7wIPufjJwGjH+XMxsEvBJYJa7nwIkgCuirWrE3QZc3Gfa54E/uvs04I/h86OmIBhB7r7F3ZeFj/cS/EOfFG1V0TGzauAdwC1R1xI1MxsLvAn4HwB3b3f33dFWFbl8YJSZ5QOjgc0R1zOi3P3PwM4+ky8Dfh4+/jnwnuFYl4IgImZWA5wBLI62kkh9F/gs0B11IRlgKtAE/Cw8VHaLmY2JuqiouPsm4FvAa8AWYI+7PxxtVRmhyt23QPDFEqgcjoUqCCJgZiXAAuBGd2+Oup4omNk7gUZ3Xxp1LRkiHzgT+Im7nwHsY5h2+7NReOz7MmAKcBwwxsw+GG1VuUtBMMLMrIAgBH7l7vdEXU+E6oF3m9kG4E7gLWb2y2hLilQD0ODuPXuIdxMEQ1xdBKx39yZ37wDuAeZEXFMm2GZmxwKEvxuHY6EKghFkZkZwDHiVu38n6nqi5O7/7O7V7l5DcBLwT+4e22987r4V2GhmJ4WTLgRWRlhS1F4DzjGz0eG/mwuJ8cnzJPcBHw4ffxi4dzgWmj8cC5Ehqwc+BLxoZsvDaV9w9wcirEkyxw3Ar8ysEFgHXBNxPZFx98VmdjewjOBqu+eI2XATZnYHcD5QbmYNwJeArwF3mdlHCcLy8mFZl4aYEBGJNx0aEhGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQSMYxMzezbyc9v8nMvjxMy77NzN43HMtKsZ7LwxFEH0tnXWZWY2ZXHX6FIgcpCCQTtQHvNbPyqAtJZmaJw5j9o8A/uvsF6aonVAMcVhAc5nZIDCgIJBN1Etw89Om+L/T95mxmLeHv883sCTO7y8xeMbOvmdkHzOwZM3vRzGqTFnORmf0lnO+d4fsTZvZNM3vWzF4ws39IWu5jZvZr4MV+6rkyXP5LZvb1cNq/AnOBm83sm/2857Phe543s6/18/qGnhA0s1lm9nj4+M1mtjz8ec7MSgluMDovnPbpoW6HmY0xs9+HNbxkZu8fyn8YyU26s1gy1Y+AF8zsG4fxntOA6QRD964DbnH32WEDoBuAG8P5aoA3A7XAY2ZWB1xNMMLlWWZWBCw0s57RLmcDp7j7+uSVmdlxwNeBmcAu4GEze4+7f9XM3gLc5O5L+rznEoKhg8929/1mNvEwtu8m4OPuvjAcuLCVYGC6m9y9J9CuG8p2mNk8YLO7vyN837jDqENyjPYIJCOFo7LeTtCcZKieDXs+tAFrgZ4/gC8S/PHvcZe7d7v7aoLAOBl4G3B1OPTHYqAMmBbO/0zfEAidBTweDozWCfyKoKfAYC4Cfubu+8Pt7Dve/GAWAt8xs08C48N19jXU7XiRYM/o62Z2nrvvOYw6JMcoCCSTfZfgWHvyuPydhP/fhoORFSa91pb0uDvpeTeH7v32HVfFAQNucPfTw58pSePf7xugPhvqhvR5T6pxXXq3Eehtz+juXwOuBUYBT5vZyQMsP+V2uPsrBHsyLwL/GR7OkphSEEjGCr8t30UQBj02EPwBg2C8+oIjWPTlZpYXnjeYCrwMPAR8LBwmHDM7cQiNYRYDbzaz8vAE7JXAEyne8zDwETMbHa6nv0NDGzi4jfN6JppZrbu/6O5fB5YQ7MnsBUqT3juk7QgPa+13918SNICJ85DXsadzBJLpvg18Iun5T4F7zewZgp6tA31bH8zLBH+wq4Dr3b3VzG4hOHy0LNzTaCJFG0B332Jm/ww8RvBN/AF3H3RYYHd/0MxOB5aYWTvwAPCFPrN9BfgfM/sCh3awu9HMLgC6CIao/gPB3k6nmT1P0OP2e0PcjjcC3zSzbqAD+NhgdUtu0+ijIiIxp0NDIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMTc/wd7Im0Rg8TbNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wcss=[]\n",
    "for i in range (1,11):\n",
    "    kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)\n",
    "    kmeans.fit(x)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 4 1 1] <class 'numpy.ndarray'> 20631\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 100)\n",
    "y_kmeans = kmeans.fit_predict(x)\n",
    "print(y_kmeans,type(y_kmeans),y_kmeans.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, labels_true = make_blobs(n_samples=20631,n_features=15,centers=kmeans.cluster_centers_,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index: -0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Rand Index: %0.3f\"% metrics.adjusted_rand_score(labels_true, y_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.3119744685040154e-05"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_rand_score(labels_true, y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 1, 0, 2])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13854958, 0.0571853 , 0.04960124, 0.13172278, 0.12693314])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.jaccard_score(labels_true,y_kmeans,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4084473016345938"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.silhouette_score(x,y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2064369153216034"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purity_score(labels_true, y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.38140695e+01, 6.42553540e+02, 1.58887996e+03, 1.40635835e+03,\n",
       "        2.16097923e+01, 5.53619831e+02, 2.38808280e+03, 9.05896367e+03,\n",
       "        4.74625789e+01, 5.21624897e+02, 2.38808140e+03, 8.13899558e+03,\n",
       "        8.43145417e+00, 3.92771571e+02, 3.88636301e+01, 2.33196404e+01],\n",
       "       [2.43880178e+02, 6.43150057e+02, 1.59606213e+03, 1.41874916e+03,\n",
       "        2.16100000e+01, 5.52410134e+02, 2.38816426e+03, 9.07171532e+03,\n",
       "        4.78369853e+01, 5.20592097e+02, 2.38816418e+03, 8.14656994e+03,\n",
       "        8.48052377e+00, 3.94656469e+02, 3.86341810e+01, 2.31819539e+01],\n",
       "       [1.94790881e+02, 6.43256297e+02, 1.59836055e+03, 1.42006192e+03,\n",
       "        2.16099843e+01, 5.52490975e+02, 2.38811961e+03, 9.13124026e+03,\n",
       "        4.78582154e+01, 5.20695244e+02, 2.38811915e+03, 8.19956345e+03,\n",
       "        8.48749426e+00, 3.95253145e+02, 3.86032862e+01, 2.31593370e+01],\n",
       "       [3.16178692e+01, 6.42399921e+02, 1.58715742e+03, 1.40315601e+03,\n",
       "        2.16096079e+01, 5.53902386e+02, 2.38806114e+03, 9.05629113e+03,\n",
       "        4.73673759e+01, 5.21873381e+02, 2.38806037e+03, 8.13745676e+03,\n",
       "        8.41993357e+00, 3.92329423e+02, 3.89251197e+01, 2.33543146e+01],\n",
       "       [1.55903268e+02, 6.42881156e+02, 1.59285592e+03, 1.41311648e+03,\n",
       "        2.16099421e+01, 5.52942725e+02, 2.38812872e+03, 9.06535689e+03,\n",
       "        4.76723137e+01, 5.21045012e+02, 2.38812946e+03, 8.14250523e+03,\n",
       "        8.45834381e+00, 3.93835294e+02, 3.87387824e+01, 2.32424357e+01]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = kmeans.cluster_centers_\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Harsh/AI_ML_TensorFlow/Predictive_Vehicle_Maintanance/ForModel/Predictive_Maintenance_train_updated.csv\",header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(labels=['UnitNumber','Setting1','Setting2','Setting3','Sensor1','Sensor5','Sensor10','Sensor16','Sensor18','Sensor19','BIN','RUL'], axis=1)\n",
    "y=data['RUL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, labels_true = make_blobs(n_samples=20631,n_features=15,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=10, min_samples=10).fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = db.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 469\n"
     ]
    }
   ],
   "source": [
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0) # the label -1 is considered as noise by the DBSCAN algorithm\n",
    "n_noise_ = list(labels).count(-1)  # calculating the number of clusters\n",
    "print(n_clusters_,n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.7783688392303072e-06"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_rand_score(labels_true, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.32998565, 0.00144844, 0.00087146, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.jaccard_score(labels_true, labels,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3027683300060074"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.silhouette_score(x,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33478745577044255"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purity_score(labels_true, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
